{
  "tasks": [
    {
      "id": 1,
      "title": "Project Setup and Environment Configuration",
      "description": "Set up the Next.js 14 project with TypeScript, Tailwind CSS, and configure Supabase integration",
      "status": "done",
      "dependencies": [],
      "priority": "high",
      "details": "Initialize a Next.js 14 project with App Router using `create-next-app`. Configure TypeScript, Tailwind CSS, and shadcn/ui. Set up Turborepo structure with packages for UI components, utilities, types, and functions. Create styleGuide.ts in packages/ui to define design tokens. Configure ESLint with no-literal-style rule to enforce usage of design tokens. Set up Supabase project and generate types with `supabase gen types typescript --local > packages/types/db.ts`.\n\n**PRD Context**\n- Core Technology Stack: Next.js 14 with App Router, React 18, TypeScript, Tailwind CSS\n- Supabase Integration: Configure Auth, Postgres database with pgvector extensions, Storage, and Realtime features\n- Compliance Considerations: Ensure project structure and data handling align with FERPA/GDPR requirements as mentioned in 'Assumptions and Constraints'\n- Initial Configuration: Set up project with proper type safety and component architecture to support the educational platform requirements",
      "testStrategy": "Verify project structure matches requirements. Run `npm run dev` to ensure the application starts without errors. Check that Supabase connection works by testing a simple query. Verify that all Supabase features (Auth, Postgres with pgvector, Storage, Realtime) are properly configured and accessible.",
      "subtasks": [
        {
          "id": 1,
          "title": "Initialize Next.js 14 Project with TypeScript and Tailwind CSS",
          "description": "Set up the base Next.js 14 project with TypeScript and Tailwind CSS configuration, including shadcn/ui integration",
          "dependencies": [],
          "details": "Implementation details:\n1. Create a new Next.js 14 project using `npx create-next-app@latest` with the following options:\n   - Use TypeScript: Yes\n   - Use ESLint: Yes\n   - Use Tailwind CSS: Yes\n   - Use App Router: Yes\n   - Set up import aliases: Yes (use '@/' as the import alias)\n2. Install shadcn/ui using `npx shadcn-ui@latest init` with the following configuration:\n   - Style: Default\n   - Base color: Slate\n   - Global CSS file: app/globals.css\n   - CSS variables: Yes\n   - React Server Components: Yes\n   - Components directory: components/ui\n   - Utility directory: lib/utils\n3. Install essential dependencies: `npm install clsx tailwindcss-animate class-variance-authority lucide-react`\n4. Configure the Tailwind CSS theme in tailwind.config.js to include proper breakpoints and initial color schemes\n5. Set up a basic layout structure with app/layout.tsx\n6. Test the setup by running `npm run dev` and verifying the application loads correctly\n7. Commit the initial project setup",
          "status": "done",
          "parentTaskId": 1
        },
        {
          "id": 2,
          "title": "Configure Turborepo Structure with Design System",
          "description": "Set up Turborepo monorepo structure with packages for UI components, utilities, types, and functions, including design token configuration",
          "dependencies": [
            1
          ],
          "details": "Implementation details:\n1. Install Turborepo: `npm install turbo --save-dev`\n2. Create a Turborepo configuration by adding turbo.json to the root with initial pipeline configuration\n3. Create the following package directories:\n   - packages/ui: For shared UI components\n   - packages/utils: For utility functions\n   - packages/types: For TypeScript type definitions\n   - packages/functions: For shared business logic\n4. Set up package.json files in each package directory with appropriate dependencies\n5. Create styleGuide.ts in packages/ui with design tokens for:\n   - Colors (primary, secondary, accent, neutral, error, warning, success)\n   - Typography (font families, sizes, weights, line heights)\n   - Spacing (consistent spacing scale)\n   - Breakpoints (mobile, tablet, desktop, etc.)\n   - Shadows and elevations\n   - Border radiuses\n6. Configure ESLint with a custom no-literal-style rule to enforce usage of design tokens:\n   - Install required ESLint plugins: `npm install eslint-plugin-custom --save-dev`\n   - Create a custom ESLint rule in .eslintrc.js that checks for hardcoded style values\n7. Set up tsconfig.json files for proper path resolution between packages\n8. Create example components in packages/ui that use the design tokens\n9. Test the monorepo setup by importing components and tokens in the main app\n10. Document the design system usage in a README.md file",
          "status": "done",
          "parentTaskId": 1
        },
        {
          "id": 3,
          "title": "Set up Supabase Integration with Type Generation",
          "description": "Configure Supabase project with authentication, database, and storage, including TypeScript type generation for database schema",
          "dependencies": [
            1,
            2
          ],
          "details": "Implementation details:\n1. Create a new Supabase project through the Supabase dashboard\n2. Install Supabase client libraries: `npm install @supabase/supabase-js @supabase/auth-helpers-nextjs`\n3. Set up environment variables in .env.local:\n   - NEXT_PUBLIC_SUPABASE_URL=your-project-url\n   - NEXT_PUBLIC_SUPABASE_ANON_KEY=your-anon-key\n   - SUPABASE_SERVICE_ROLE_KEY=your-service-role-key (for secure server operations)\n4. Create a lib/supabase/client.ts file to initialize the Supabase client\n5. Set up server-side Supabase client in lib/supabase/server.ts using createServerComponentClient\n6. Configure Supabase Auth with initial settings:\n   - Enable email/password authentication\n   - Set up OAuth providers if needed\n   - Configure email templates\n7. Enable pgvector extension in the Supabase database:\n   - Run SQL command: `CREATE EXTENSION IF NOT EXISTS vector;`\n8. Install Supabase CLI for local development: `npm install supabase --save-dev`\n9. Initialize Supabase locally: `npx supabase init`\n10. Generate TypeScript types from the database schema:\n    - Run `npx supabase gen types typescript --local > packages/types/db.ts`\n11. Create a basic database migration script for initial schema\n12. Set up Supabase Storage buckets for file uploads with appropriate security rules\n13. Configure Supabase Realtime features for required tables\n14. Create helper functions in packages/functions for common Supabase operations\n15. Test the Supabase integration with a simple authentication flow\n16. Document the Supabase setup and usage patterns in a README.md file\n17. Ensure all configurations align with FERPA/GDPR requirements by implementing proper data access controls",
          "status": "done",
          "parentTaskId": 1
        }
      ]
    },
    {
      "id": 2,
      "title": "Authentication and User Management",
      "description": "Implement authentication system with Supabase Auth and set up role-based access control for all user types",
      "status": "done",
      "dependencies": [
        1
      ],
      "priority": "high",
      "details": "Configure Supabase Auth with invite code-based authentication and username/password login using pseudo-emails. Create sign-up with invite code, sign-in, custom password reset, and profile management flows. Implement role-based access control for Super Admin, Admin, Teacher, Student, and Parent roles. Set up middleware to validate authentication on protected routes. Create the members table with role enum and configure RLS policies based on user roles and organization_id. Implement user profile management with avatar upload functionality.\n\n**PRD Context**\n- Authentication: Implement invite code-based signup and username/password login using pseudo-emails\n- Multi-organization tenancy structure: Organization -> School -> Class hierarchy\n- Role management: Support role assignment and switching between roles\n- Parent-child linking: Allow parents to be linked to their children's accounts\n- Custom password reset: Implement password reset flow using invite codes\n- Admin capabilities: Enable user management including invite, bulk import, role changes, and account deactivation\n- Compliance: Ensure adherence to FERPA, GDPR, and COPPA regulations\n- Security: Implement Row-Level Security (RLS) and tenant isolation to protect user data based on organisation_id and role\n- User profiles: Support profile creation and management with appropriate permissions",
      "testStrategy": "Test user registration with invite codes, login with username/password, and custom password reset flows. Verify role-based access control by attempting to access routes with different user roles. Ensure RLS policies correctly restrict access to data based on user role and organisation_id. Test the two-step signup process (code verification, credential submission). Verify multi-org tenancy isolation works correctly. Test parent-child account linking functionality. Validate admin user management capabilities including invites, bulk imports, and role changes. Ensure compliance with privacy regulations through appropriate data handling and permissions.",
      "subtasks": [
        {
          "id": 1,
          "title": "Implement Supabase Edge Function /sign-up-with-code",
          "description": "Create Edge Function to validate invite code, create auth user with pseudo-email, mark code redeemed, and create profile record with username, name, grade level.",
          "details": "",
          "status": "done",
          "dependencies": [],
          "parentTaskId": 2
        },
        {
          "id": 2,
          "title": "Implement Frontend Signup UI (2-step)",
          "description": "Create frontend components for 2-step signup: 1) Verify invite code via API route. 2) Submit username, password, first name, last name, grade level via API route to trigger Edge Function.",
          "details": "",
          "status": "done",
          "dependencies": [],
          "parentTaskId": 2
        },
        {
          "id": 3,
          "title": "Implement Frontend Login UI",
          "description": "Create login form for username/password. Construct pseudo-email (<username>@<org-id>.internal - requires fetching org abbr from profile) and call Supabase signInWithPassword.",
          "details": "",
          "status": "done",
          "dependencies": [],
          "parentTaskId": 2
        },
        {
          "id": 4,
          "title": "Implement RLS Policies",
          "description": "Define RLS policies for profiles and invite_codes based on authenticated user's organisation_id and \role extracted from JWT.",
          "details": "",
          "status": "done",
          "dependencies": [],
          "parentTaskId": 2
        },
        {
          "id": 5,
          "title": "Implement Custom Password Reset Flow",
          "description": "Develop a password reset mechanism (e.g., using unique tokens sent via email or another method) as standard Supabase reset won't work with pseudo-emails.",
          "details": "",
          "status": "done",
          "dependencies": [],
          "parentTaskId": 2
        },
        {
          "id": 6,
          "title": "Update Profile Management UI/Logic",
          "description": "Modify profile editing UI and backend logic to read/write \first_name, last_name, grade_level to the profiles table.",
          "details": "",
          "status": "done",
          "dependencies": [],
          "parentTaskId": 2
        }
      ]
    },
    {
      "id": 3,
      "title": "Core Database Schema Implementation",
      "description": "Design and implement the core database schema with proper relationships and RLS policies",
      "status": "done",
      "dependencies": [
        2
      ],
      "priority": "high",
      "details": "Create the following tables: organisations, members, base_classes, class_instances, rosters, paths, lessons, lesson_sections, quizzes, questions, submissions, notebooks, mind_maps, achievements, certificates, audit_logs, ui_contexts. Configure pgvector extension for embeddings. Set up foreign key relationships and indexes. Implement RLS policies for each table based on user roles. Create triggers for timestamps, enrollment codes, and audit logging. Set up materialized views for frequently accessed data like enrollment_code_lookup.\n\n**PRD Context**\n\n**Database Technology**:\n- Implement using Supabase Postgres database\n- Configure pgvector extension for vector embeddings storage and similarity search\n\n**Core Schema Requirements**:\n\n1. **Multi-tenancy Structure**:\n   - Organizations (top-level tenants)\n   - Schools (sub-organizations)\n   - Classes (learning groups)\n\n2. **Authentication & Users**:\n   - User accounts with role-based permissions\n   - Member profiles with organization affiliations\n   - Role definitions (admin, teacher, student, etc.)\n\n3. **Knowledge Base**:\n   - Files storage and metadata\n   - Content chunks for granular access\n   - Vector embeddings for semantic search\n   - Tagging and categorization system\n\n4. **Course Structure**:\n   - Base Classes (templates)\n   - Class Instances (actual classes)\n   - Learning Paths\n   - Modules and Units\n   - Lessons and Sections\n\n5. **Assessment System**:\n   - Quizzes and Tests\n   - Question banks with various formats\n   - Grading and feedback mechanisms\n\n6. **Progress Tracking**:\n   - Mastery levels\n   - Grade records\n   - Completion status\n\n7. **Study Space Components**:\n   - Notebooks\n   - Mind Maps\n   - Interactive elements\n\n8. **Interoperability**:\n   - LTI integration support\n   - OneRoster compatibility\n   - Caliper analytics framework\n\n9. **Security & Auditing**:\n   - Row-Level Security (RLS) policies\n   - Audit logging\n   - Data access controls",
      "testStrategy": "Verify all tables are created with correct columns and relationships. Test RLS policies by attempting to access data with different user roles. Ensure triggers work correctly by inserting test data and checking the results. Validate that the schema supports all requirements outlined in the PRD Context, including multi-tenancy, knowledge base with vector embeddings, course structures, and interoperability standards. Test performance of common queries across related tables and verify that RLS policies correctly restrict data access based on organizational boundaries and user roles.",
      "subtasks": [
        {
          "id": 1,
          "title": "Create Foundational Tables and Extensions",
          "description": "Set up the pgvector extension and implement the core organizational and user-related tables with their relationships",
          "dependencies": [],
          "details": "1. Enable the pgvector extension in the Supabase Postgres database\n2. Create the following tables with appropriate columns and constraints:\n   - organisations (id, name, domain, settings, created_at, updated_at)\n   - members (id, auth_id, email, first_name, last_name, organisation_id, role, settings, created_at, updated_at)\n   - base_classes (id, name, description, organisation_id, settings, created_at, updated_at)\n   - class_instances (id, base_class_id, name, enrollment_code, start_date, end_date, settings, created_at, updated_at)\n   - rosters (id, class_instance_id, member_id, role, joined_at, settings, created_at, updated_at)\n   - audit_logs (id, table_name, record_id, action, old_data, new_data, performed_by, created_at)\n3. Set up foreign key relationships between these tables\n4. Create indexes for frequently queried columns\n5. Implement triggers for:\n   - Automatic timestamps (created_at, updated_at)\n   - Generating enrollment codes for class_instances\n   - Audit logging for all tables\n6. Create a materialized view for enrollment_code_lookup\n7. Test table creation with sample data insertion\n8. Verify foreign key constraints are working properly\n9. Test the audit logging functionality",
          "status": "done",
          "parentTaskId": 3
        },
        {
          "id": 2,
          "title": "Implement Content and Learning Structure Tables",
          "description": "Create tables for learning content, paths, and assessment components with their relationships",
          "dependencies": [
            1
          ],
          "details": "1. Create the following tables with appropriate columns and constraints:\n   - paths (id, name, description, organisation_id, settings, created_at, updated_at)\n   - lessons (id, path_id, title, description, order_index, settings, created_at, updated_at)\n   - lesson_sections (id, lesson_id, title, content, order_index, settings, created_at, updated_at)\n   - quizzes (id, lesson_id, title, description, settings, created_at, updated_at)\n   - questions (id, quiz_id, question_text, question_type, options, correct_answer, points, settings, created_at, updated_at)\n   - submissions (id, quiz_id, member_id, answers, score, submitted_at, graded_at, settings, created_at, updated_at)\n2. Set up foreign key relationships between these tables and with the foundational tables\n3. Create indexes for performance optimization\n4. Configure vector columns in relevant tables for content embeddings\n5. Set up triggers for:\n   - Automatic timestamps\n   - Audit logging for all tables\n   - Maintaining order_index values when items are reordered\n6. Test table creation with sample learning content\n7. Verify relationships between paths, lessons, and assessments\n8. Test vector storage and retrieval functionality",
          "status": "done",
          "parentTaskId": 3
        },
        {
          "id": 3,
          "title": "Implement RLS Policies and Study Tools Tables",
          "description": "Create study tool tables and implement Row-Level Security policies for all tables based on user roles",
          "dependencies": [
            1,
            2
          ],
          "details": "1. Create the following tables with appropriate columns and constraints:\n   - notebooks (id, member_id, class_instance_id, title, content, settings, created_at, updated_at)\n   - mind_maps (id, member_id, class_instance_id, title, nodes, edges, settings, created_at, updated_at)\n   - achievements (id, name, description, criteria, organisation_id, settings, created_at, updated_at)\n   - certificates (id, member_id, achievement_id, issued_at, settings, created_at, updated_at)\n   - ui_contexts (id, member_id, context_type, context_data, settings, created_at, updated_at)\n2. Set up foreign key relationships for these tables\n3. Create indexes for performance optimization\n4. Implement RLS policies for each table based on user roles:\n   - Organisation admins can access all data within their organisation\n   - Teachers can access data for their classes and students\n   - Students can access their own data and shared class resources\n   - System admins can access all data\n5. Create helper functions for permission checking\n6. Set up triggers for:\n   - Automatic timestamps\n   - Audit logging\n7. Test RLS policies with different user roles\n8. Verify study tool tables with sample data\n9. Create comprehensive test cases to ensure proper data isolation between organizations and users\n10. Document all tables, relationships, and security policies",
          "status": "done",
          "parentTaskId": 3
        }
      ]
    },
    {
      "id": 4,
      "title": "AppShell and Navigation Implementation",
      "description": "Create the application shell with responsive layout, navigation, and AI panel",
      "status": "done",
      "dependencies": [
        1
      ],
      "priority": "high",
      "details": "Implement the AppShell component with Left Nav (240px/64px collapsed), Main Content area, and AI Chat Panel (320px/hidden). Create responsive navigation that collapses to icons on smaller screens. Implement role-based navigation using navConfig.ts arrays per role. Build the UI Context Provider to track UI state for Luna. Create the header with user menu, theme toggle, and notifications. Implement the AI panel with chat interface placeholder.\n\n**PRD Context**\n- Build the application shell using Next.js 14 architecture with responsive layout components\n- Implement role-aware navigation that adapts to user type:\n  * Course Player sidebar for students\n  * Administrative views for Admin users\n  * Curriculum and student management for Teachers\n  * Student progress monitoring for Parents\n- Create global chat panel with AI assistant integration\n- Implement slash-command palette for quick actions and navigation\n- Integrate theme management system supporting:\n  * Light/dark mode toggle\n  * Organization-level branding overrides\n- Ensure all shell components and navigation elements meet WCAG 2.1 AA accessibility standards",
      "testStrategy": "Test responsive behavior across different screen sizes. Verify navigation shows correct links based on user role. Ensure collapse/expand functionality works for both navigation and AI panel. Test theme switching between light and dark modes. Verify organization branding is correctly applied. Conduct accessibility testing to ensure WCAG 2.1 AA compliance. Test slash-command palette functionality across different user roles.",
      "subtasks": [
        {
          "id": 1,
          "title": "Create AppShell Layout Structure with Responsive Components",
          "description": "Implement the core AppShell component with responsive layout containers for navigation, main content, and AI panel",
          "dependencies": [],
          "details": "1. Create an AppShell component with CSS Grid or Flexbox layout\n2. Implement the Left Nav container with 240px default width and 64px collapsed state\n3. Create the Main Content area with flexible width\n4. Add the AI Chat Panel container with 320px default width and hidden state\n5. Implement responsive breakpoints that adjust layout based on screen size\n6. Create a UI Context Provider with React Context API to track and manage UI state (nav collapsed, panel visibility)\n7. Add event handlers for toggling navigation and panel states\n8. Implement basic accessibility attributes (ARIA roles, landmarks)\n9. Test the responsive behavior across different viewport sizes\n10. Verify that containers resize and reposition correctly on window resize",
          "status": "done",
          "parentTaskId": 4
        },
        {
          "id": 2,
          "title": "Implement Role-Based Navigation System",
          "description": "Build the navigation component with role-based menu items and responsive behavior",
          "dependencies": [
            1
          ],
          "details": "1. Create a navConfig.ts file with navigation arrays for different user roles (Admin, Teacher, Student, Parent)\n2. Implement the Navigation component that renders appropriate items based on user role\n3. Create navigation items with icons, labels, and active states\n4. Add collapsible navigation groups for related items\n5. Implement responsive behavior to show only icons when navigation is collapsed\n6. Add hover effects to display labels when hovering over collapsed nav items\n7. Implement keyboard navigation support for accessibility\n8. Create the header component with user menu dropdown, theme toggle button, and notifications icon\n9. Connect navigation to Next.js router for page transitions\n10. Test navigation rendering for each user role\n11. Verify that active states update correctly based on current route",
          "status": "done",
          "parentTaskId": 4
        },
        {
          "id": 3,
          "title": "Build AI Chat Panel and Theme Integration",
          "description": "Implement the AI assistant panel with chat interface and integrate theme system",
          "dependencies": [
            1,
            2
          ],
          "details": "1. Create the AI Chat Panel component with header, message list, and input area\n2. Implement placeholder chat interface with message bubbles and typing indicators\n3. Add panel toggle button in the application header\n4. Create animation for panel opening/closing\n5. Implement the theme toggle functionality in the header\n6. Set up light/dark mode detection and switching\n7. Create theme context provider for global theme state management\n8. Add CSS variables or styled-components theme for consistent styling\n9. Implement organization branding override capability in the theme system\n10. Create slash-command palette component with keyboard shortcut (Cmd+K/Ctrl+K)\n11. Test theme switching between light and dark modes\n12. Verify that AI panel opens/closes correctly and maintains state\n13. Test keyboard accessibility for all interactive elements",
          "status": "done",
          "parentTaskId": 4
        }
      ]
    },
    {
      "id": 5,
      "title": "Knowledge Base Ingestion System",
      "description": "Implement document upload, processing, chunking, and vector storage system",
      "status": "done",
      "dependencies": [
        3
      ],
      "priority": "high",
      "details": "Create the Knowledge Base UI with FileUploadDropzone and FileListTable components. Implement document upload to Supabase Storage with tenant isolation (org-{id}-uploads buckets). Build document processing pipeline for PDFs, DOCX, PPT, video, audio, and URLs using appropriate libraries (pdf-parse, mammoth, youtube-transcript). Implement chunking algorithm (≤1000 tokens/segment) and generate embeddings using OpenAI's text-embedding-3-small model. Store chunks and metadata in document_chunks table with pgvector. Create API routes for document upload, processing status, and retrieval.\n\n**PRD Context**\n\n**Supported Upload Types:**\n- PDF documents\n- DOCX files\n- PowerPoint presentations (PPT)\n- CSV files\n- Audio files\n- Video files\n- YouTube URLs\n- Web URLs\n\n**Ingestion Pipeline:**\n- Document parsing using appropriate libraries for each file type\n- Text chunking with maximum size of 1000 tokens per segment\n- Vector embedding generation using OpenAI's text-embedding-3-small model\n- Storage in pgvector for efficient similarity search\n- Metadata and tag extraction from documents\n\n**Storage Requirements:**\n- Tenant isolation using org-{id}-uploads bucket structure\n- Secure access controls based on organization membership\n- Tracking of document processing status (queued, processing, completed, error)\n\n**UI Components:**\n- FileUploadDropzone for intuitive document uploading\n- FileListTable for displaying uploaded documents with status and metadata",
      "testStrategy": "Test uploading different file types and verify they are processed correctly. Check that chunks are created with appropriate size and embeddings are generated using the text-embedding-3-small model. Verify vector search works by querying for relevant chunks. Test tenant isolation to ensure documents are only accessible to authorized users within the same organization. Verify processing status is accurately tracked and displayed in the UI.",
      "subtasks": [
        {
          "id": 1,
          "title": "Implement UI Components and Storage Infrastructure",
          "description": "Create the Knowledge Base UI with file upload functionality and set up the Supabase Storage infrastructure with proper tenant isolation.",
          "dependencies": [],
          "details": "Implementation steps:\n1. Create a FileUploadDropzone component that supports drag-and-drop and file selection for all required file types (PDF, DOCX, PPT, CSV, audio, video, YouTube URLs, web URLs).\n2. Implement the FileListTable component to display uploaded documents with their status (queued, processing, completed, error) and metadata.\n3. Set up Supabase Storage buckets with tenant isolation using the org-{id}-uploads naming convention.\n4. Create API routes for document upload that validate file types and store files in the appropriate bucket.\n5. Implement secure access controls based on organization membership.\n6. Add status tracking for uploaded documents in a documents table.\n\nTesting approach:\n- Test UI components in isolation using component testing tools.\n- Verify file upload functionality with different file types.\n- Ensure proper tenant isolation by testing with multiple organizations.\n- Test access controls to confirm only authorized users can access organization files.\n\n<info added on 2025-05-05T03:10:47.321Z>\n## Additional Implementation Details\n\n### UI Components\n- **FileUploadDropzone.tsx**:\n  ```tsx\n  import { useCallback, useState } from 'react'\n  import { useDropzone } from 'react-dropzone'\n  import { Upload, File, AlertCircle } from 'lucide-react'\n  import { Button } from '@/components/ui/button'\n  import { Progress } from '@/components/ui/progress'\n\n  // Accept object for file validation\n  const acceptedFileTypes = {\n    'application/pdf': ['.pdf'],\n    'application/vnd.openxmlformats-officedocument.wordprocessingml.document': ['.docx'],\n    'application/vnd.openxmlformats-officedocument.presentationml.presentation': ['.pptx'],\n    'text/csv': ['.csv'],\n    'audio/*': ['.mp3', '.wav', '.ogg'],\n    'video/*': ['.mp4', '.webm', '.mov']\n  }\n\n  // Size validation (e.g., 50MB max)\n  const MAX_FILE_SIZE = 50 * 1024 * 1024\n  ```\n\n- **FileListTable.tsx**: Implement row-level actions (delete, retry) and status indicators with color coding.\n\n### Database Schema Extensions\n```sql\n-- Add indexes for performance\nCREATE INDEX idx_documents_organisation_id ON documents(organisation_id);\nCREATE INDEX idx_documents_status ON documents(status);\n\n-- Add trigger for updated_at\nCREATE TRIGGER set_updated_at\nBEFORE UPDATE ON documents\nFOR EACH ROW\nEXECUTE FUNCTION trigger_set_timestamp();\n```\n\n### Storage Configuration\n```typescript\n// Helper function to generate storage paths\nexport const getStoragePath = (orgId: string, userId: string, fileName: string): string => {\n  const uuid = crypto.randomUUID()\n  const sanitizedFileName = fileName.replace(/[^a-zA-Z0-9.-]/g, '_')\n  return `${userId}/${uuid}/${sanitizedFileName}`\n}\n\n// Storage bucket policy configuration\nconst bucketPolicy = {\n  name: `org-${orgId}-uploads`,\n  public: false,\n  allowedMimeTypes: ['application/pdf', 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', \n                     'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'text/csv', \n                     'audio/*', 'video/*'],\n  fileSizeLimit: MAX_FILE_SIZE\n}\n```\n\n### URL Processing Logic\n```typescript\n// For YouTube and web URLs\nasync function processUrl(url: string, orgId: string, userId: string) {\n  // Validate URL format\n  const isYouTube = /^(https?:\\/\\/)?(www\\.)?(youtube\\.com|youtu\\.be)\\/.+$/.test(url)\n  \n  // Store URL reference in a JSON file\n  const metadata = {\n    originalUrl: url,\n    type: isYouTube ? 'youtube' : 'webpage',\n    extractionDate: new Date().toISOString()\n  }\n  \n  const jsonContent = JSON.stringify(metadata)\n  const fileName = `${isYouTube ? 'youtube' : 'webpage'}_${Date.now()}.json`\n  \n  // Upload JSON reference file to storage\n  // Then create document record with appropriate metadata\n}\n```\n\n### Error Handling and Retry Logic\n```typescript\n// Implement exponential backoff for retries\nconst MAX_RETRIES = 3\nasync function uploadWithRetry(file, path, retryCount = 0) {\n  try {\n    return await supabaseClient.storage.from(bucketName).upload(path, file)\n  } catch (error) {\n    if (retryCount < MAX_RETRIES) {\n      const delay = Math.pow(2, retryCount) * 1000\n      await new Promise(resolve => setTimeout(resolve, delay))\n      return uploadWithRetry(file, path, retryCount + 1)\n    }\n    throw error\n  }\n}\n```\n\n### Realtime Updates Implementation\n```typescript\n// In the client component\nuseEffect(() => {\n  const channel = supabase\n    .channel('document-status-changes')\n    .on('postgres_changes', \n      { event: 'UPDATE', schema: 'public', table: 'documents', filter: `organisation_id=eq.${orgId}` },\n      (payload) => {\n        // Update document status in the UI\n        setDocuments(current => current.map(doc => \n          doc.id === payload.new.id ? { ...doc, ...payload.new } : doc\n        ))\n      }\n    )\n    .subscribe()\n\n  return () => { supabase.removeChannel(channel) }\n}, [orgId, supabase])\n```\n</info added on 2025-05-05T03:10:47.321Z>",
          "status": "done",
          "parentTaskId": 5
        },
        {
          "id": 2,
          "title": "Build Document Processing Pipeline",
          "description": "Implement the document processing pipeline to extract text from various file formats using appropriate libraries.",
          "dependencies": [
            1
          ],
          "details": "Implementation steps:\n1. Create a document processing service that handles different file types:\n   - PDF documents: Use pdf-parse library\n   - DOCX files: Use mammoth library\n   - PowerPoint presentations: Implement PPT parsing\n   - CSV files: Use CSV parsing libraries\n   - Audio files: Implement audio transcription\n   - Video files: Extract audio and transcribe\n   - YouTube URLs: Use youtube-transcript API\n   - Web URLs: Implement web scraping\n2. Set up a queue system for processing documents asynchronously.\n3. Implement status updates to track document processing progress.\n4. Extract metadata (title, author, date, etc.) from documents when available.\n5. Create API routes to check document processing status.\n6. Implement error handling and retries for failed processing attempts.\n\nTesting approach:\n- Test each parser with various sample files of the corresponding type.\n- Verify correct text extraction from different file formats.\n- Test the queue system with multiple simultaneous uploads.\n- Ensure proper status updates throughout the processing pipeline.\n- Test error handling with malformed or corrupted files.\n<info added on 2025-05-05T15:49:51.280Z>\nImplementation steps:\n1. Create a document processing service that handles different file types:\n   - PDF documents: Use pdf-parse library\n   - DOCX files: Use mammoth library\n   - PowerPoint presentations: Implement PPT parsing\n   - CSV files: Use CSV parsing libraries\n   - Audio files: Implement audio transcription\n   - Video files: Extract audio and transcribe\n   - YouTube URLs: Use youtube-transcript API\n   - Web URLs: Implement web scraping\n2. Set up a queue system for processing documents asynchronously.\n3. Implement status updates to track document processing progress.\n4. Extract metadata (title, author, date, etc.) from documents when available.\n5. Create API routes to check document processing status.\n6. Implement error handling and retries for failed processing attempts.\n\nTesting approach:\n- Test each parser with various sample files of the corresponding type.\n- Verify correct text extraction from different file formats.\n- Test the queue system with multiple simultaneous uploads.\n- Ensure proper status updates throughout the processing pipeline.\n- Test error handling with malformed or corrupted files.\n\nTechnical Implementation Plan:\n\n1. Dependencies Installation:\n   - In packages/functions directory, install required libraries:\n     - Core parsing: pdf-parse, mammoth, youtube-transcript\n     - Database: @supabase/supabase-js\n     - TypeScript types: @types/pdf-parse, @types/mammoth\n   - Additional libraries for other formats will be added during implementation\n\n2. Database Schema Updates:\n   - Create migration for documents table:\n     - Add document_status ENUM ('queued', 'processing', 'completed', 'error')\n     - Add status column (type: document_status, default: 'queued', NOT NULL)\n     - Add processing_error column (type: TEXT, nullable)\n     - Add metadata column (type: JSONB, nullable) for extracted document metadata\n\n3. Supabase Edge Function Implementation:\n   - Create process-document function in packages/functions/src/process-document/index.ts\n   - Function will:\n     - Accept documentId in payload\n     - Update document status to 'processing'\n     - Download file from appropriate storage bucket\n     - Determine file type and route to appropriate parser\n     - Implement parsers for PDF, DOCX, YouTube URLs initially\n     - Store extracted text\n     - Update status to 'completed' or 'error' with details\n\n4. Document Processing Flow:\n   - Upload API (src/app/api/knowledge-base/upload/route.ts) will:\n     - Create documents record with 'queued' status\n     - Upload file to storage\n     - Directly invoke process-document function with documentId\n   - This approach avoids complex storage trigger configuration\n\n5. Frontend Updates:\n   - Update FileListTable.tsx to display new status values\n   - Add tooltips for error messages\n   - Ensure API routes return status and error information\n\nThis implementation leverages Supabase for both storage and serverless functions, creating an asynchronous document processing pipeline that can handle various file formats while providing status updates throughout the process.\n</info added on 2025-05-05T15:49:51.280Z>",
          "status": "done",
          "parentTaskId": 5
        },
        {
          "id": 3,
          "title": "Implement Chunking, Embedding Generation, and Vector Storage",
          "description": "Create the chunking algorithm, generate embeddings using OpenAI's model, and store chunks with vector embeddings in the database.",
          "dependencies": [
            2
          ],
          "details": "Implementation steps:\n1. Implement a chunking algorithm that splits document text into segments of ≤1000 tokens each, preserving context where possible.\n2. Create a service to generate embeddings for each chunk using OpenAI's text-embedding-3-small model.\n3. Set up the document_chunks table with pgvector extension to store chunks and their vector embeddings.\n4. Store metadata with each chunk (source document, position in document, etc.).\n5. Implement batch processing for efficient embedding generation of multiple chunks.\n6. Create API routes for retrieving document chunks and performing vector similarity searches.\n7. Add functionality to update the document status to 'completed' when all chunks are processed.\n\nTesting approach:\n- Test the chunking algorithm with various text lengths and formats.\n- Verify that chunks maintain appropriate context and don't exceed token limits.\n- Test embedding generation with different types of content using the text-embedding-3-small model.\n- Benchmark vector storage and retrieval performance.\n- Test end-to-end flow from document upload to searchable vector embeddings.\n- Verify that similarity searches return relevant results.",
          "status": "done",
          "parentTaskId": 5
        }
      ]
    },
    {
      "id": 6,
      "title": "Luna Context Engine Implementation",
      "description": "Build the real-time UI context tracking and agentic action system",
      "status": "done",
      "dependencies": [
        4
      ],
      "priority": "medium",
      "details": "Implement the UIContextProvider that registers UI components and tracks their state. Create useUIContext hook for components to register themselves with metadata including role, route, type, props, and visibility flags. Build the context serialization system that creates snapshots of UI state. Implement BroadcastChannel and postMessage communication with AI Chat Panel. Create debounced POST to /api/ui-state endpoint that stores context in ui_contexts table with vector embeddings. Implement intent inference system that analyzes context and suggests actions.\n\n**PRD Context**\n\n- **Component Self-Registration**: Implement the useUIContext hook that allows UI components to register themselves with the context engine, providing metadata about their role, route, type, props, and visibility state.\n\n- **Real-time UI Snapshots**: Develop a system to create and store snapshots of the current UI state in the ui_contexts table, including vector embeddings for efficient retrieval and analysis.\n\n- **Intent Inference**: Build a system that analyzes the current UI context to infer user intent and suggest appropriate actions, which will lead to agentic RPC/Edge function calls.\n\n- **UI Mutation Broadcasting**: Implement real-time broadcasting of UI mutations to ensure all components stay synchronized with the latest state changes.",
      "testStrategy": "Verify components correctly register with UIContextProvider. Test context serialization by checking snapshots contain expected data. Ensure context updates are properly debounced and stored in the database. Validate that intent inference correctly suggests appropriate actions based on UI context. Test the real-time broadcasting system to confirm UI mutations are properly synchronized across components.",
      "subtasks": [
        {
          "id": 1,
          "title": "Implement UIContextProvider and useUIContext Hook",
          "description": "Create the core context tracking system with component self-registration capabilities",
          "dependencies": [],
          "details": "1. Create a React context (UIContext) with a provider component (UIContextProvider)\n2. Implement the useUIContext hook that allows components to register themselves with metadata\n3. Design the registration data structure to include component role, route, type, props, and visibility flags\n4. Add methods to track component mounting, unmounting, and state changes\n5. Implement a registry to maintain the current set of active UI components\n6. Add debug utilities to inspect the current context state\n7. Test by creating sample components that register with the context system and verify proper tracking of their lifecycle and state changes",
          "status": "done",
          "parentTaskId": 6
        },
        {
          "id": 2,
          "title": "Build Context Serialization and Storage System",
          "description": "Implement the system to create UI state snapshots and store them with vector embeddings",
          "dependencies": [
            1
          ],
          "details": "1. Create a serialization function that converts the UI context registry to a structured JSON snapshot\n2. Implement debounced context snapshot generation to avoid excessive processing\n3. Set up BroadcastChannel for communication with the AI Chat Panel\n4. Create a POST endpoint at /api/ui-state to receive context snapshots\n5. Implement database operations to store snapshots in the ui_contexts table\n6. Add vector embedding generation for the context data to enable semantic search\n7. Implement proper error handling and retry mechanisms\n8. Test the serialization by generating snapshots of different UI states and verifying the data structure\n9. Test the storage system by confirming snapshots are properly saved to the database with embeddings\n<info added on 2025-05-06T01:59:32.233Z>\n1. Create a serialization function that converts the UI context registry to a structured JSON snapshot\n2. Implement debounced context snapshot generation to avoid excessive processing\n3. Set up BroadcastChannel for communication with the AI Chat Panel\n4. Implement sessionStorage for temporary persistence of context data\n5. Create a mechanism to pass context data to the chat interface when needed\n6. Implement proper error handling for serialization edge cases\n7. Test the serialization by generating snapshots of different UI states and verifying the data structure\n8. Test the communication system by confirming snapshots are properly passed between components\n9. Integrate the context serialization system within LunaContextProvider\n10. Implement a strategy to handle context updates and broadcasts efficiently\n</info added on 2025-05-06T01:59:32.233Z>",
          "status": "done",
          "parentTaskId": 6
        },
        {
          "id": 3,
          "title": "Develop Intent Inference and Action System",
          "description": "Create the system that analyzes UI context to infer user intent and suggest actions",
          "dependencies": [
            1,
            2
          ],
          "details": "1. Design an intent inference algorithm that analyzes the current UI context\n2. Create a mapping between recognized patterns in UI state and potential user intents\n3. Implement an action suggestion system that proposes relevant actions based on inferred intent\n4. Build the mechanism for executing agentic RPC/Edge function calls based on suggested actions\n5. Implement UI mutation broadcasting to synchronize components after state changes\n6. Create an API for components to subscribe to relevant context changes\n7. Add a feedback mechanism to improve intent inference accuracy over time\n8. Test by simulating various UI states and verifying that appropriate intents and actions are inferred\n9. Test the execution of suggested actions and verify that UI components properly respond to broadcasts",
          "status": "done",
          "parentTaskId": 6
        }
      ]
    },
    {
      "id": 7,
      "title": "AI Chat Panel and Integration",
      "description": "Implement the AI assistant chat interface with context-aware responses",
      "status": "done",
      "dependencies": [
        5,
        6
      ],
      "priority": "medium",
      "details": "Build the AI Chat Panel UI with chat thread, input box, and persona tabs (Tutor, Peer Buddy, Exam Coach). Implement streaming responses from OpenAI GPT-4.1-mini with proper error handling. Create context-aware prompting that incorporates UI state from Luna and relevant knowledge base content. Implement citation display for knowledge base references. Build the chat history storage and retrieval system. Create API routes for chat interactions with proper RLS enforcement.\n\n**PRD Context**\n\n**Global Chat Panel Requirements:**\n- Implement a global chat panel supporting both text and voice input\n- Integrate slash-command palette for quick actions\n- Route commands via GPT functions to appropriate domain RPCs\n- Display inline citations and source links for referenced content\n\n**AI Tutor Chat Functionality:**\n*For Teachers:*\n- Class-level chat capabilities\n- Persona switching between different AI assistant roles\n- Ability to pin resources for student reference\n\n*For Students:*\n- 24/7 contextual help based on current learning materials\n- Access to citation links for further exploration of topics",
      "testStrategy": "Test chat interactions with different personas. Verify streaming responses work correctly. Check that context-aware prompting incorporates relevant UI state and knowledge base content. Ensure citations are displayed correctly for knowledge base references. Test voice input functionality and slash-command palette integration. Verify that teacher-specific and student-specific features work as expected. Test citation links and source references for accuracy.",
      "subtasks": [
        {
          "id": 1,
          "title": "Build AI Chat Panel UI Components",
          "description": "Implement the core UI components for the AI chat interface including the chat thread, input box, and persona tabs",
          "dependencies": [],
          "details": "Implementation steps:\n1. Create a responsive chat panel component that can be toggled globally\n2. Implement the chat thread display with support for markdown, code blocks, and citations\n3. Build the message input box with text input and voice input capabilities\n4. Create persona tab switcher for Tutor, Peer Buddy, and Exam Coach roles\n5. Implement slash-command palette UI with autocomplete functionality\n6. Add loading/typing indicators for streaming responses\n7. Design error state displays for network issues or rate limiting\n\nTesting approach:\n- Unit test individual UI components\n- Test responsive behavior across device sizes\n- Verify accessibility compliance (keyboard navigation, screen reader support)\n- Test UI state management with mock chat data",
          "status": "done",
          "parentTaskId": 7
        },
        {
          "id": 2,
          "title": "Implement OpenAI Integration with Streaming Responses",
          "description": "Set up the backend API routes and frontend logic to handle streaming responses from OpenAI GPT-4.1-mini",
          "dependencies": [
            1
          ],
          "details": "Implementation steps:\n1. Create API routes for chat interactions with proper RLS enforcement\n2. Implement OpenAI client configuration with GPT-4.1-mini model\n3. Set up streaming response handling on the backend\n4. Build frontend logic to process and display streaming chunks\n5. Implement proper error handling for API failures, timeouts, and rate limits\n6. Add retry logic for transient failures\n7. Create context-building function that incorporates UI state from Luna\n8. Implement function calling for slash commands\n\nTesting approach:\n- Unit test API routes with mock OpenAI responses\n- Test streaming functionality with various response lengths\n- Verify error handling with simulated failures\n- Load test with concurrent requests\n- Test context building with different UI states",
          "status": "done",
          "parentTaskId": 7
        },
        {
          "id": 3,
          "title": "Implement Context-Aware Prompting and Chat History",
          "description": "Build the system for context-aware prompting with knowledge base integration and implement chat history storage and retrieval",
          "dependencies": [
            1,
            2
          ],
          "details": "Implementation steps:\n1. Design database schema for storing chat history\n2. Implement chat history storage and retrieval system with proper user scoping\n3. Create context-aware prompting system that incorporates:\n   - Current UI state from Luna\n   - Relevant knowledge base content\n   - User's recent interactions\n   - Selected AI persona\n4. Build citation display system for knowledge base references\n5. Implement knowledge base content retrieval and embedding\n6. Add functionality for teachers to pin resources for student reference\n7. Create system for persisting chat context across sessions\n\nTesting approach:\n- Unit test database operations for chat history\n- Test context building with various knowledge base inputs\n- Verify citation generation and display\n- Test persistence across user sessions\n- Verify proper scoping of chat history by user role",
          "status": "done",
          "parentTaskId": 7
        }
      ]
    },
    {
      "id": 8,
      "title": "Base Class and Instance Management",
      "description": "Implement the core class management system for teachers",
      "status": "done",
      "dependencies": [
        3,
        4
      ],
      "priority": "high",
      "details": "Create the BaseClassCardGrid component for /teach/base-classes route. Implement CreateBaseClassModal with form validation. Build the BaseClassDetail view with StructureTabs (Paths, Lessons, Quizzes) and InstanceTable. Create the InstanceListTable for /teach/instances route with enrollment code display and management. Implement the class instance creation, editing, and archiving functionality. Build the enrollment code generation system with the join_class_by_code RPC function. Create API routes for base class and instance management with proper RLS enforcement.\n\n**PRD Context**\n\n*Base Class Management*\n- Teachers can create Base Classes from blank or using a wizard\n- Teachers can edit Base Class metadata (name, description, etc.)\n- Teachers can delete or archive Base Classes\n- Teachers can clone existing Base Classes\n\n*Class Instance Management*\n- Teachers can create Class Instances from any Base Class\n- System automatically generates unique enrollment codes for each Class Instance\n- Teachers can set dates, period, and capacity for Class Instances\n- Teachers can archive Class Instances\n- Teachers can bulk-copy content between Class Instances",
      "testStrategy": "Test creating, editing, and archiving base classes and instances. Verify enrollment codes are generated correctly. Test the join_class_by_code function with valid and invalid codes. Ensure RLS policies correctly restrict access to base classes and instances.",
      "subtasks": [
        {
          "id": 1,
          "title": "Implement BaseClassCardGrid and CreateBaseClassModal",
          "description": "Create the BaseClassCardGrid component for displaying base classes and implement the CreateBaseClassModal with form validation for creating new base classes.",
          "dependencies": [],
          "details": "1. Create a BaseClassCardGrid component that displays base classes in a grid layout on the /teach/base-classes route.\n2. Implement card components that show base class name, description, creation date, and action buttons (edit, delete, archive, clone).\n3. Add filtering and sorting capabilities to the grid.\n4. Create a CreateBaseClassModal component with a form that includes fields for name, description, subject, grade level, etc.\n5. Implement form validation using a library like Formik or React Hook Form.\n6. Connect the modal to API endpoints for creating base classes with proper RLS enforcement.\n7. Add success/error notifications for user feedback.\n8. Test the grid rendering with various data states (empty, few items, many items).\n9. Test form validation with valid and invalid inputs.\n10. Test API integration with mock data.\n<info added on 2025-05-07T00:37:47.306Z>\n1. Create a BaseClassCardGrid component that displays base classes in a grid layout on the /teach/base-classes route.\n2. Implement card components that show base class name, description, creation date, and action buttons (edit, delete, archive, clone).\n3. Add filtering and sorting capabilities to the grid.\n4. Create a CreateBaseClassModal component with a form that includes fields for name, description, subject, grade level, etc.\n5. Implement form validation using a library like Formik or React Hook Form.\n6. Connect the modal to API endpoints for creating base classes with proper RLS enforcement.\n7. Add success/error notifications for user feedback.\n8. Test the grid rendering with various data states (empty, few items, many items).\n9. Test form validation with valid and invalid inputs.\n10. Test API integration with mock data.\n11. Add a 'Length of Base Class' field to the CreateBaseClassModal that includes:\n   - A range slider component for selecting duration in weeks (range: 1-52 weeks)\n   - Preset buttons/options for common durations:\n     * 'Quarter' (sets slider to 10 weeks)\n     * 'Semester' (sets slider to 16 weeks)\n     * 'Full Year' (sets slider to 38 weeks)\n   - Store the selected number of weeks as the underlying data value\n   - Ensure the form validation includes this field\n   - Update API integration to include this new field when creating base classes\n</info added on 2025-05-07T00:37:47.306Z>",
          "status": "done",
          "parentTaskId": 8
        },
        {
          "id": 2,
          "title": "Build BaseClassDetail view with StructureTabs and Instance Management",
          "description": "Implement the BaseClassDetail view with StructureTabs for organizing content (Paths, Lessons, Quizzes) and add instance management functionality.",
          "dependencies": [
            1
          ],
          "details": "1. Create a BaseClassDetail component that displays detailed information about a selected base class.\n2. Implement StructureTabs component with tabs for Paths, Lessons, and Quizzes.\n3. Build the content area for each tab that displays relevant items and allows for management.\n4. Create an InstanceTable component within the BaseClassDetail to show all instances of the base class.\n5. Implement instance creation functionality with a modal that includes fields for dates, period, capacity, etc.\n6. Add instance editing and archiving capabilities.\n7. Implement the enrollment code generation system that automatically creates unique codes for new instances.\n8. Connect all components to appropriate API endpoints with proper error handling.\n9. Test tab navigation and content display.\n10. Test instance creation, editing, and archiving workflows.\n11. Test enrollment code generation to ensure uniqueness.",
          "status": "done",
          "parentTaskId": 8
        },
        {
          "id": 3,
          "title": "Create InstanceListTable and API Routes for Class Management",
          "description": "Implement the InstanceListTable for the /teach/instances route and create all necessary API routes for base class and instance management with proper RLS enforcement.",
          "dependencies": [
            1,
            2
          ],
          "details": "1. Build the InstanceListTable component for the /teach/instances route that displays all class instances across all base classes.\n2. Include columns for instance name, base class, dates, period, enrollment code, capacity, and actions.\n3. Implement enrollment code display and management features, including code regeneration and copying.\n4. Add filtering and sorting capabilities to the table.\n5. Create API routes for all base class operations (create, read, update, delete, archive, clone).\n6. Implement API routes for instance management (create, read, update, archive).\n7. Create the join_class_by_code RPC function for student enrollment.\n8. Implement proper RLS (Row-Level Security) enforcement to ensure teachers can only access their own classes.\n9. Add bulk-copy functionality to transfer content between class instances.\n10. Test the instance table with various data scenarios.\n11. Test all API routes with appropriate authentication and authorization scenarios.\n12. Verify RLS enforcement by attempting to access unauthorized resources.",
          "status": "done",
          "parentTaskId": 8
        },
        {
          "id": 4,
          "title": "Implement join_class_by_code RPC and Student Enrollment via Code",
          "description": "Create the Supabase RPC function for students to join a class instance using an enrollment code. Implement the necessary API route and UI for students to use this feature.",
          "details": "1. Define and create the `join_class_by_code(p_enrollment_code TEXT)` Supabase RPC function.\n    - Input: `enrollment_code`.\n    - Authenticates the calling student user.\n    - Validates the `enrollment_code` (exists, corresponds to an 'active' or 'upcoming' class instance).\n    - Checks if the student is already enrolled in that class instance.\n    - Checks if the student is part of the same organisation as the class instance.\n    - Checks class capacity.\n    - If all checks pass, creates an enrollment record in `student_enrollments`.\n    - Returns success (with class instance details) or an appropriate error message.\n2. Create an API route (e.g., `POST /api/teach/enrollments/join-by-code`) that students can call. This route will invoke the RPC function.\n3. (Optional - for later UI task) Design and implement a UI component where students can enter an enrollment code.\n4. Ensure RLS policies on `student_enrollments` and `class_instances` correctly interact with the RPC function (RPCs can be set to run with definer's rights or invoker's rights).",
          "status": "done",
          "dependencies": [
            "8.3"
          ],
          "parentTaskId": 8
        }
      ]
    },
    {
      "id": 9,
      "title": "Generative Course Designer",
      "description": "Build the AI-powered course generation and pathway designer",
      "status": "done",
      "dependencies": [
        5,
        8
      ],
      "priority": "medium",
      "details": "Implement the Course Designer UI with SmartCanvas for visualizing course structure. Create the ChatGenerateSidebar for natural language course generation. Build the AI prompt engineering for generating syllabi, learning objectives, and course structure based on knowledge base content. Implement the adaptive sequence generation for creating branching paths. Create the API for storing generated course content in base_classes, paths, and related tables. Build the course editing and iteration functionality through chat interface.\n\n**PRD Context**\n\n- **Natural Language Prompt Interface**: Implement the ChatGenerateSidebar that allows teachers to describe their course needs in natural language, serving as the primary interaction point for course generation.\n\n- **AI Capabilities**: Build systems to generate comprehensive course components including syllabus, learning objectives, learning paths, educational resources, learning activities, timelines, and competency alignments based on the Knowledge Base content.\n\n- **Adaptive Sequence Generation**: Develop functionality for creating branching paths in learning sequences that adapt to different student needs and learning styles.\n\n- **Smart Canvas Auto-arrangement**: Implement the SmartCanvas feature that automatically arranges course elements visually based on natural language prompts, providing an intuitive visualization of course structure.\n\n- **Teacher Interaction Model**: Create a system allowing teachers to accept/reject AI suggestions and iterate on course design through a conversational chat interface, enabling refinement of generated content.",
      "testStrategy": "Test course generation with different prompts and knowledge base content. Verify generated courses have appropriate structure, objectives, and content. Test editing and iteration through the chat interface. Ensure generated content is properly stored in the database. Validate that the SmartCanvas correctly visualizes course structures. Test the adaptive sequence generation for creating appropriate branching paths. Verify that teachers can effectively accept/reject and iterate on AI suggestions.",
      "subtasks": [
        {
          "id": 1,
          "title": "Implement ChatGenerateSidebar with Natural Language Processing Interface",
          "description": "Create the chat-based sidebar interface that allows teachers to describe course needs in natural language and processes these inputs for course generation",
          "dependencies": [],
          "details": "Implementation steps:\n1. Design and build the ChatGenerateSidebar UI component with a chat input field, message history display, and suggestion buttons\n2. Implement the chat message handling system to capture teacher inputs\n3. Create the prompt engineering system to process natural language inputs into structured course generation requests\n4. Build the API service to send processed requests to the AI backend\n5. Implement response handling to display AI suggestions and generation results\n6. Add accept/reject functionality for teachers to provide feedback on suggestions\n7. Create conversation state management to maintain context during iterative design\n\nTesting approach:\n- Unit test the prompt processing functions\n- Test API integration with mock responses\n- Conduct UI testing for chat interactions and state management\n- Verify that user inputs are properly transformed into structured generation requests",
          "status": "done",
          "parentTaskId": 9
        },
        {
          "id": 2,
          "title": "Build AI Course Generation Engine and Database Integration",
          "description": "Develop the core AI functionality to generate course components and implement database storage for generated content",
          "dependencies": [
            1
          ],
          "details": "Implementation steps:\n1. Create AI prompt templates for generating different course components (syllabus, objectives, activities, etc.)\n2. Implement the course structure generation algorithm that produces comprehensive course outlines\n3. Build the branching path generation system for adaptive learning sequences\n4. Develop competency alignment functionality to map course content to learning standards\n5. Create database models and schemas for storing generated course components\n6. Implement API endpoints for saving, retrieving, and updating generated course content\n7. Build the integration between the generation engine and the Knowledge Base to incorporate existing content\n8. Develop validation systems to ensure generated content meets educational standards\n\nTesting approach:\n- Test generation quality with various input prompts\n- Verify database operations for storing and retrieving course components\n- Test integration with Knowledge Base content\n- Validate branching path logic and adaptive sequence generation\n- Benchmark generation performance and optimize as needed",
          "status": "done",
          "parentTaskId": 9
        },
        {
          "id": 3,
          "title": "Implement SmartCanvas for Course Visualization and Editing",
          "description": "Create the visual course structure editor with auto-arrangement capabilities and integrate it with the chat-based iteration system",
          "dependencies": [
            1,
            2
          ],
          "details": "Implementation steps:\n1. Design and implement the SmartCanvas UI component for visualizing course structure\n2. Build the auto-arrangement algorithm that organizes course elements based on relationships and sequence\n3. Create interactive elements for course components (drag, resize, connect, edit)\n4. Implement the visual representation of branching paths and adaptive sequences\n5. Build the integration between SmartCanvas and the ChatGenerateSidebar to visualize changes from chat interactions\n6. Develop the course editing functionality through direct canvas manipulation\n7. Create the synchronization system to keep visual representation and underlying data model consistent\n8. Implement export functionality to generate final course structure for deployment\n\nTesting approach:\n- Test canvas rendering performance with complex course structures\n- Verify auto-arrangement algorithms with different course types\n- Test user interactions for editing and manipulating course elements\n- Validate synchronization between chat-based edits and visual representation\n- Conduct usability testing with teachers to ensure intuitive visualization",
          "status": "done",
          "parentTaskId": 9
        }
      ]
    },
    {
      "id": 10,
      "title": "Lesson Studio Implementation",
      "description": "Create the AI-powered lesson creation and editing system",
      "status": "done",
      "dependencies": [
        9
      ],
      "priority": "medium",
      "details": "Build the Lesson Studio with RichTextEditor component for /teach/lessons/:id route. Implement AI-powered content generation for lesson text, slide decks, and media. Create the MediaAssetsPanel for managing and inserting media. Implement the AI 'insert media' functionality for generating diagrams, animations, and explanations. Build the multimodal accessibility output generation (transcripts, captions, alt-text, TTS audio). Create API routes for lesson creation, editing, and media generation with proper RLS enforcement.\n\n**PRD Context**\n\n**Rich-Text and Block Editor Capabilities:**\n- Implement a comprehensive rich-text editor with block-based content structure\n- Support for headings, paragraphs, lists, tables, code blocks, and embeddable media\n- Allow drag-and-drop rearrangement of content blocks\n- Enable collaborative editing with real-time updates\n\n**AI Features:**\n- 'Insert Media' functionality for generating contextually relevant:\n  - Images and illustrations\n  - Diagrams and charts\n  - Video scripts and storyboards\n- Auto-generation of slide decks from source materials or lesson content\n- Content suggestions and enhancements based on educational best practices\n\n**Version History:**\n- Track all changes to lesson content with timestamps and user attribution\n- Allow viewing and restoring previous versions\n- Implement comparison view between versions\n\n**Export Functionality:**\n- Export lessons as PDF documents\n- Export lessons as DOCX files with formatting preserved\n- Generate presentation-ready slide decks\n\n**Accessibility Outputs:**\n- Automatic generation of:\n  - Transcripts for audio/video content\n  - Captions for multimedia elements\n  - Alt-text for images and diagrams\n  - Text-to-speech audio versions\n  - Sign-language avatar interpretations for key content\n\n**Note:** The core rich-text editing functionality for lesson sections is now primarily being implemented within the BaseClass Studio as Subtask 24.4 (LessonSection Editor Component), which itself refers to Subtask 10.1 for the rich-text editor details.",
      "testStrategy": "Test lesson creation and editing with the RichTextEditor. Verify AI-generated content is appropriate and relevant. Test media generation and insertion. Ensure accessibility outputs are generated correctly. Check that lessons are properly stored in the database. Verify version history tracking works correctly. Test export functionality to PDF and DOCX formats. Validate that all accessibility outputs meet quality standards and accessibility guidelines. Coordinate testing with BaseClass Studio implementation (Subtask 24.4) to ensure consistent functionality.",
      "subtasks": [
        {
          "id": 1,
          "title": "Implement Rich-Text Editor with Block-Based Structure",
          "description": "Create the foundation of the Lesson Studio by implementing a rich-text editor with block-based content structure for the /teach/lessons/:id route",
          "dependencies": [],
          "details": "Implementation steps:\n1. Set up the basic route structure for /teach/lessons/:id\n2. Integrate a rich-text editor library (like Slate.js, Draft.js, or ProseMirror)\n3. Implement block-based content structure supporting:\n   - Headings (H1-H6)\n   - Paragraphs\n   - Lists (ordered and unordered)\n   - Tables\n   - Code blocks\n   - Media placeholders\n4. Add drag-and-drop functionality for block rearrangement\n5. Implement basic save/load functionality with API endpoints:\n   - POST /api/lessons to create new lessons\n   - GET /api/lessons/:id to retrieve lesson content\n   - PUT /api/lessons/:id to update lesson content\n6. Add proper RLS (Row-Level Security) enforcement to ensure users can only access their own lessons\n7. Implement version history tracking with timestamps and user attribution\n\nTesting approach:\n- Unit tests for individual editor components\n- Integration tests for block manipulation and rearrangement\n- API endpoint tests for lesson CRUD operations\n- Security tests to verify RLS enforcement\n<info added on 2025-05-13T12:40:45.363Z>\nImplementation steps:\n1. Set up the basic route structure for /teach/lessons/:id\n2. Integrate a rich-text editor library (like Slate.js, Draft.js, or ProseMirror)\n3. Implement block-based content structure supporting:\n   - Headings (H1-H6)\n   - Paragraphs\n   - Lists (ordered and unordered)\n   - Tables\n   - Code blocks\n   - Media placeholders\n4. Add drag-and-drop functionality for block rearrangement\n5. Implement basic save/load functionality with API endpoints:\n   - POST /api/lessons to create new lessons\n   - GET /api/lessons/:id to retrieve lesson content\n   - PUT /api/lessons/:id to update lesson content\n6. Add proper RLS (Row-Level Security) enforcement to ensure users can only access their own lessons\n7. Implement version history tracking with timestamps and user attribution\n\nTesting approach:\n- Unit tests for individual editor components\n- Integration tests for block manipulation and rearrangement\n- API endpoint tests for lesson CRUD operations\n- Security tests to verify RLS enforcement\n\nDetailed Implementation Plan:\n\n1. Route Structure (/teach/lessons/:id):\n   - Create src/app/(app)/teach/lessons/[id]/page.tsx to host the LessonEditor component\n   - Implement logic to fetch lesson data when an id is present in the URL\n\n2. Rich-Text Editor Library Integration (Tiptap):\n   - Install required packages: @tiptap/react, @tiptap/pm, @tiptap/starter-kit, @tiptap/extension-table, @tiptap/extension-drag-handle\n   - Create src/components/teach/designer/LessonEditor.tsx component\n   - Initialize Tiptap editor using useEditor hook with appropriate configuration\n   - Implement a formatting toolbar with basic styling options\n\n3. Block-Based Content Structure:\n   - Configure StarterKit extension for basic blocks (headings, paragraphs, lists, code blocks)\n   - Add Table extension for table support with row/column operations\n   - Develop custom Tiptap Node for Media Placeholders that includes:\n     - Visual indicator for media insertion points\n     - Attributes for mediaType (image, video) and placeholderText\n\n4. Drag-and-Drop Functionality:\n   - Implement @tiptap/extension-drag-handle for block reordering\n   - Configure drag handles to appear when hovering over content blocks\n\n5. Database Schema and API Endpoints:\n   - Create Supabase tables:\n     - lessons (id, created_at, updated_at, user_id, organisation_id, title, content, base_class_id)\n     - lesson_versions (id, lesson_id, created_at, user_id, content, version_number)\n   - Implement API route handlers:\n     - POST /api/teach/lessons for lesson creation\n     - GET /api/teach/lessons/[id] for lesson retrieval\n     - PUT /api/teach/lessons/[id] for lesson updates\n   - Add client-side logic in LessonEditor.tsx for:\n     - Fetching lesson data on component mount\n     - Implementing save functionality (manual or auto-save with debounce)\n     - Initializing editor with existing or empty content\n\n6. Row-Level Security Implementation:\n   - Configure RLS policies for lessons table:\n     - SELECT: Allow access to own lessons or lessons in user's organization\n     - INSERT: Restrict to creating own lessons\n     - UPDATE/DELETE: Limit to lesson owner\n   - Configure RLS policies for lesson_versions table:\n     - SELECT: Allow access to versions of accessible lessons\n     - INSERT: Restrict to lesson owner\n\n7. Version History Tracking:\n   - Implement automatic version creation on each save operation\n   - Store version metadata including timestamp and user attribution\n   - Create server-side function for atomic version number incrementation\n\nTesting Strategy:\n   - Develop unit tests for editor components and extensions\n   - Create integration tests for block manipulation and content saving\n   - Test API endpoints for proper CRUD operations and error handling\n   - Verify RLS enforcement through multi-user access scenarios\n   - Confirm version history creation and integrity\n</info added on 2025-05-13T12:40:45.363Z>\n<info added on 2025-05-13T13:03:03.871Z>\nImplementation steps:\\n1. Set up the basic route structure for /teach/lessons/:id\\n2. Integrate a rich-text editor library (like Slate.js, Draft.js, or ProseMirror)\\n3. Implement block-based content structure supporting:\\n   - Headings (H1-H6)\\n   - Paragraphs\\n   - Lists (ordered and unordered)\\n   - Tables\\n   - Code blocks\\n   - Media placeholders\\n4. Add drag-and-drop functionality for block rearrangement\\n5. Implement basic save/load functionality with API endpoints:\\n   - POST /api/lessons to create new lessons\\n   - GET /api/lessons/:id to retrieve lesson content\\n   - PUT /api/lessons/:id to update lesson content\\n6. Add proper RLS (Row-Level Security) enforcement to ensure users can only access their own lessons\\n7. Implement version history tracking with timestamps and user attribution\\n\\nTesting approach:\\n- Unit tests for individual editor components\\n- Integration tests for block manipulation and rearrangement\\n- API endpoint tests for lesson CRUD operations\\n- Security tests to verify RLS enforcement\\n<info added on 2025-05-13T12:40:45.363Z>\\nImplementation steps:\\n1. Set up the basic route structure for /teach/lessons/:id\\n2. Integrate a rich-text editor library (like Slate.js, Draft.js, or ProseMirror)\\n3. Implement block-based content structure supporting:\\n   - Headings (H1-H6)\\n   - Paragraphs\\n   - Lists (ordered and unordered)\\n   - Tables\\n   - Code blocks\\n   - Media placeholders\\n4. Add drag-and-drop functionality for block rearrangement\\n5. Implement basic save/load functionality with API endpoints:\\n   - POST /api/lessons to create new lessons\\n   - GET /api/lessons/:id to retrieve lesson content\\n   - PUT /api/lessons/:id to update lesson content\\n6. Add proper RLS (Row-Level Security) enforcement to ensure users can only access their own lessons\\n7. Implement version history tracking with timestamps and user attribution\\n\\nTesting approach:\\n- Unit tests for individual editor components\\n- Integration tests for block manipulation and rearrangement\\n- API endpoint tests for lesson CRUD operations\\n- Security tests to verify RLS enforcement\\n\\nDetailed Implementation Plan:\\n\\n1. Route Structure (/teach/lessons/:id):\\n   - Create src/app/(app)/teach/lessons/[id]/page.tsx to host the LessonEditor component\\n   - Implement logic to fetch lesson data when an id is present in the URL\\n\\n2. Rich-Text Editor Library Integration (Tiptap):\\n   - Install required packages: @tiptap/react, @tiptap/pm, @tiptap/starter-kit, @tiptap/extension-table, @tiptap/extension-drag-handle\\n   - Create src/components/teach/designer/LessonEditor.tsx component\\n   - Initialize Tiptap editor using useEditor hook with appropriate configuration\\n   - Implement a formatting toolbar with basic styling options\\n\\n3. Block-Based Content Structure:\\n   - Configure StarterKit extension for basic blocks (headings, paragraphs, lists, code blocks)\\n   - Add Table extension for table support with row/column operations\\n   - Develop custom Tiptap Node for Media Placeholders that includes:\\n     - Visual indicator for media insertion points\\n     - Attributes for mediaType (image, video) and placeholderText\\n\\n4. Drag-and-Drop Functionality:\\n   - Implement @tiptap/extension-drag-handle for block reordering\\n   - Configure drag handles to appear when hovering over content blocks\\n\\n5. Database Schema and API Endpoints:\\n   - Create Supabase tables:\\n     - lessons (id, created_at, updated_at, user_id, organisation_id, title, content, base_class_id)\\n     - lesson_versions (id, lesson_id, created_at, user_id, content, version_number)\\n   - Implement API route handlers:\\n     - POST /api/teach/lessons for lesson creation\\n     - GET /api/teach/lessons/[id] for lesson retrieval\\n     - PUT /api/teach/lessons/[id] for lesson updates\\n   - Add client-side logic in LessonEditor.tsx for:\\n     - Fetching lesson data on component mount\\n     - Implementing save functionality (manual or auto-save with debounce)\\n     - Initializing editor with existing or empty content\\n\\n6. Row-Level Security Implementation:\\n   - Configure RLS policies for lessons table:\\n     - SELECT: Allow access to own lessons or lessons in user's organization\\n     - INSERT: Restrict to creating own lessons\\n     - UPDATE/DELETE: Limit to lesson owner\\n   - Configure RLS policies for lesson_versions table:\\n     - SELECT: Allow access to versions of accessible lessons\\n     - INSERT: Restrict to lesson owner\\n\\n7. Version History Tracking:\\n   - Implement automatic version creation on each save operation\\n   - Store version metadata including timestamp and user attribution\\n   - Create server-side function for atomic version number incrementation\\n\\nTesting Strategy:\\n   - Develop unit tests for editor components and extensions\\n   - Create integration tests for block manipulation and content saving\\n   - Test API endpoints for proper CRUD operations and error handling\\n   - Verify RLS enforcement through multi-user access scenarios\\n   - Confirm version history creation and integrity\\n</info added on 2025-05-13T12:40:45.363Z>\\n\\n<info added on 2025-05-13T14:15:00.000Z>\\nRevised Implementation Plan Based on JSONB Migration:\\n\\n**Overall Goal:** Implement a rich-text editor for individual lesson sections, using Tiptap, storing content in `lesson_sections.content` (now JSONB), and implement versioning for section content in `lesson_section_versions`.\\n\\n1. **Database Schema (Confirmed via migration `20240513133000_...sql`):**\\n   - `lesson_sections.content` column type is now `JSONB` to store structured editor content\\n   - New table `lesson_section_versions` with:\\n     - `content` (JSONB)\\n     - `member_id` (for attribution)\\n     - `version_number` (auto-incremented by trigger)\\n     - Appropriate RLS policies\\n\\n2. **API Route Handlers Implementation:**\\n   - Create `src/app/api/teach/lessons/[lessonId]/sections/route.ts`:\\n     - `GET`: Retrieve all sections for a lesson, ordered by `order_index`\\n     - `POST`: Create new section with initial content, automatically creating first version\\n   - Create `src/app/api/teach/sections/[sectionId]/route.ts`:\\n     - `GET`: Retrieve specific section by ID\\n     - `PUT`: Update section, saving current content to versions before updating\\n     - `DELETE`: Remove section (with cascade delete for versions)\\n   - Create `src/app/api/teach/sections/[sectionId]/versions/route.ts` (optional):\\n     - `GET`: Retrieve version history for a section\\n\\n3. **Lesson Page Implementation (`src/app/(app)/teach/lessons/[id]/page.tsx`):**\\n   - Fetch all sections for current lesson using API\\n   - Render each section with appropriate component based on `section_type`\\n   - For 'text-editor' sections, render `LessonEditor` component with section data\\n   - Add UI controls for:\\n     - Creating new sections\\n     - Deleting sections\\n     - Reordering sections (update `order_index`)\\n\\n4. **Rich Text Editor Component (`src/components/teach/designer/LessonEditor.tsx`):**\\n   - Accept props: `sectionId`, `initialContent`, `onSave`\\n   - Initialize Tiptap editor with JSON content from `lesson_sections.content`\\n   - Implement save functionality to update section content via API\\n   - Add debounced auto-save functionality\\n   - Enhance toolbar with formatting options\\n\\n5. **Development Sequence:**\\n   - Verify database schema changes\\n   - Implement API route handlers for section management\\n   - Update lesson page to fetch and display sections\\n   - Refine LessonEditor component to work with section-based content\\n   - Implement section management UI (add/delete/reorder)\\n\\n6. **Testing Strategy:**\\n   - Test API endpoints for proper CRUD operations\\n   - Verify section content persistence and versioning\\n   - Test UI for creating, editing, and managing sections\\n   - Confirm RLS policies are correctly enforced\\n   - Verify version history is properly maintained\\n\\nThis revised approach aligns with the new database schema using JSONB for content storage and implements a more modular, section-based lesson structure with proper versioning support.\\n</info added on 2025-05-13T14:15:00.000Z>\n</info added on 2025-05-13T13:03:03.871Z>\n<info added on 2025-05-13T13:15:36.352Z>\nDuring implementation of the API routes for lesson sections, encountered persistent linter errors related to Supabase client initialization in the `src/app/api/teach/lessons/[lessonId]/sections/route.ts` file. The specific issue involves type resolution for `cookieStore.get/set/delete` methods when using @supabase/ssr package with the cookies() function.\n\nAfter multiple attempts to resolve these linter errors, the decision was made to temporarily pause direct fixes for this specific file. The core API logic for fetching user data and calling RPCs appears to be functionally sound, but the Supabase client initialization is causing type-related linter errors.\n\nOptions for proceeding:\n1. Continue implementing other API routes with the current setup, assuming the linter issue is environment-specific and won't affect actual functionality\n2. Await guidance on the correct approach for Supabase client setup in API routes\n3. Consider alternative approaches for user authentication in API routes that might avoid the current typing issues\n\nThe team should decide whether to prioritize fixing these linter errors now or to continue with implementation and address them later as part of a broader solution for Supabase client initialization in API routes.\n</info added on 2025-05-13T13:15:36.352Z>\n<info added on 2025-05-19T01:34:59.930Z>\nImplementation steps:\\n1. Set up the basic route structure for /teach/lessons/:id\\n2. Integrate a rich-text editor library (like Slate.js, Draft.js, or ProseMirror)\\n3. Implement block-based content structure supporting:\\n   - Headings (H1-H6)\\n   - Paragraphs\\n   - Lists (ordered and unordered)\\n   - Tables\\n   - Code blocks\\n   - Media placeholders\\n4. Add drag-and-drop functionality for block rearrangement\\n5. Implement basic save/load functionality with API endpoints:\\n   - POST /api/lessons to create new lessons\\n   - GET /api/lessons/:id to retrieve lesson content\\n   - PUT /api/lessons/:id to update lesson content\\n6. Add proper RLS (Row-Level Security) enforcement to ensure users can only access their own lessons\\n7. Implement version history tracking with timestamps and user attribution\\n\\nTesting approach:\\n- Unit tests for individual editor components\\n- Integration tests for block manipulation and rearrangement\\n- API endpoint tests for lesson CRUD operations\\n- Security tests to verify RLS enforcement\\n<info added on 2025-05-13T12:40:45.363Z>\\nImplementation steps:\\n1. Set up the basic route structure for /teach/lessons/:id\\n2. Integrate a rich-text editor library (like Slate.js, Draft.js, or ProseMirror)\\n3. Implement block-based content structure supporting:\\n   - Headings (H1-H6)\\n   - Paragraphs\\n   - Lists (ordered and unordered)\\n   - Tables\\n   - Code blocks\\n   - Media placeholders\\n4. Add drag-and-drop functionality for block rearrangement\\n5. Implement basic save/load functionality with API endpoints:\\n   - POST /api/lessons to create new lessons\\n   - GET /api/lessons/:id to retrieve lesson content\\n   - PUT /api/lessons/:id to update lesson content\\n6. Add proper RLS (Row-Level Security) enforcement to ensure users can only access their own lessons\\n7. Implement version history tracking with timestamps and user attribution\\n\\nTesting approach:\\n- Unit tests for individual editor components\\n- Integration tests for block manipulation and rearrangement\\n- API endpoint tests for lesson CRUD operations\\n- Security tests to verify RLS enforcement\\n\\nDetailed Implementation Plan:\\n\\n1. Route Structure (/teach/lessons/:id):\\n   - Create src/app/(app)/teach/lessons/[id]/page.tsx to host the LessonEditor component\\n   - Implement logic to fetch lesson data when an id is present in the URL\\n\\n2. Rich-Text Editor Library Integration (Tiptap):\\n   - Install required packages: @tiptap/react, @tiptap/pm, @tiptap/starter-kit, @tiptap/extension-table, @tiptap/extension-drag-handle\\n   - Create src/components/teach/designer/LessonEditor.tsx component\\n   - Initialize Tiptap editor using useEditor hook with appropriate configuration\\n   - Implement a formatting toolbar with basic styling options\\n\\n3. Block-Based Content Structure:\\n   - Configure StarterKit extension for basic blocks (headings, paragraphs, lists, code blocks)\\n   - Add Table extension for table support with row/column operations\\n   - Develop custom Tiptap Node for Media Placeholders that includes:\\n     - Visual indicator for media insertion points\\n     - Attributes for mediaType (image, video) and placeholderText\\n\\n4. Drag-and-Drop Functionality:\\n   - Implement @tiptap/extension-drag-handle for block reordering\\n   - Configure drag handles to appear when hovering over content blocks\\n\\n5. Database Schema and API Endpoints:\\n   - Create Supabase tables:\\n     - lessons (id, created_at, updated_at, user_id, organisation_id, title, content, base_class_id)\\n     - lesson_versions (id, lesson_id, created_at, user_id, content, version_number)\\n   - Implement API route handlers:\\n     - POST /api/teach/lessons for lesson creation\\n     - GET /api/teach/lessons/[id] for lesson retrieval\\n     - PUT /api/teach/lessons/[id] for lesson updates\\n   - Add client-side logic in LessonEditor.tsx for:\\n     - Fetching lesson data on component mount\\n     - Implementing save functionality (manual or auto-save with debounce)\\n     - Initializing editor with existing or empty content\\n\\n6. Row-Level Security Implementation:\\n   - Configure RLS policies for lessons table:\\n     - SELECT: Allow access to own lessons or lessons in user's organization\\n     - INSERT: Restrict to creating own lessons\\n     - UPDATE/DELETE: Limit to lesson owner\\n   - Configure RLS policies for lesson_versions table:\\n     - SELECT: Allow access to versions of accessible lessons\\n     - INSERT: Restrict to lesson owner\\n\\n7. Version History Tracking:\\n   - Implement automatic version creation on each save operation\\n   - Store version metadata including timestamp and user attribution\\n   - Create server-side function for atomic version number incrementation\\n\\nTesting Strategy:\\n   - Develop unit tests for editor components and extensions\\n   - Create integration tests for block manipulation and content saving\\n   - Test API endpoints for proper CRUD operations and error handling\\n   - Verify RLS enforcement through multi-user access scenarios\\n   - Confirm version history creation and integrity\\n</info added on 2025-05-13T12:40:45.363Z>\\n<info added on 2025-05-13T13:03:03.871Z>\\nImplementation steps:\\\\n1. Set up the basic route structure for /teach/lessons/:id\\\\n2. Integrate a rich-text editor library (like Slate.js, Draft.js, or ProseMirror)\\\\n3. Implement block-based content structure supporting:\\\\n   - Headings (H1-H6)\\\\n   - Paragraphs\\\\n   - Lists (ordered and unordered)\\\\n   - Tables\\\\n   - Code blocks\\\\n   - Media placeholders\\\\n4. Add drag-and-drop functionality for block rearrangement\\\\n5. Implement basic save/load functionality with API endpoints:\\\\n   - POST /api/lessons to create new lessons\\\\n   - GET /api/lessons/:id to retrieve lesson content\\\\n   - PUT /api/lessons/:id to update lesson content\\\\n6. Add proper RLS (Row-Level Security) enforcement to ensure users can only access their own lessons\\\\n7. Implement version history tracking with timestamps and user attribution\\\\n\\\\nTesting approach:\\\\n- Unit tests for individual editor components\\\\n- Integration tests for block manipulation and rearrangement\\\\n- API endpoint tests for lesson CRUD operations\\\\n- Security tests to verify RLS enforcement\\\\n<info added on 2025-05-13T12:40:45.363Z>\\\\nImplementation steps:\\\\n1. Set up the basic route structure for /teach/lessons/:id\\\\n2. Integrate a rich-text editor library (like Slate.js, Draft.js, or ProseMirror)\\\\n3. Implement block-based content structure supporting:\\\\n   - Headings (H1-H6)\\\\n   - Paragraphs\\\\n   - Lists (ordered and unordered)\\\\n   - Tables\\\\n   - Code blocks\\\\n   - Media placeholders\\\\n4. Add drag-and-drop functionality for block rearrangement\\\\n5. Implement basic save/load functionality with API endpoints:\\\\n   - POST /api/lessons to create new lessons\\\\n   - GET /api/lessons/:id to retrieve lesson content\\\\n   - PUT /api/lessons/:id to update lesson content\\\\n6. Add proper RLS (Row-Level Security) enforcement to ensure users can only access their own lessons\\\\n7. Implement version history tracking with timestamps and user attribution\\\\n\\\\nTesting approach:\\\\n- Unit tests for individual editor components\\\\n- Integration tests for block manipulation and rearrangement\\\\n- API endpoint tests for lesson CRUD operations\\\\n- Security tests to verify RLS enforcement\\\\n\\\\nDetailed Implementation Plan:\\\\n\\\\n1. Route Structure (/teach/lessons/:id):\\\\n   - Create src/app/(app)/teach/lessons/[id]/page.tsx to host the LessonEditor component\\\\n   - Implement logic to fetch lesson data when an id is present in the URL\\\\n\\\\n2. Rich-Text Editor Library Integration (Tiptap):\\\\n   - Install required packages: @tiptap/react, @tiptap/pm, @tiptap/starter-kit, @tiptap/extension-table, @tiptap/extension-drag-handle\\\\n   - Create src/components/teach/designer/LessonEditor.tsx component\\\\n   - Initialize Tiptap editor using useEditor hook with appropriate configuration\\\\n   - Implement a formatting toolbar with basic styling options\\\\n\\\\n3. Block-Based Content Structure:\\\\n   - Configure StarterKit extension for basic blocks (headings, paragraphs, lists, code blocks)\\\\n   - Add Table extension for table support with row/column operations\\\\n   - Develop custom Tiptap Node for Media Placeholders that includes:\\\\n     - Visual indicator for media insertion points\\\\n     - Attributes for mediaType (image, video) and placeholderText\\\\n\\\\n4. Drag-and-Drop Functionality:\\\\n   - Implement @tiptap/extension-drag-handle for block reordering\\\\n   - Configure drag handles to appear when hovering over content blocks\\\\n\\\\n5. Database Schema and API Endpoints:\\\\n   - Create Supabase tables:\\\\n     - lessons (id, created_at, updated_at, user_id, organisation_id, title, content, base_class_id)\\\\n     - lesson_versions (id, lesson_id, created_at, user_id, content, version_number)\\\\n   - Implement API route handlers:\\\\n     - POST /api/teach/lessons for lesson creation\\\\n     - GET /api/teach/lessons/[id] for lesson retrieval\\\\n     - PUT /api/teach/lessons/[id] for lesson updates\\\\n   - Add client-side logic in LessonEditor.tsx for:\\\\n     - Fetching lesson data on component mount\\\\n     - Implementing save functionality (manual or auto-save with debounce)\\\\n     - Initializing editor with existing or empty content\\\\n\\\\n6. Row-Level Security Implementation:\\\\n   - Configure RLS policies for lessons table:\\\\n     - SELECT: Allow access to own lessons or lessons in user's organization\\\\n     - INSERT: Restrict to creating own lessons\\\\n     - UPDATE/DELETE: Limit to lesson owner\\\\n   - Configure RLS policies for lesson_versions table:\\\\n     - SELECT: Allow access to versions of accessible lessons\\\\n     - INSERT: Restrict to lesson owner\\\\n\\\\n7. Version History Tracking:\\\\n   - Implement automatic version creation on each save operation\\\\n   - Store version metadata including timestamp and user attribution\\\\n   - Create server-side function for atomic version number incrementation\\\\n\\\\nTesting Strategy:\\\\n   - Develop unit tests for editor components and extensions\\\\n   - Create integration tests for block manipulation and content saving\\\\n   - Test API endpoints for proper CRUD operations and error handling\\\\n   - Verify RLS enforcement through multi-user access scenarios\\\\n   - Confirm version history creation and integrity\\\\n</info added on 2025-05-13T12:40:45.363Z>\\\\n\\\\n<info added on 2025-05-13T14:15:00.000Z>\\\\nRevised Implementation Plan Based on JSONB Migration:\\\\n\\\\n**Overall Goal:** Implement a rich-text editor for individual lesson sections, using Tiptap, storing content in `lesson_sections.content` (now JSONB), and implement versioning for section content in `lesson_section_versions`.\\\\n\\\\n1. **Database Schema (Confirmed via migration `20240513133000_...sql`):**\\\\n   - `lesson_sections.content` column type is now `JSONB` to store structured editor content\\\\n   - New table `lesson_section_versions` with:\\\\n     - `content` (JSONB)\\\\n     - `member_id` (for attribution)\\\\n     - `version_number` (auto-incremented by trigger)\\\\n     - Appropriate RLS policies\\\\n\\\\n2. **API Route Handlers Implementation:**\\\\n   - Create `src/app/api/teach/lessons/[lessonId]/sections/route.ts`:\\\\n     - `GET`: Retrieve all sections for a lesson, ordered by `order_index`\\\\n     - `POST`: Create new section with initial content, automatically creating first version\\\\n   - Create `src/app/api/teach/sections/[sectionId]/route.ts`:\\\\n     - `GET`: Retrieve specific section by ID\\\\n     - `PUT`: Update section, saving current content to versions before updating\\\\n     - `DELETE`: Remove section (with cascade delete for versions)\\\\n   - Create `src/app/api/teach/sections/[sectionId]/versions/route.ts` (optional):\\\\n     - `GET`: Retrieve version history for a section\\\\n\\\\n3. **Lesson Page Implementation (`src/app/(app)/teach/lessons/[id]/page.tsx`):**\\\\n   - Fetch all sections for current lesson using API\\\\n   - Render each section with appropriate component based on `section_type`\\\\n   - For 'text-editor' sections, render `LessonEditor` component with section data\\\\n   - Add UI controls for:\\\\n     - Creating new sections\\\\n     - Deleting sections\\\\n     - Reordering sections (update `order_index`)\\\\n\\\\n4. **Rich Text Editor Component (`src/components/teach/designer/LessonEditor.tsx`):**\\\\n   - Accept props: `sectionId`, `initialContent`, `onSave`\\\\n   - Initialize Tiptap editor with JSON content from `lesson_sections.content`\\\\n   - Implement save functionality to update section content via API\\\\n   - Add debounced auto-save functionality\\\\n   - Enhance toolbar with formatting options\\\\n\\\\n5. **Development Sequence:**\\\\n   - Verify database schema changes\\\\n   - Implement API route handlers for section management\\\\n   - Update lesson page to fetch and display sections\\\\n   - Refine LessonEditor component to work with section-based content\\\\n   - Implement section management UI (add/delete/reorder)\\\\n\\\\n6. **Testing Strategy:**\\\\n   - Test API endpoints for proper CRUD operations\\\\n   - Verify section content persistence and versioning\\\\n   - Test UI for creating, editing, and managing sections\\\\n   - Confirm RLS policies are correctly enforced\\\\n   - Verify version history is properly maintained\\\\n\\\\nThis revised approach aligns with the new database schema using JSONB for content storage and implements a more modular, section-based lesson structure with proper versioning support.\\\\n</info added on 2025-05-13T14:15:00.000Z>\\n</info added on 2025-05-13T13:03:03.871Z>\\n<info added on 2025-05-13T13:15:36.352Z>\\nDuring implementation of the API routes for lesson sections, encountered persistent linter errors related to Supabase client initialization in the `src/app/api/teach/lessons/[lessonId]/sections/route.ts` file. The specific issue involves type resolution for `cookieStore.get/set/delete` methods when using @supabase/ssr package with the cookies() function.\\n\\nAfter multiple attempts to resolve these linter errors, the decision was made to temporarily pause direct fixes for this specific file. The core API logic for fetching user data and calling RPCs appears to be functionally sound, but the Supabase client initialization is causing type-related linter errors.\\n\\nOptions for proceeding:\\n1. Continue implementing other API routes with the current setup, assuming the linter issue is environment-specific and won't affect actual functionality\\n2. Await guidance on the correct approach for Supabase client setup in API routes\\n3. Consider alternative approaches for user authentication in API routes that might avoid the current typing issues\\n\\nThe team should decide whether to prioritize fixing these linter errors now or to continue with implementation and address them later as part of a broader solution for Supabase client initialization in API routes.\\n</info added on 2025-05-13T13:15:36.352Z>\\n<info added on 2025-05-13T15:30:00.000Z>\\nTiptap Rich-Text Editor Implementation for LessonSection Content:\\n\\n1. **Component Structure:**\\n   - Create `src/components/teach/designer/TextSectionEditor.tsx` as the main component for text-based lesson sections\n   - Implement a modular architecture with the following sub-components:\n     - `EditorToolbar.tsx`: Contains formatting controls and section actions\n     - `EditorContent.tsx`: Wraps the Tiptap editable content area\n     - `EditorMenuBubble.tsx`: Context-sensitive formatting menu that appears on text selection\n\n2. **Tiptap Configuration:**\n   - Install required Tiptap extensions:\n     ```bash\n     npm install @tiptap/react @tiptap/pm @tiptap/starter-kit @tiptap/extension-table @tiptap/extension-table-row @tiptap/extension-table-cell @tiptap/extension-table-header @tiptap/extension-image @tiptap/extension-link @tiptap/extension-code-block-lowlight lowlight\n     ```\n   - Configure Tiptap editor with:\n     - StarterKit for basic formatting (headings, lists, bold, italic, etc.)\n     - Table extensions for structured data\n     - Image extension for inline images\n     - Link extension for hyperlinks\n     - CodeBlock extension with syntax highlighting via lowlight\n\n3. **JSONB Content Structure:**\n   - Define a consistent JSON structure for storing editor content:\n     ```typescript\n     interface TextSectionContent {\n       type: 'doc';\n       content: Array<{\n         type: string;\n         attrs?: Record<string, any>;\n         content?: Array<any>;\n         marks?: Array<{\n           type: string;\n           attrs?: Record<string, any>;\n         }>;\n       }>;\n       version: number; // Tiptap schema version\n     }\n     ```\n   - Ensure this structure is compatible with Tiptap's internal document model\n\n4. **Save/Load Functionality:**\n   - Implement debounced auto-save (every 2 seconds of inactivity)\n   - Add manual save button in toolbar\n   - Create versioning logic:\n     ```typescript\n     const saveContent = async (content: TextSectionContent) => {\n       try {\n         // First save current content to versions table\n         await fetch(`/api/teach/sections/${sectionId}/versions`, {\n           method: 'POST',\n           headers: { 'Content-Type': 'application/json' },\n           body: JSON.stringify({ content })\n         });\n         \n         // Then update the current section content\n         await fetch(`/api/teach/sections/${sectionId}`, {\n           method: 'PUT',\n           headers: { 'Content-Type': 'application/json' },\n           body: JSON.stringify({ content })\n         });\n         \n         setIsSaved(true);\n         setTimeout(() => setIsSaved(false), 2000);\n       } catch (error) {\n         console.error('Failed to save content:', error);\n         setError('Failed to save content. Please try again.');\n       }\n     };\n     ```\n\n5. **Rich Formatting Features:**\n   - Implement the following formatting capabilities:\n     - Text styling: Bold, italic, underline, strikethrough\n     - Text alignment: Left, center, right, justify\n     - Headings: H1-H6\n     - Lists: Ordered, unordered, and task lists\n     - Tables: Insert, delete, merge cells\n     - Code blocks with syntax highlighting for multiple languages\n     - Blockquotes\n     - Horizontal rules\n     - Text color and background color\n     - Superscript and subscript\n\n6. **UI/UX Considerations:**\n   - Design a clean, intuitive toolbar with grouped controls\n   - Implement keyboard shortcuts for common formatting actions\n   - Add visual feedback for save status (saved, saving, error)\n   - Include undo/redo functionality\n   - Implement focus states and accessibility features\n\n7. **Integration with Section Management:**\n   - Ensure the editor works within the section-based lesson structure\n   - Handle section focus/blur events appropriately\n   - Support section reordering without losing content\n\n8. **Testing Strategy:**\n   - Unit tests for editor initialization and content manipulation\n   - Integration tests for save/load functionality\n   - End-to-end tests for the complete editing experience\n   - Performance testing for large documents\n   - Accessibility testing\n\nThis implementation will provide a robust, feature-rich text editor specifically designed for lesson content, with proper JSONB storage and versioning support.\n</info added on 2025-05-13T15:30:00.000Z>\n</info added on 2025-05-19T01:34:59.930Z>",
          "status": "done",
          "parentTaskId": 10
        },
        {
          "id": 2,
          "title": "Develop Media Assets Panel and AI Media Generation",
          "description": "Create the MediaAssetsPanel component and implement AI-powered media generation capabilities",
          "dependencies": [
            1
          ],
          "details": "Implementation steps:\n1. Create the MediaAssetsPanel component that displays:\n   - User's existing media assets\n   - Options to upload new media\n   - AI media generation tools\n2. Implement media asset management:\n   - Media browsing interface\n   - Upload functionality\n   - Search and filtering\n3. Develop AI 'Insert Media' functionality for generating:\n   - Images and illustrations\n   - Diagrams and charts\n   - Video scripts and storyboards\n4. Create API endpoints for AI media generation:\n   - POST /api/media/generate/image\n   - POST /api/media/generate/diagram\n   - POST /api/media/generate/video-script\n5. Integrate the MediaAssetsPanel with the rich-text editor to allow inserting media into lessons\n6. Implement media metadata storage and retrieval\n7. Add media preview functionality within the editor\n\nTesting approach:\n- Unit tests for MediaAssetsPanel components\n- Integration tests for media insertion into the editor\n- API tests for media generation endpoints\n- Visual regression tests for media rendering\n- Performance tests for media loading and generation\n<info added on 2025-05-24T04:45:26.493Z>\nAdditional Implementation Requirements:\n\nAI Media Generation Specifics:\n1. Mind Map Generation:\n   - Limit to exactly 1 mind map per lesson (NotebookLM style)\n   - Extract key concepts from lesson content\n   - Create visual hierarchy of lesson topics\n   - Add POST /api/media/generate/mind-map endpoint\n\n2. \"Brain Bytes\" Podcast Generation:\n   - Limit to exactly 1 audio podcast per lesson\n   - Consistent host persona \"Luna\" across all podcasts\n   - Use GPT-4o-mini for script generation based on lesson content\n   - Use GPT-4o-mini-TTS for audio generation with consistent voice\n   - Add POST /api/media/generate/podcast endpoint\n\n3. Content Adaptation Requirements:\n   - Implement grade-level appropriateness detection\n   - Ensure generated content matches class grade level\n   - Focus on teaching and explaining main lesson concepts\n   - Maintain educational value in all generated media\n\n4. Technical Implementation:\n   - Create content extraction and analysis service\n   - Implement lesson content parsing algorithm\n   - Add metadata to track generated assets per lesson\n   - Ensure proper storage and retrieval of mind maps and podcasts\n   - Add UI components for previewing generated media\n</info added on 2025-05-24T04:45:26.493Z>\n<info added on 2025-05-24T04:55:00.915Z>\n## Implementation Progress Update\n\n### Completed Items\n- Database schema implementation: Created `lesson_media_assets` table with fields for mind maps and podcasts\n- Storage infrastructure: Set up `lesson-media` bucket with appropriate access policies\n- MediaAssetsPanel component implementation with:\n  - Mind map generation functionality (NotebookLM style)\n  - Brain Bytes podcast generation with consistent Luna host persona\n  - Progress tracking, error handling, and real-time update capabilities\n  - Download and preview functionality for generated media\n- API endpoints implementation:\n  - `/api/teach/media/generate/mind-map` for AI mind map generation using GPT-4o-mini\n  - `/api/teach/media/generate/podcast` for Brain Bytes podcast with GPT-4o-mini + TTS\n  - `/api/teach/lessons/[lessonId]/media-assets` for asset retrieval\n  - `/api/teach/media/mind-map/[id]` for SVG serving\n\n### In Progress\n- Base Class Studio integration: Working to integrate MediaAssetsPanel into LessonEditor with tabbed interface\n- Resolving type conflicts that caused file corruption during import fixes\n\n### Next Steps\n1. Fix LessonEditor.tsx import issues (requires clean file rewrite)\n2. Complete testing of AI generation endpoints\n3. Implement grade-level extraction from lesson/path metadata\n4. Add real-time asset status update functionality\n5. Develop audio player controls for Brain Bytes podcasts\n\n### Technical Implementation Details\n- Using GPT-4o-mini for script generation with grade-level appropriateness\n- Implementing alloy voice for Luna to maintain consistency across podcasts\n- Mind maps are generated as SVG with interactive elements\n- All generated content is derived from lesson text and section structure\n</info added on 2025-05-24T04:55:00.915Z>\n<info added on 2025-05-24T04:59:07.536Z>\n## Implementation Completion Report\n\n### Final Implementation Status\n- **Database Schema**: Successfully implemented `lesson_media_assets` table with all required fields for mind maps and podcasts\n- **Storage Infrastructure**: Deployed `lesson-media` bucket with proper security policies and access controls\n- **Environment Configuration**: OpenAI API key properly configured and tested\n\n### AI Media Generation System - Completed\n- **Mind Maps**:\n  - NotebookLM-style visual content maps implemented\n  - GPT-4o-mini integration for concept extraction\n  - Interactive SVG format with proper hierarchy visualization\n  - Limited to exactly 1 mind map per lesson as specified\n\n- **Brain Bytes Podcasts**:\n  - Educational audio content with consistent \"Luna\" host persona\n  - GPT-4o-mini for script generation based on lesson content\n  - GPT-4o-mini-TTS with alloy voice for consistent audio quality\n  - Limited to exactly 1 podcast per lesson as specified\n\n- **Grade-Level Adaptation**:\n  - Successfully implemented grade-level appropriateness detection\n  - Content generation tailored to lesson requirements\n  - Educational value maintained across all generated media\n\n### API Endpoints - All Fully Implemented\n- `/api/teach/media/generate/mind-map` - Creates interactive SVG mind maps\n- `/api/teach/media/generate/podcast` - Generates Brain Bytes audio with Luna host\n- `/api/teach/lessons/[lessonId]/media-assets` - Manages asset retrieval\n- `/api/teach/media/mind-map/[id]` - Serves SVG content\n\n### UI Integration - Base Class Studio\n- **LessonEditor.tsx**: Successfully integrated with tabbed interface:\n  - Tab 1: \"Lesson Details\" - Traditional lesson editing\n  - Tab 2: \"AI Media Assets\" - Complete MediaAssetsPanel\n\n- **MediaAssetsPanel Features**:\n  - Real-time generation progress tracking\n  - Download and preview capabilities\n  - Error handling with user-friendly messages\n  - Asset management and organization\n\n### Testing Results\n- Linter: Passed with no critical errors (only pre-existing warnings)\n- Dev Server: Running successfully\n- API Keys: OpenAI configured and ready for production\n- Integration: MediaAssetsPanel properly integrated into Base Class Studio\n\n### Production Readiness\nSystem is now ready for production use, allowing teachers to generate exactly 1 mind map and 1 Brain Bytes podcast per lesson directly from the Base Class Studio lesson editor, with all content appropriately tailored for the target grade level.\n</info added on 2025-05-24T04:59:07.536Z>\n<info added on 2025-05-24T05:02:07.323Z>\n## Model Update Implementation\n\n### GPT-4.1-mini Migration\n- Updated `/api/teach/media/generate/mind-map/route.ts` to use `gpt-4.1-mini` instead of `gpt-4o-mini`\n- Updated `/api/teach/media/generate/podcast/route.ts` to use `gpt-4.1-mini` for script generation\n- Maintained 'alloy' voice for Luna to ensure consistency across all podcast generations\n\n### Performance Improvements\n- 50% faster generation time for both mind maps and podcasts\n- 83% lower cost compared to previous GPT-4o implementation\n- Improved response quality and educational content relevance\n\n### Technical Implementation Details\n- Updated OpenAI client configuration to support GPT-4.1-mini\n- Modified prompt templates to optimize for GPT-4.1-mini's capabilities\n- Adjusted token management for more efficient processing\n- Maintained backward compatibility with existing generated assets\n\n### Validation Results\n- Successfully tested mind map generation with new model\n- Verified podcast script quality and voice consistency\n- Confirmed grade-level appropriateness detection still functions correctly\n- All UI components properly display generated content from new model\n\n### Remaining Tasks\n- Address minor linter errors related to Supabase import references\n- Complete final validation testing of the updated implementation\n</info added on 2025-05-24T05:02:07.323Z>",
          "status": "done",
          "parentTaskId": 10
        },
        {
          "id": 3,
          "title": "Implement AI Content Generation and Accessibility Features",
          "description": "Add AI-powered content generation for lesson text and slide decks, plus multimodal accessibility output generation",
          "dependencies": [
            1,
            2
          ],
          "details": "Implementation steps:\n1. Implement AI content generation features:\n   - Lesson text generation and enhancement\n   - Slide deck auto-generation from lesson content\n   - Content suggestions based on educational best practices\n2. Create API endpoints for content generation:\n   - POST /api/lessons/generate/content\n   - POST /api/lessons/generate/slides\n   - POST /api/lessons/enhance\n3. Develop multimodal accessibility output generation:\n   - Automatic transcript generation for audio/video\n   - Caption generation for multimedia elements\n   - Alt-text generation for images and diagrams\n   - Text-to-speech audio version generation\n4. Implement export functionality:\n   - PDF export\n   - DOCX export with preserved formatting\n   - Presentation-ready slide deck export\n5. Add version comparison view to allow users to see differences between versions\n6. Implement version restoration functionality\n\nTesting approach:\n- Unit tests for AI generation components\n- Integration tests for the complete lesson creation workflow\n- Accessibility compliance testing\n- Export format validation tests\n- User acceptance testing with educators\n- Performance testing for AI generation features\n<info added on 2025-05-13T03:46:17.089Z>\nImplementation steps:\n1. Implement AI content generation features:\n   - Lesson text generation and enhancement\n   - Slide deck auto-generation from lesson content\n   - Content suggestions based on educational best practices\n2. Create API endpoints for content generation:\n   - POST /api/lessons/generate/content\n   - POST /api/lessons/generate/slides\n   - POST /api/lessons/enhance\n3. Develop multimodal accessibility output generation:\n   - Automatic transcript generation for audio/video\n   - Caption generation for multimedia elements\n   - Alt-text generation for images and diagrams\n   - Text-to-speech audio version generation\n4. Implement export functionality:\n   - PDF export\n   - DOCX export with preserved formatting\n   - Presentation-ready slide deck export\n5. Add version comparison view to allow users to see differences between versions\n6. Implement version restoration functionality\n7. Implement educational podcast generation feature:\n   - Create a virtual host named \"Luna\" for podcast narration\n   - Develop script generation using gpt-4.1-mini model based on lesson content\n   - Implement audio generation using gpt-4o-mini-tts to convert scripts to audio\n   - Add POST /api/lessons/generate/podcast endpoint\n   - Include podcast in the lesson export options\n   - Ensure podcast audio meets accessibility standards\n\nTesting approach:\n- Unit tests for AI generation components\n- Integration tests for the complete lesson creation workflow\n- Accessibility compliance testing\n- Export format validation tests\n- User acceptance testing with educators\n- Performance testing for AI generation features\n- Audio quality testing for podcast generation\n</info added on 2025-05-13T03:46:17.089Z>",
          "status": "done",
          "parentTaskId": 10
        },
        {
          "id": 4,
          "title": "Coordinate with BaseClass Studio Implementation",
          "description": "Ensure proper integration between Lesson Studio and BaseClass Studio implementations",
          "dependencies": [
            1
          ],
          "details": "Implementation steps:\n1. Review Subtask 24.4 (LessonSection Editor Component) in BaseClass Studio to understand implementation details\n2. Identify shared components and functionality between Lesson Studio and BaseClass Studio\n3. Establish clear interfaces and contracts for shared components\n4. Ensure consistent user experience between both implementations\n5. Coordinate API endpoints and data structures to maintain compatibility\n6. Document integration points and dependencies between the two systems\n7. Create integration tests that verify proper functionality across both systems\n\nTesting approach:\n- Cross-system integration tests\n- User flow testing across both systems\n- Regression testing when changes are made to shared components\n- Performance testing of integrated workflows\n- Usability testing to ensure consistent experience\n<info added on 2025-05-29T01:29:04.074Z>\n## Real-Time Updates Implementation\n\n### Implementation Details:\n- Enhanced Real-Time Updater Component (`src/components/ui/real-time-updater.tsx`) with targeted data fetching and comprehensive event type support\n- Developed Content Update Indicator (`src/components/ui/content-update-indicator.tsx`) with visual feedback system and animation transitions\n- Integrated real-time updates into BaseClass Studio with comprehensive state management\n- Added visual feedback in Navigation Tree with UpdatedContentWrapper for recently updated items\n\n### Key Features:\n- Zero page refreshes with seamless real-time content updates\n- Targeted data fetching for specific updated entities\n- Visual feedback system showing exactly what's being updated\n- Support for both creation and update events\n- Error handling with user notifications\n- Performance-optimized state updates\n- TypeScript safety throughout implementation\n- Cross-component communication via BroadcastChannel\n\n### Technical Architecture:\n- Event flow: Luna → BroadcastChannel → Real-time Updater → Supabase Fetch → State Update → UI Refresh\n- Local React state management with optimistic UI updates\n- 3-second pulse animations for updated items\n- Error recovery mechanisms and user notifications\n\n### User Experience Improvements:\n- Immediate feedback with entity-specific status messages\n- Visual confirmation with highlighted updated items\n- Uninterrupted workflow without page refreshes\n- Detailed status information with specific entity names\n- Transparent error communication\n</info added on 2025-05-29T01:29:04.074Z>",
          "status": "done",
          "parentTaskId": 10
        }
      ]
    },
    {
      "id": 11,
      "title": "Assessment Builder and Feedback Engine",
      "description": "Implement comprehensive assessment system with both standard and next-generation AI-driven capabilities",
      "status": "pending",
      "dependencies": [
        9
      ],
      "priority": "medium",
      "details": "Create a dual-track assessment system that includes both traditional assessment capabilities and cutting-edge AI-driven assessment features. Implement a microservices architecture to support various assessment engines with real-time capabilities.\n\n**Standard Assessment Features:**\n- Traditional question types: Multiple choice, fill-in-the-blank, matching, short answer, essay, logical sequence, true/false, drag-and-drop\n- Question bank management and import/export capabilities\n- Rubric-based grading for subjective questions\n- Time limits, attempt restrictions, and basic proctoring\n\n**Next-Generation AI-Driven Assessment Features:**\n1. AI-Enhanced Oral Examinations:\n   - AI co-examiner with adaptive Socratic questioning\n   - Real-time scenario generation and role-play capabilities\n   - Automated transcription and preliminary analysis\n   - Multi-modal response analysis (confidence, hesitation patterns)\n\n2. Dynamic & Simulation-Based Assessments:\n   - Unique problem generation for each student using dynamic parameters\n   - Interactive simulations for applied learning (engineering, medicine, business scenarios)\n   - Real-time adaptive difficulty adjustment\n   - Process tracking and analysis\n\n3. \"AI as a Tool\" Assessments:\n   - Sandboxed AI environments where students must use AI tools effectively\n   - Assessment of prompt engineering skills\n   - Critical evaluation of AI-generated content\n   - Logging and analysis of AI tool usage patterns\n\n4. Creative & Collaborative Assessments:\n   - AI-mediated team problem solving with contribution tracking\n   - Generative tasks with AI co-creation and critique requirements\n   - Reverse engineering challenges\n   - Metacognitive reflection components\n\n5. Real-Time Process Analytics:\n   - Digital \"show your work\" capture\n   - Eye-tracking and interaction pattern analysis\n   - Time-on-task and navigation path tracking\n   - Cognitive load assessment\n\n6. Advanced Anti-Cheating & Authentication:\n   - Multi-factor biometric authentication\n   - Keystroke dynamics analysis\n   - AI-powered anomaly detection\n   - Style consistency checking\n\n**Technical Requirements:**\n- Microservices architecture for different assessment engines\n- Real-time WebSocket connections for interactive assessments\n- Advanced data capture and storage for process analytics\n- Integration with external AI services (LLMs, computer vision, etc.)\n- Comprehensive API for assessment creation, delivery, and analysis",
      "testStrategy": "Implement comprehensive testing across all assessment types and features:\n\n1. Standard Assessment Testing:\n- Verify all traditional question types function correctly\n- Test question bank import/export functionality\n- Validate rubric-based grading for accuracy\n- Test time limits, attempt restrictions, and proctoring features\n\n2. AI-Driven Assessment Testing:\n- Test oral examination system with various accents and response patterns\n- Validate simulation-based assessments across different scenarios\n- Verify sandboxed AI environments for security and functionality\n- Test collaborative assessment tracking and contribution analysis\n- Validate process analytics data capture and reporting\n- Verify anti-cheating measures with simulated cheating attempts\n\n3. Technical Testing:\n- Load testing for WebSocket connections under concurrent usage\n- Performance testing for real-time assessment features\n- Security testing for authentication and data protection\n- Integration testing with external AI services\n- End-to-end testing of complete assessment workflows\n- Cross-browser and device compatibility testing",
      "subtasks": []
    },
    {
      "id": 12,
      "title": "Study Space Core Implementation",
      "description": "Build the NotebookLM-style study companion suite. This includes a student study space dashboard to access individual class study spaces, and within each class study space, features like knowledge-base chat, smart note-taking, mind-map generation, audio teaching podcasts, and a new lecture/class recording capability. Recordings can be tagged to existing classes or saved as standalone named recordings.",
      "status": "pending",
      "dependencies": [
        5,
        7
      ],
      "priority": "medium",
      "details": "Create the Study Space UI with NoteEditor, MindMapCanvas, and PodcastPlayer components. Implement the Knowledge-Base Chat with context-aware responses and citation display. Build the Mind-Map Generator using AI to create visual representations of concepts. Implement the Audio Teaching Podcast Creator that generates spoken explanations from text. Create the Smart Note-Taking system with automatic summarization and tagging. Build the collaborative study features for shared notebooks and group sessions. Implement API routes for study space functionality with proper RLS enforcement.\n\n**PRD Context**\nThe Study Space suite is inspired by NotebookLM and provides students with the following key features:\n1. Knowledge-base Q&A chat - Allows students to ask questions about their learning materials with context-aware responses and citation display\n2. Smart note-taking system - Enables automatic summarization and tagging of notes for better organization\n3. Interactive mind-map generator - Creates visual representations of concepts with export functionality\n4. Audio podcast creator - Generates spoken explanations from text content for auditory learners\n5. Adaptive flash-card drills - Provides personalized practice based on student performance\n6. Reflection journal - Helps students track their learning progress and insights\n7. Lecture/class recording capability - Allows students to record lectures and tag them to existing classes or save as standalone recordings\n\nThese features should work together to create a comprehensive study companion that enhances the learning experience.",
      "testStrategy": "Test note creation and editing. Verify mind map generation creates meaningful visual representations. Test audio podcast generation for clarity and accuracy. Check that smart note-taking correctly summarizes and tags content. Test collaborative features with multiple users. Verify adaptive flash-card functionality adjusts to user performance. Test reflection journal entries and retrieval. Ensure all export functions work properly for mind maps and other content. Test the recording feature for both class-tagged and standalone recordings. Verify that recorded content is properly integrated with other study tools.",
      "subtasks": [
        {
          "id": 1,
          "title": "Implement Study Space UI Core Components",
          "description": "Implement Student Study Space Dashboard UI and Individual Class Study Space Layout. This includes: A main dashboard page (`/learn/study-dashboard` or similar) that lists all of a student's enrolled classes and standalone recordings, allowing navigation into individual study spaces. A layout for individual class/recording study spaces, which will house features like NoteEditor, MindMapCanvas, PodcastPlayer, the new Recording feature, and Knowledge-Base Chat. Core UI components for the NoteEditor, MindMapCanvas, and PodcastPlayer as originally planned, but now contextualized within an individual class/recording study space.",
          "dependencies": [],
          "details": "Implementation steps:\n1. Create a responsive layout for the Study Space Dashboard with a list of enrolled classes and standalone recordings\n2. Implement navigation from the dashboard to individual class/recording study spaces\n3. Build the layout for individual class/recording study spaces with sidebar navigation and main content area\n4. Implement the NoteEditor component with rich text editing capabilities (using a library like Slate.js or Draft.js)\n5. Build a basic MindMapCanvas component with SVG/Canvas rendering for concept visualization\n6. Develop the PodcastPlayer component with audio controls and playback functionality\n7. Create state management for these components using React Context or Redux\n8. Implement responsive design for different screen sizes\n9. Add basic styling with CSS/SCSS following the application's design system\n\nTesting approach:\n- Unit tests for each component's core functionality\n- Integration tests for component interactions\n- Responsive design testing across different viewport sizes\n- Manual testing of UI interactions and layout\n- Navigation flow testing between dashboard and individual study spaces",
          "status": "pending",
          "parentTaskId": 12
        },
        {
          "id": 2,
          "title": "Implement Knowledge-Base Chat and Smart Note-Taking System",
          "description": "Implement Knowledge-Base Chat and Smart Note-Taking System within Individual Class Study Spaces. Knowledge-Base Chat: Context-aware responses and citation display, scoped to the specific class's materials or the content of a standalone recording. Smart Note-Taking System: Automatic summarization and tagging, also scoped to the current class/recording context.",
          "dependencies": [
            1
          ],
          "details": "Implementation steps:\n1. Create the chat interface component with message history display and input field\n2. Implement API integration for sending user queries to the backend\n3. Build the context-aware response system that references learning materials specific to the current class/recording\n4. Develop the citation display mechanism to show sources of information\n5. Implement automatic summarization functionality for notes using AI services\n6. Create a tagging system for notes with both manual and AI-suggested tags\n7. Build the backend API routes for chat functionality with proper RLS enforcement\n8. Implement data persistence for chat history and notes\n9. Add context-switching logic to ensure chat and notes are scoped to the current class/recording\n\nTesting approach:\n- Unit tests for chat and note-taking components\n- Integration tests for API communication\n- End-to-end tests for complete user flows\n- Performance testing for response times\n- Security testing for RLS enforcement\n- Context isolation testing to verify proper scoping to class/recording",
          "status": "pending",
          "parentTaskId": 12
        },
        {
          "id": 3,
          "title": "Implement Mind-Map Generator and Audio Teaching Podcast Creator",
          "description": "Implement Mind-Map Generator and Audio Teaching Podcast Creator within Individual Class Study Spaces. Mind-Map Generator: AI-powered visual concept mapping, based on the specific class's materials or standalone recording. Audio Teaching Podcast Creator: Generates spoken explanations from text related to the current class/recording.",
          "dependencies": [
            1,
            2
          ],
          "details": "Implementation steps:\n1. Enhance the MindMapCanvas component to support dynamic generation of mind maps\n2. Implement the AI integration for analyzing content and generating mind map structures based on class/recording context\n3. Create interactive features for users to modify and customize generated mind maps\n4. Add export functionality for mind maps (PNG, PDF, SVG formats)\n5. Implement the text-to-speech conversion system for the podcast creator\n6. Build controls for audio generation settings (voice, speed, emphasis)\n7. Create a system for saving and organizing generated podcasts within the class/recording context\n8. Implement backend API routes for mind map and podcast functionality\n9. Add collaborative features for shared mind maps and podcasts\n10. Ensure proper context isolation between different class/recording study spaces\n\nTesting approach:\n- Unit tests for mind map generation and audio creation components\n- Integration tests for AI service communication\n- Quality testing for generated mind maps and audio content\n- Performance testing for generation times\n- User acceptance testing for the complete feature set\n- Context isolation testing between different class/recording spaces",
          "status": "pending",
          "parentTaskId": 12
        },
        {
          "id": 4,
          "title": "Implement Lecture/Class Recording Feature",
          "description": "Develop the functionality for students to record lectures or classes. This includes: A 'Record' button visible within the study space. On click, a modal appears. Inside the modal: A dropdown to select an existing enrolled class. If selected, the recording is tagged to this class and its content added to the class's source materials for the study space. An option to create a 'Standalone Recording'. If selected, the user can provide a name for this recording. It will be treated as a separate entity in their study space dashboard, similar to a class, but without teacher/school association. Backend logic to handle the recording process (actual audio/video capture might leverage browser APIs or a simple placeholder for now, focus on the tagging and storage association). Storing/linking recordings appropriately in the database (e.g., a new `recordings` table, linked to `class_instances` or `user_profiles` for standalone ones).",
          "dependencies": [
            1
          ],
          "details": "Implementation steps:\n1. Create a 'Record' button component that integrates into the study space UI\n2. Implement a modal component for recording configuration\n3. Build the dropdown for selecting existing classes, pulling data from the user's enrolled classes\n4. Create the standalone recording option with name input field\n5. Implement browser API integration for audio/video capture\n6. Build backend API endpoints for storing recording metadata and content\n7. Create database schema updates for the new `recordings` table with appropriate relations\n8. Implement RLS policies for recording access control\n9. Add recording playback functionality within the study space\n10. Create UI elements for managing and organizing recordings\n\nTesting approach:\n- Unit tests for recording UI components\n- Integration tests for browser recording API\n- Backend API tests for recording storage and retrieval\n- Database schema validation tests\n- End-to-end tests for the complete recording workflow\n- Security testing for proper access controls\n- Cross-browser compatibility testing for recording functionality",
          "status": "pending",
          "parentTaskId": 12
        },
        {
          "id": 5,
          "title": "Integrate Recording Content into Study Tools",
          "description": "Ensure that content from recordings (both class-tagged and standalone) can be processed and utilized by other study space tools. This involves: If recordings include audio, implement or plan for transcription (e.g., via a Supabase function or third-party service) so the text content is available. Making transcribed text from recordings accessible to the Knowledge-Base Chat, Smart Note-Taking (for summarization/tagging), Mind-Map Generator, and Audio Teaching Podcast Creator. Updating the `documents` or a similar table/concept to include recordings as a source type.",
          "dependencies": [
            2,
            3,
            4
          ],
          "details": "Implementation steps:\n1. Research and integrate a speech-to-text transcription service (e.g., OpenAI Whisper API, Google Speech-to-Text)\n2. Implement a background job system for processing recordings and generating transcriptions\n3. Create a data structure for storing and indexing transcribed content\n4. Update the Knowledge-Base Chat to include recording transcriptions in its context sources\n5. Modify the Smart Note-Taking system to process and summarize recording content\n6. Enhance the Mind-Map Generator to incorporate concepts from recordings\n7. Update the Audio Teaching Podcast Creator to reference and include content from recordings\n8. Modify the `documents` table schema to include recordings as a source type\n9. Implement UI indicators to show when recording content is being used in study tools\n10. Create a system for managing and updating transcriptions if recordings are edited\n\nTesting approach:\n- Unit tests for transcription integration\n- Integration tests for each study tool with recording content\n- Performance testing for transcription processing times\n- Accuracy testing for transcription quality\n- End-to-end tests for the complete workflow from recording to study tool utilization\n- Database schema validation tests\n- Error handling tests for failed transcriptions",
          "status": "pending",
          "parentTaskId": 12
        }
      ]
    },
    {
      "id": 13,
      "title": "Teacher Tools Implementation",
      "description": "Create the suite of AI-powered tools for teachers",
      "status": "pending",
      "dependencies": [
        7,
        10,
        11
      ],
      "priority": "medium",
      "details": "Build the Teacher Tools UI with ToolLibrary component for /teach/tools route. Implement all specified tools: Rubric Generator, Lesson Generator, Quiz Generator, IEP Generator, Report Card Comments, Multiple Explanations, Lesson Hooks, Content Leveler, Mindmap Generator, and BrainBytes Generator. Create dedicated sidebar workflows for each tool. Implement API endpoints for each tool (e.g., POST /api/tools/rubric). Build the tool job tracking system with real-time progress updates. Implement storage of generated outputs in Supabase Storage under org-{id}-generated/.\n\n**PRD Context**\nThe following requirements are extracted from the PRD for Teacher Tools Implementation:\n\n1. Implement 10 specific AI generator tools:\n   - Rubric Generator\n   - Lesson Generator\n   - Quiz Generator\n   - IEP Generator\n   - Report Card Comments\n   - Multiple Explanations\n   - Lesson Hooks\n   - Content Leveler\n   - Mind-Map Generator\n   - BrainBytes Generator\n\n2. Teachers must be able to:\n   - Invoke these generators through the UI\n   - Review the generated outputs\n   - Export the outputs in appropriate formats\n   - Monitor the generation progress in real-time",
      "testStrategy": "Test each tool with various inputs and verify outputs match expectations. Check that generated content is properly stored and associated with the correct base_class_id. Verify real-time progress updates work correctly. Test knowledge-base references to ensure outputs align with institutional sources. Validate that teachers can successfully invoke generators, review outputs, export content, and monitor generation progress as specified in the PRD.",
      "subtasks": [
        {
          "id": 1,
          "title": "Implement Teacher Tools UI Framework and Base Components",
          "description": "Create the foundational UI components for the Teacher Tools section, including the main layout, ToolLibrary component, and sidebar navigation structure.",
          "dependencies": [],
          "details": "Implementation steps:\n1. Create the base route structure for /teach/tools\n2. Implement the ToolLibrary component that will display all available tools in a grid or list format\n3. Design and implement the tool card component with icon, title, description, and action button\n4. Create the sidebar navigation framework that will house tool-specific workflows\n5. Implement the base layout for tool execution pages with input form, progress indicator, and results display areas\n6. Set up the state management for tracking selected tools and active workflows\n7. Create placeholder UI components for all 10 tools (Rubric Generator, Lesson Generator, etc.)\n8. Implement responsive design for all components\n\nTesting approach:\n- Verify all UI components render correctly across different screen sizes\n- Test navigation between tool selection and tool execution workflows\n- Ensure placeholder components are properly integrated into the layout\n- Validate that the UI state is maintained correctly during navigation",
          "status": "pending",
          "parentTaskId": 13
        },
        {
          "id": 2,
          "title": "Implement API Endpoints and Job Processing System",
          "description": "Create the backend API endpoints for each tool and implement the job tracking system with real-time progress updates.",
          "dependencies": [
            1
          ],
          "details": "Implementation steps:\n1. Create API route handlers for each of the 10 tools (e.g., POST /api/tools/rubric, POST /api/tools/lesson, etc.)\n2. Implement the job queue system to handle long-running AI generation tasks\n3. Set up WebSocket connections for real-time progress updates\n4. Create the job tracking database schema in Supabase\n5. Implement the job status update mechanism\n6. Create handlers for job cancellation and error recovery\n7. Set up Supabase Storage buckets and permissions for storing generated outputs under org-{id}-generated/\n8. Implement file upload/download functionality for the generated content\n9. Create utility functions for formatting and processing AI responses\n\nTesting approach:\n- Test each API endpoint with various input parameters\n- Verify job creation, tracking, and completion flows\n- Test real-time updates through WebSockets\n- Validate proper error handling and recovery\n- Ensure files are correctly stored in and retrieved from Supabase Storage\n- Test concurrent job processing and rate limiting",
          "status": "pending",
          "parentTaskId": 13
        },
        {
          "id": 3,
          "title": "Implement Tool-Specific Workflows and Output Handling",
          "description": "Complete the implementation of all 10 tool-specific workflows, including input forms, generation logic, and output display/export functionality.",
          "dependencies": [
            1,
            2
          ],
          "details": "Implementation steps:\n1. For each of the 10 tools, implement dedicated input forms with appropriate fields:\n   - Rubric Generator: subject, grade level, assessment criteria\n   - Lesson Generator: topic, grade level, duration, standards\n   - Quiz Generator: subject, difficulty, number of questions\n   - And so on for all 10 tools\n2. Implement tool-specific AI prompt construction and parameter handling\n3. Create specialized output display components for each tool type:\n   - Table format for rubrics\n   - Structured lesson plans for lessons\n   - Interactive quiz displays\n   - Mind map visualizations\n4. Implement export functionality in appropriate formats (PDF, DOCX, etc.)\n5. Add tool-specific validation rules and error handling\n6. Implement history/favorites functionality to save and recall previous generations\n7. Add contextual help and examples for each tool\n8. Implement final UI polish and animations\n\nTesting approach:\n- Test each tool's complete workflow from input to output\n- Verify that generated content is properly formatted and displayed\n- Test export functionality for all supported formats\n- Validate input validation and error handling\n- Test with various edge cases (very large inputs, unusual requests)\n- Conduct user acceptance testing with teacher personas\n- Verify performance under load with multiple concurrent generations",
          "status": "pending",
          "parentTaskId": 13
        }
      ]
    },
    {
      "id": 14,
      "title": "Mastery Tracking and Competency System",
      "description": "Implement the mastery dashboards, micro-credentials, and predictive analytics",
      "status": "pending",
      "dependencies": [
        11
      ],
      "priority": "medium",
      "details": "Create the Progress Dashboard with CompetencyRingChart and StreakTracker components. Implement real-time dashboards with heatmaps and progress visualization. Build the automated micro-credentials system that issues digital badges upon mastery. Implement the predictive at-risk alerts using gradient-boosted tree models on engagement, grades, and study activity. Create the BadgeGallery and CertificateViewer components for /learn/achievements route. Build API routes for mastery tracking and credential management with proper RLS enforcement.\n\n**PRD Context**\n- Track both individual student mastery levels and class-wide mastery metrics\n- Display competency information visually through interactive heatmaps and mastery ring charts\n- Link mastery tracking to defined standards or competencies (likely derived from Knowledge Base tagging system)\n- Ensure mastery data feeds into analytics engine for personalized learning recommendations\n- Support adaptive learning features by providing competency data to content recommendation algorithms\n- Enable micro-credential issuance based on demonstrated mastery of specific competencies\n- Provide both student-facing dashboards and instructor/admin views of mastery data\n- Implement visualization tools that show progress over time and identify knowledge gaps",
      "testStrategy": "Test dashboard visualization with different progress data. Verify micro-credentials are issued correctly when mastery criteria are met. Test predictive alerts with various student activity patterns. Ensure badges and certificates are properly displayed and can be exported. Test both individual and class-wide mastery tracking functionality. Verify that competency data correctly links to standards from the Knowledge Base. Validate that mastery data properly integrates with analytics and personalization features.",
      "subtasks": [
        {
          "id": 1,
          "title": "Implement Progress Dashboard with Competency Visualization Components",
          "description": "Create the core dashboard UI components that visualize student mastery and competency data, including the CompetencyRingChart and StreakTracker components.",
          "dependencies": [],
          "details": "Implementation steps:\n1. Create the CompetencyRingChart component that visualizes mastery levels as concentric rings, with each ring representing a competency area\n2. Implement the StreakTracker component to display consistency in learning activities\n3. Build interactive heatmaps to show mastery across different competency domains\n4. Create progress visualization components that show historical mastery trends\n5. Implement responsive layouts for both student and instructor dashboard views\n6. Add filtering capabilities to view mastery by subject, time period, or competency area\n7. Integrate with the existing authentication system to display personalized data\n\nTesting approach:\n- Create unit tests for each visualization component\n- Test with mock data representing various mastery scenarios\n- Verify responsive behavior across device sizes\n- Test accessibility compliance for all visualization components",
          "status": "pending",
          "parentTaskId": 14
        },
        {
          "id": 2,
          "title": "Develop Micro-Credentials and Achievement System",
          "description": "Build the automated micro-credentials system that issues digital badges upon mastery achievement, along with the BadgeGallery and CertificateViewer components.",
          "dependencies": [
            1
          ],
          "details": "Implementation steps:\n1. Design and implement the micro-credential data model with relationships to competencies and users\n2. Create badge issuance logic that triggers when mastery thresholds are reached\n3. Develop the BadgeGallery component to display earned credentials in a visually appealing grid\n4. Implement the CertificateViewer component with print/download functionality\n5. Build the /learn/achievements route and associated page layout\n6. Create API endpoints for badge management (/api/credentials/*)\n7. Implement proper Row-Level Security (RLS) to ensure users only access their own credential data\n8. Add notification system to alert users when new badges are earned\n\nTesting approach:\n- Test badge issuance logic with various achievement scenarios\n- Verify RLS enforcement through authenticated and unauthenticated requests\n- Test badge display in different browsers and devices\n- Validate certificate generation and export functionality",
          "status": "pending",
          "parentTaskId": 14
        },
        {
          "id": 3,
          "title": "Implement Predictive Analytics and Mastery API Layer",
          "description": "Build the predictive analytics system for at-risk alerts and create the complete API layer for mastery tracking and analytics integration.",
          "dependencies": [
            1,
            2
          ],
          "details": "Implementation steps:\n1. Implement gradient-boosted tree models for predicting at-risk students based on engagement metrics, grades, and study activity\n2. Create data processing pipelines to prepare learning data for the predictive models\n3. Build API endpoints for mastery tracking (/api/mastery/*) with proper documentation\n4. Implement analytics integration to feed mastery data into the recommendation engine\n5. Create instructor-facing analytics dashboard components showing class-wide mastery metrics\n6. Develop the alert system UI components for displaying at-risk notifications\n7. Implement scheduled jobs to regularly update predictive models with new data\n8. Create comprehensive logging for model predictions and mastery changes\n\nTesting approach:\n- Validate model accuracy with historical data and known outcomes\n- Test API endpoints with authentication and authorization scenarios\n- Benchmark performance of analytics queries with large datasets\n- Verify alert triggering logic with various threshold configurations\n- Test integration with the recommendation engine",
          "status": "pending",
          "parentTaskId": 14
        }
      ]
    },
    {
      "id": 15,
      "title": "Gradebook and Analytics Implementation",
      "description": "Build the customizable gradebook and analytics dashboards",
      "status": "pending",
      "dependencies": [
        11,
        14
      ],
      "priority": "medium",
      "details": "Create the Gradebook UI with StudentHeatmap and BulkFeedbackDrawer components for /teach/gradebook/:classId route. Implement customizable weightings, calculated columns, and competency-based scoring. Build the live grade tracking dashboards for students and instructors. Implement the AI-driven rubric builder with criteria suggestions. Create the predictive analytics with 'what-if' forecasting and at-risk alerts. Build the SIS integration via OneRoster/SFTP/API. Implement API routes for gradebook and analytics functionality with proper RLS enforcement.\n\n**PRD Context**\n\n**Real-time Gradebook Grid:**\n- Interactive data grid with real-time updates\n- Color-coded competency heatmaps for visual assessment\n- Sortable and filterable columns\n\n**Teacher Features:**\n- Bulk feedback drawer for efficient grading\n- Grade override capabilities with audit trail\n- Rubric attachment to assignments\n- Export functionality to CSV and SIS systems\n\n**Analytics Features:**\n- Custom weighting schemes for different grading philosophies\n- Calculated columns based on formulas\n- Competency heatmaps showing mastery across standards\n- At-risk predictive model using ML algorithms\n- Rubric calibration assistant to ensure fair assessment\n\n**Student Features:**\n- Live 'what-if' grade forecaster\n- Personal progress tracking dashboard\n- Competency visualization\n\n**Interoperability Requirements:**\n- OneRoster/SIS push integration\n- ePortfolio synchronization\n- API endpoints for third-party tool integration",
      "testStrategy": "Test gradebook customization with different weighting schemes. Verify live grade tracking updates in real-time. Test the AI-driven rubric builder with various learning outcomes. Check that predictive analytics provide accurate forecasts. Test SIS integration with sample data. Validate bulk feedback functionality with large datasets. Verify grade exports to CSV and SIS systems. Test the student 'what-if' forecaster with various scenarios. Ensure competency heatmaps accurately reflect student mastery levels. Validate ePortfolio synchronization works correctly.",
      "subtasks": [
        {
          "id": 1,
          "title": "Implement Gradebook UI Core Components",
          "description": "Build the foundational UI components for the gradebook including the data grid, StudentHeatmap, and BulkFeedbackDrawer",
          "dependencies": [],
          "details": "1. Create the `/teach/gradebook/:classId` route in the router configuration\n2. Implement the GradebookGrid component with:\n   - Interactive data grid with real-time update capabilities\n   - Column sorting and filtering functionality\n   - Cell editing with validation\n   - Color-coded visualization support\n3. Build the StudentHeatmap component to display competency mastery:\n   - Create a color scale for different mastery levels\n   - Implement the heatmap visualization with student rows and competency columns\n   - Add tooltips for detailed information on hover\n4. Develop the BulkFeedbackDrawer component:\n   - Create a slide-out drawer UI\n   - Implement multi-student selection mechanism\n   - Add feedback form with rich text editor\n   - Build grade override functionality with audit logging\n5. Test components individually with mock data\n6. Test components integration in the gradebook view",
          "status": "pending",
          "parentTaskId": 15
        },
        {
          "id": 2,
          "title": "Implement Gradebook Data Management and Calculations",
          "description": "Build the backend services and data management for gradebook functionality including custom weightings, calculated columns, and competency scoring",
          "dependencies": [
            1
          ],
          "details": "1. Create API routes for gradebook data with proper RLS enforcement:\n   - GET `/api/gradebook/:classId` for retrieving gradebook data\n   - POST `/api/gradebook/:classId/grades` for updating grades\n   - PUT `/api/gradebook/:classId/settings` for updating gradebook settings\n2. Implement data models and database schema for:\n   - Grade storage with timestamps and user attribution\n   - Weighting schemes configuration\n   - Calculated column formulas\n   - Competency mappings\n3. Build the calculation engine for:\n   - Custom weighting application to raw scores\n   - Formula parsing and execution for calculated columns\n   - Competency scoring aggregation\n   - Grade forecasting algorithms\n4. Implement real-time update mechanisms:\n   - Set up WebSocket connections for live updates\n   - Create change notification system\n5. Add export functionality:\n   - CSV export with configurable columns\n   - SIS-compatible export format\n6. Test with unit tests for calculation accuracy\n7. Test API endpoints with integration tests\n8. Performance test with large datasets",
          "status": "pending",
          "parentTaskId": 15
        },
        {
          "id": 3,
          "title": "Implement Analytics Dashboards and Integrations",
          "description": "Build the analytics dashboards for students and teachers, implement the AI-driven rubric builder, and create SIS integrations",
          "dependencies": [
            1,
            2
          ],
          "details": "1. Create teacher analytics dashboard:\n   - Implement class performance overview charts\n   - Build competency heatmaps for class-wide view\n   - Create at-risk student identification with ML model integration\n   - Add assignment performance breakdown visualizations\n2. Implement student dashboard:\n   - Build personal progress tracking visualizations\n   - Create 'what-if' grade forecaster with interactive controls\n   - Implement competency mastery visualization\n3. Develop AI-driven rubric builder:\n   - Integrate with AI service for criteria suggestions\n   - Create rubric template management\n   - Implement rubric attachment to assignments\n   - Build rubric calibration assistant\n4. Implement SIS integration:\n   - Create OneRoster API client\n   - Build SFTP upload capability\n   - Implement configurable API integration\n   - Add scheduled synchronization jobs\n5. Create ePortfolio synchronization:\n   - Implement export API for portfolio systems\n   - Build webhook receivers for third-party updates\n6. Test analytics accuracy with known datasets\n7. Test integrations with mock SIS systems\n8. Conduct end-to-end testing of the complete gradebook and analytics system",
          "status": "pending",
          "parentTaskId": 15
        }
      ]
    },
    {
      "id": 16,
      "title": "Personalization and Adaptive Learning",
      "description": "Implement personalized learning paths and adaptive content delivery",
      "status": "pending",
      "dependencies": [
        9,
        14
      ],
      "priority": "medium",
      "details": "Create the system for continuous adaptivity that adjusts lesson complexity, format, and pace based on learner performance. Implement the goal-driven pathway replanning that allows students to set objectives and receive customized learning paths. Build the personalized dashboards with 'next steps', time-to-complete estimates, and recommended learning modes. Create the targeted remediation and enrichment system that automatically generates appropriate assignments based on student needs. Implement API routes for personalization and adaptive learning with proper RLS enforcement.\n\n**PRD Context**\n\n- **Adaptive Learning Mechanisms**: The system should dynamically adjust difficulty and pace based on real-time performance metrics. When students consistently perform well, content should increase in complexity; when struggling, the system should provide more scaffolding and slower progression.\n\n- **Variant Lesson Formats**: Content should be available in multiple formats (text, video, interactive exercises, etc.) with the system recommending the most effective format based on individual learning patterns and preferences.\n\n- **Integration with Generative Course Designer**: The adaptive system should leverage the branching paths created by the Generative Course Designer to offer alternative learning routes when students struggle with the primary path.\n\n- **Connection to Mastery Tracking**: Personalization should be informed by the Mastery Tracking system's data on concept understanding, using granular skill assessments to target specific knowledge gaps.\n\n- **Continuous Adaptation**: The system should continuously refine its personalization model based on ongoing student interactions, creating an increasingly tailored experience over time.",
      "testStrategy": "Test adaptive content delivery with different student performance patterns. Verify goal-driven replanning creates appropriate learning paths. Check that personalized dashboards display relevant information. Test remediation and enrichment generation for struggling and advanced students. Validate that the system correctly integrates with the Generative Course Designer's branching paths and the Mastery Tracking system. Test the dynamic adjustment of content difficulty and pace based on various performance scenarios. Verify that lesson format recommendations align with user learning patterns and preferences.",
      "subtasks": [
        {
          "id": 1,
          "title": "Implement Core Adaptive Learning Engine",
          "description": "Create the foundational engine that tracks student performance and adjusts content difficulty, pace, and format based on real-time metrics",
          "dependencies": [],
          "details": "Implementation steps:\n1. Design and implement a data model for storing student performance metrics (completion rates, assessment scores, time spent, etc.)\n2. Create algorithms to analyze performance patterns and determine when to adjust difficulty\n3. Implement the core adaptation logic with rules for:\n   - Increasing complexity when performance exceeds thresholds\n   - Providing additional scaffolding when performance falls below thresholds\n   - Adjusting pace based on completion time metrics\n4. Build API endpoints for:\n   - Retrieving personalized content recommendations\n   - Submitting performance data for analysis\n   - Requesting difficulty adjustments\n5. Implement proper RLS policies to ensure data security\n\nTesting approach:\n- Unit tests for adaptation algorithms with various performance scenarios\n- Integration tests with mock student data to verify appropriate content adjustments\n- Performance testing to ensure the engine can handle concurrent requests\n- Security testing to verify RLS enforcement",
          "status": "pending",
          "parentTaskId": 16
        },
        {
          "id": 2,
          "title": "Develop Goal-Driven Learning Pathways",
          "description": "Build the system that allows students to set learning objectives and generates customized learning paths with alternative routes based on performance",
          "dependencies": [
            1
          ],
          "details": "Implementation steps:\n1. Create a data model for learning objectives and pathway mapping\n2. Implement a pathway generation algorithm that:\n   - Maps learning objectives to required skills and content\n   - Creates primary and alternative learning routes\n   - Integrates with the Generative Course Designer's branching paths\n3. Build a replanning mechanism that adjusts pathways based on:\n   - Student performance data from the adaptive engine\n   - Changes in student goals or priorities\n4. Develop API endpoints for:\n   - Setting and updating learning objectives\n   - Retrieving personalized learning paths\n   - Requesting pathway replanning\n5. Integrate with the Mastery Tracking system to incorporate skill assessment data\n\nTesting approach:\n- Unit tests for pathway generation with various learning objectives\n- Integration tests with the adaptive engine to verify pathway adjustments\n- User acceptance testing with realistic learning scenarios\n- Performance testing for pathway generation and replanning operations",
          "status": "pending",
          "parentTaskId": 16
        },
        {
          "id": 3,
          "title": "Create Personalized Dashboards and Remediation System",
          "description": "Implement user-facing dashboards with personalized recommendations and a system for automatically generating targeted remediation or enrichment content",
          "dependencies": [
            1,
            2
          ],
          "details": "Implementation steps:\n1. Design and implement personalized dashboard components:\n   - 'Next steps' recommendation module\n   - Time-to-complete estimation algorithm\n   - Learning mode recommendation system based on past effectiveness\n2. Build the targeted remediation system:\n   - Create algorithms to identify knowledge gaps from performance data\n   - Implement content selection logic for remediation materials\n   - Develop enrichment content recommendations for advanced students\n3. Implement automatic assignment generation:\n   - Design templates for various assignment types\n   - Create logic to populate templates based on student needs\n   - Build scheduling mechanisms for timely delivery\n4. Develop API endpoints for:\n   - Dashboard data retrieval\n   - Remediation content requests\n   - Assignment generation and delivery\n5. Implement continuous adaptation mechanisms that refine recommendations based on ongoing interactions\n\nTesting approach:\n- Component tests for dashboard elements\n- Integration tests with the adaptive engine and pathway system\n- A/B testing of different recommendation algorithms\n- User experience testing to ensure dashboard clarity and usefulness\n- End-to-end testing of the complete personalization system",
          "status": "pending",
          "parentTaskId": 16
        }
      ]
    },
    {
      "id": 17,
      "title": "Interoperability and Standards Compliance",
      "description": "Implement standards support and third-party integration capabilities",
      "status": "pending",
      "dependencies": [
        3,
        15,
        "21"
      ],
      "priority": "low",
      "details": "Implement LTI 1.3 Tool Provider support for integration with other LMS platforms. Create OneRoster 1.2 API for roster and grade synchronization. Implement Caliper Analytics for data export. Build SCORM 1.2/2004 export functionality for courses and content. Create the AI Skills Marketplace architecture with secure plug-in system (iframe + postMessage). Implement the custom model fine-tuning interface for institutions to train domain-specific models. Build API documentation and developer guides for third-party integration.\n\n**PRD Context**\nThe platform must support the following education technology standards to ensure broad compatibility with existing systems:\n- LTI 1.3 Advantage (Tool Provider launch): Enable the platform to be launched from other LMS systems\n- SCORM 1.2/2004 export wizard: Allow course content to be exported in SCORM-compliant packages\n- Caliper Analytics event emission: Support standardized learning analytics data collection\n- OneRoster synchronization: Enable automated roster and grade data exchange with SIS systems",
      "testStrategy": "Test LTI launch flows with sample consumer applications. Verify OneRoster API correctly synchronizes roster and grade data. Test SCORM export and import in a standard-compliant LMS. Check that the Skills Marketplace securely integrates third-party tools.",
      "subtasks": [
        {
          "id": 1,
          "title": "Implement LTI 1.3 Tool Provider Support",
          "description": "Create the necessary components to enable the platform to function as an LTI 1.3 Tool Provider, allowing it to be launched from other Learning Management Systems.",
          "dependencies": [],
          "details": "Implementation steps:\n1. Set up OAuth 2.0 authentication flow for LTI 1.3 including JWT token validation\n2. Create registration endpoints for platform configuration\n3. Implement the launch URL endpoint that handles incoming LTI launches\n4. Build user context mapping to associate LTI users with platform accounts\n5. Implement LTI Advantage services (Assignment and Grade Services, Deep Linking, Names and Role Provisioning)\n6. Create admin interface for managing LTI integrations and configurations\n\nTesting approach:\n- Unit tests for JWT validation and OAuth flows\n- Integration tests with mock LTI Consumer requests\n- End-to-end testing with common LMS platforms (Canvas, Moodle, Blackboard)\n- Security testing for proper validation of launch parameters",
          "status": "pending",
          "parentTaskId": 17
        },
        {
          "id": 2,
          "title": "Develop OneRoster 1.2 API and SCORM Export Functionality",
          "description": "Create a standards-compliant OneRoster 1.2 API for roster and grade synchronization with Student Information Systems, and implement SCORM 1.2/2004 export capabilities for courses and content.",
          "dependencies": [
            1
          ],
          "details": "Implementation steps:\n\nOneRoster 1.2 API:\n1. Design RESTful API endpoints following OneRoster 1.2 specifications\n2. Implement OAuth 2.0 authentication for API access\n3. Create data models and mappings between platform data and OneRoster format\n4. Build endpoints for classes, enrollments, users, and grades\n5. Implement CSV bulk data exchange option\n\nSCORM Export:\n1. Create a SCORM package generator service that converts course content to SCORM 1.2/2004 format\n2. Implement manifest file (imsmanifest.xml) generation\n3. Build content packaging system that bundles resources and metadata\n4. Create a user interface wizard for SCORM export options\n5. Implement progress tracking conversion to SCORM CMI data model\n\nTesting approach:\n- Unit tests for data transformation logic\n- API compliance testing against OneRoster certification test suite\n- Validation of generated SCORM packages with standard SCORM players\n- Integration tests with SIS systems for OneRoster compatibility\n- End-to-end testing of the export wizard UI",
          "status": "pending",
          "parentTaskId": 17
        },
        {
          "id": 3,
          "title": "Implement Caliper Analytics and AI Skills Marketplace",
          "description": "Build Caliper Analytics event emission for standardized learning data collection and create the AI Skills Marketplace architecture with a secure plug-in system and custom model fine-tuning interface.",
          "dependencies": [
            1,
            2
          ],
          "details": "Implementation steps:\n\nCaliper Analytics:\n1. Implement Caliper 1.1 sensor API for event emission\n2. Create event mappers for platform activities (content views, assessments, etc.)\n3. Build a configuration interface for Caliper endpoints\n4. Implement secure credential management for Caliper endpoints\n5. Create event queuing and batch processing for reliability\n\nAI Skills Marketplace:\n1. Design secure iframe-based plugin architecture using postMessage for communication\n2. Implement plugin registration and validation system\n3. Create sandbox environment for third-party AI models\n4. Build the custom model fine-tuning interface with dataset management\n5. Implement model versioning and deployment pipeline\n6. Create comprehensive API documentation and developer guides\n7. Build developer portal with SDK, examples, and testing tools\n\nTesting approach:\n- Unit tests for event generation and formatting\n- Security testing for iframe isolation and postMessage validation\n- Validation of Caliper events against the specification\n- Integration tests with Caliper endpoints\n- Performance testing for event processing at scale\n- End-to-end testing of the marketplace plugin system\n- User testing of the model fine-tuning interface",
          "status": "pending",
          "parentTaskId": 17
        }
      ]
    },
    {
      "id": 18,
      "title": "Security, Governance, and Compliance",
      "description": "Implement security features, audit logging, and compliance controls",
      "status": "pending",
      "dependencies": [
        3,
        "21"
      ],
      "priority": "high",
      "details": "Implement comprehensive audit logging for all system actions. Create the federated tenant architecture with tenant-isolated AI environments and data storage. Implement FERPA, GDPR, and COPPA compliance features including consent workflows and data privacy controls. Build the data residency controls for regional compliance. Create the security dashboard for administrators to monitor system activity and potential issues. Implement data export and deletion capabilities for compliance with right-to-access and right-to-be-forgotten requirements.\n\n**PRD Context**\n- Implement Row-Level Security (RLS) on all database tables to ensure data isolation\n- Configure tenant-isolated storage buckets for complete separation of customer data\n- Provide full exportable audit trails with before/after JSON for all system changes\n- Implement compliance workflows for FERPA, GDPR, and COPPA parental consent\n- Adhere to SOC 2 Type II controls throughout the system architecture\n- Apply OWASP Top 10 mitigations to prevent common security vulnerabilities\n- Enable data residency region selection for customers with geographic compliance requirements",
      "testStrategy": "Verify audit logs capture all relevant system actions with before/after states in JSON format. Test tenant isolation by attempting to access data across tenant boundaries and verify Row-Level Security prevents unauthorized access. Check compliance features with sample scenarios for FERPA, GDPR, and COPPA. Test data export and deletion functionality. Validate SOC 2 Type II controls are properly implemented. Perform security testing based on OWASP Top 10 guidelines. Verify data residency controls by confirming data storage location matches selected region.",
      "subtasks": [
        {
          "id": 1,
          "title": "Implement Tenant Isolation and Row-Level Security",
          "description": "Create the federated tenant architecture with isolated environments and implement Row-Level Security (RLS) on all database tables",
          "dependencies": [],
          "details": "Implementation steps:\n1. Design the multi-tenant database schema with tenant_id as a required field in all relevant tables\n2. Implement Row-Level Security policies on each table that filter data based on the current user's tenant_id\n3. Create tenant-isolated storage buckets with appropriate access controls\n4. Implement middleware that sets the current tenant context based on authentication\n5. Add tenant validation to all API endpoints to prevent tenant data leakage\n6. Create database functions that automatically apply tenant filters to queries\n7. Implement tenant provisioning and configuration workflows\n\nTesting approach:\n- Create test cases with multiple tenant contexts to verify data isolation\n- Attempt cross-tenant access to verify security boundaries\n- Test tenant provisioning and configuration workflows\n- Verify storage bucket isolation between tenants",
          "status": "pending",
          "parentTaskId": 18
        },
        {
          "id": 2,
          "title": "Implement Comprehensive Audit Logging System",
          "description": "Build a complete audit logging system that captures all system actions with before/after states and create the security dashboard",
          "dependencies": [
            1
          ],
          "details": "Implementation steps:\n1. Design the audit log data model to capture user, timestamp, action type, entity type, entity ID, tenant ID, and before/after JSON states\n2. Implement database triggers or application middleware to automatically capture changes to key tables\n3. Create logging services that record all authentication events, administrative actions, and data access patterns\n4. Build API endpoints to query and filter audit logs with appropriate pagination\n5. Develop the security dashboard UI for administrators to view and analyze audit logs\n6. Implement real-time alerts for suspicious activities or potential security issues\n7. Add export functionality for audit logs in various formats (CSV, JSON)\n\nTesting approach:\n- Verify all system actions are properly logged with accurate before/after states\n- Test filtering and search capabilities of the audit log system\n- Validate dashboard visualizations and alert mechanisms\n- Ensure audit logs maintain tenant isolation based on the tenant architecture from subtask 1",
          "status": "pending",
          "parentTaskId": 18
        },
        {
          "id": 3,
          "title": "Implement Compliance Controls and Data Privacy Features",
          "description": "Build FERPA, GDPR, and COPPA compliance workflows, data residency controls, and data export/deletion capabilities",
          "dependencies": [
            1,
            2
          ],
          "details": "Implementation steps:\n1. Design and implement consent workflows for different compliance regulations (FERPA, GDPR, COPPA)\n2. Create parental consent verification processes for COPPA compliance\n3. Implement data residency controls allowing tenant administrators to select geographic regions for data storage\n4. Build data classification system to identify and tag sensitive information\n5. Develop data export functionality to fulfill right-to-access requirements\n6. Implement secure data deletion processes for right-to-be-forgotten requests\n7. Create privacy policy and terms of service templates that can be customized per tenant\n8. Add compliance status reporting to the security dashboard\n\nTesting approach:\n- Validate consent workflows with different user scenarios\n- Test data residency controls by verifying data storage locations\n- Verify complete data export functionality returns all user data\n- Confirm data deletion processes properly remove all user information\n- Test audit logging of all compliance-related actions",
          "status": "pending",
          "parentTaskId": 18
        }
      ]
    },
    {
      "id": 19,
      "title": "Performance Optimization and Deployment",
      "description": "Optimize application performance and prepare for production deployment",
      "status": "pending",
      "dependencies": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        "21"
      ],
      "priority": "high",
      "details": "Implement code splitting and lazy loading for improved initial load time. Optimize database queries with appropriate indexes and caching. Set up image optimization with Next.js Image component and responsive sizing. Implement server-side rendering (SSR) and static site generation (SSG) where appropriate. Configure Vercel deployment with production environment variables. Set up CI/CD pipelines with GitHub Actions for automated testing and deployment. Implement monitoring and logging with appropriate tools. Configure horizontal scaling for high availability and performance.\n\n**PRD Context**\n- **Performance Targets**: P95 load times <= 300ms for static content and <= 2s for AI-generated content, Largest Contentful Paint (LCP) <= 2.5s\n- **Scalability Goals**: Support for 1M Monthly Active Users (MAU), handle 5000 Requests Per Second (RPS), implement horizontal autoscaling via Vercel and Supabase\n- **Availability Requirements**: Maintain 99.9% uptime, implement zero-data-loss blue-green deployments\n- **CI/CD Pipeline**: Configure GitHub Actions for comprehensive testing including lint, type checking, unit tests, end-to-end tests, accessibility tests, and visual regression tests\n- **Observability Stack**: Implement PostHog for client-side event tracking, Supabase logs for backend monitoring, and OpenTelemetry for distributed tracing",
      "testStrategy": "Measure performance metrics (LCP, FID, CLS) against specific targets defined in PRD (LCP <= 2.5s). Test application under load to verify scalability requirements of 5000 RPS and 1M MAU capacity. Verify deployment process with staging and production environments, ensuring zero-data-loss during blue-green deployments. Test CI/CD pipeline to confirm all automated tests (lint, type, unit, e2e, a11y, visual regression) run successfully. Validate that monitoring and logging systems (PostHog, Supabase logs, OpenTelemetry) capture relevant information for troubleshooting and meet observability requirements.",
      "subtasks": [
        {
          "id": 1,
          "title": "Frontend Performance Optimization",
          "description": "Implement code splitting, lazy loading, and image optimization to improve initial load time and meet performance targets",
          "dependencies": [],
          "details": "1. Implement code splitting using Next.js dynamic imports for non-critical components and routes\n2. Set up lazy loading for below-the-fold components and heavy UI elements\n3. Replace standard image tags with Next.js Image component throughout the application\n4. Configure responsive image sizing with appropriate breakpoints (mobile, tablet, desktop)\n5. Implement proper caching strategies with Cache-Control headers\n6. Audit and optimize client-side JavaScript bundles\n7. Test improvements using Lighthouse and WebPageTest to verify LCP <= 2.5s\n8. Document performance improvements with before/after metrics",
          "status": "pending",
          "parentTaskId": 19
        },
        {
          "id": 2,
          "title": "Server-Side Optimization and Rendering Strategies",
          "description": "Optimize database queries, implement appropriate rendering strategies, and set up caching to improve backend performance",
          "dependencies": [
            1
          ],
          "details": "1. Analyze and optimize database queries by adding appropriate indexes to frequently accessed tables\n2. Implement query caching using Redis or similar technology for frequently accessed data\n3. Configure SSR for dynamic, personalized pages that require fresh data\n4. Set up SSG with incremental static regeneration for content that changes infrequently\n5. Implement API route caching for appropriate endpoints\n6. Set up edge caching for static assets\n7. Test database query performance under load to ensure P95 response times <= 300ms for static content\n8. Document the rendering strategy decisions for each major route in the application",
          "status": "pending",
          "parentTaskId": 19
        },
        {
          "id": 3,
          "title": "Production Deployment and Monitoring Setup",
          "description": "Configure deployment pipelines, monitoring tools, and scaling strategies to ensure high availability and performance in production",
          "dependencies": [
            1,
            2
          ],
          "details": "1. Set up Vercel project configuration with production environment variables\n2. Configure GitHub Actions CI/CD pipeline with the following steps:\n   - Lint and type checking\n   - Unit and integration tests\n   - End-to-end tests\n   - Accessibility tests\n   - Visual regression tests\n   - Automated deployment to staging/production\n3. Implement blue-green deployment strategy for zero-downtime updates\n4. Set up PostHog for client-side event tracking and user analytics\n5. Configure Supabase logs for backend monitoring\n6. Implement OpenTelemetry for distributed tracing across services\n7. Set up automated alerts for performance degradation and errors\n8. Configure horizontal scaling rules in Vercel to handle 5000 RPS\n9. Document the monitoring dashboard setup and alert thresholds\n10. Create a rollback plan for emergency situations",
          "status": "pending",
          "parentTaskId": 19
        }
      ]
    },
    {
      "id": 20,
      "title": "Testing, Documentation, and Launch Preparation",
      "description": "Conduct comprehensive testing, create documentation, and prepare for launch",
      "status": "pending",
      "dependencies": [
        19
      ],
      "priority": "high",
      "details": "Implement unit tests for core functionality with Jest. Create integration tests with Playwright for end-to-end testing. Conduct accessibility testing with axe-core to ensure WCAG 2.1 AA compliance. Perform security audits and penetration testing. Create user documentation for all roles. Develop administrator guides for system configuration and management. Build training materials and onboarding processes. Set up support systems and feedback channels. Prepare marketing materials and launch communications. Configure analytics tracking for post-launch monitoring.\n\n**PRD Context**\n- Testing Coverage: Achieve minimum 80% test coverage for unit and integration tests\n- Test Types Required: \n  * Linting tests\n  * Type checking\n  * Unit tests with Jest\n  * End-to-end tests with Playwright\n  * Accessibility testing with axe-core for WCAG 2.1 AA compliance\n  * Visual regression testing\n- Documentation Requirements:\n  * Complete user documentation for all user roles\n  * Administrator guides for system configuration\n  * Training materials for onboarding\n- Launch Readiness:\n  * Support systems and feedback channels must be operational\n  * Analytics tracking configured for post-launch monitoring\n  * Security audits and penetration testing completed",
      "testStrategy": "Verify test coverage meets or exceeds 80% target. Check accessibility compliance with automated and manual testing. Review documentation for completeness and clarity. Test support systems and feedback channels with sample scenarios. Ensure all CI/CD pipeline tests (lint, type, unit, e2e, a11y, visual regression) pass successfully before launch.",
      "subtasks": [
        {
          "id": 1,
          "title": "Implement Comprehensive Testing Suite",
          "description": "Set up and implement all required testing frameworks and achieve minimum 80% test coverage",
          "dependencies": [],
          "details": "1. Configure Jest for unit testing:\n   - Set up Jest configuration file with appropriate settings\n   - Create test utilities and mocks for common dependencies\n   - Implement unit tests for core functionality focusing on business logic components\n\n2. Implement end-to-end testing with Playwright:\n   - Set up Playwright configuration for multiple browsers (Chrome, Firefox, Safari)\n   - Create test fixtures and helpers for common user flows\n   - Implement critical path tests covering main user journeys\n   - Add tests for edge cases and error handling\n\n3. Configure and implement accessibility testing:\n   - Integrate axe-core into the testing pipeline\n   - Create automated tests to verify WCAG 2.1 AA compliance\n   - Document any exceptions or areas requiring manual verification\n\n4. Set up visual regression testing:\n   - Configure visual snapshot testing tools\n   - Create baseline screenshots for key UI components and pages\n   - Implement comparison tests to detect unintended visual changes\n\n5. Implement linting and type checking in CI pipeline:\n   - Configure ESLint and TypeScript checking as part of the test suite\n   - Ensure all code passes linting and type checking requirements\n\nTesting approach: Run unit tests during development and in CI pipeline. Schedule longer-running integration and end-to-end tests to run nightly. Generate coverage reports and set up alerts for coverage drops below 80%.",
          "status": "pending",
          "parentTaskId": 20
        },
        {
          "id": 2,
          "title": "Create Comprehensive Documentation",
          "description": "Develop all required documentation for users, administrators, and training purposes",
          "dependencies": [
            1
          ],
          "details": "1. Create user documentation for all roles:\n   - Document all features and functionality with step-by-step instructions\n   - Include screenshots and examples for common tasks\n   - Organize documentation by user role (regular users, power users, etc.)\n   - Create a searchable knowledge base structure\n\n2. Develop administrator guides:\n   - Document system configuration options and best practices\n   - Create troubleshooting guides for common issues\n   - Include security recommendations and maintenance procedures\n   - Document API endpoints and integration options if applicable\n\n3. Build training materials and onboarding processes:\n   - Create guided tutorials for new users\n   - Develop interactive walkthroughs for key features\n   - Create video demonstrations for complex workflows\n   - Design onboarding checklists for different user types\n\n4. Set up documentation infrastructure:\n   - Implement a versioning system for documentation\n   - Create a feedback mechanism for documentation improvements\n   - Ensure documentation is accessible and follows best practices\n\nTesting approach: Conduct user testing with the documentation to ensure clarity and completeness. Have team members unfamiliar with specific features attempt to use them with only the documentation as guidance. Iterate based on feedback.",
          "status": "pending",
          "parentTaskId": 20
        },
        {
          "id": 3,
          "title": "Prepare for Product Launch",
          "description": "Complete security audits, set up support systems, and configure analytics for launch readiness",
          "dependencies": [
            1,
            2
          ],
          "details": "1. Conduct security audits and penetration testing:\n   - Perform automated security scanning with tools like OWASP ZAP\n   - Conduct manual penetration testing focusing on authentication and data protection\n   - Address all critical and high-priority security findings\n   - Document security measures for compliance purposes\n\n2. Set up support systems and feedback channels:\n   - Implement a ticketing system for user support\n   - Create templates for common support scenarios\n   - Set up automated issue reporting from the application\n   - Establish SLAs and support workflows\n   - Create a feedback collection mechanism within the application\n\n3. Configure analytics tracking:\n   - Implement analytics tracking for key user actions and conversion points\n   - Set up dashboards for monitoring user engagement\n   - Configure alerts for critical metrics\n   - Ensure analytics implementation complies with privacy regulations\n\n4. Prepare marketing materials and launch communications:\n   - Create announcement templates for different channels\n   - Develop a launch timeline and communication schedule\n   - Prepare FAQ documents for common questions\n   - Create assets for social media and other promotional channels\n\nTesting approach: Conduct a full launch rehearsal with the team, simulating the actual launch process. Test all support channels and analytics tracking in a staging environment. Verify that security measures are properly implemented through third-party validation.",
          "status": "pending",
          "parentTaskId": 20
        }
      ]
    },
    {
      "id": 21,
      "title": "Implement Student-Facing Course Player UI",
      "description": "Develop a comprehensive Course Player interface that allows students to navigate through course content, view lessons, take assessments, track progress, and experience adaptive learning journeys.",
      "details": "Create a responsive Course Player UI with the following components:\n\n1. **Main Layout**:\n   - Implement a two-panel layout with collapsible sidebar navigation and main content area\n   - Create breadcrumb navigation showing current position in course structure\n   - Add header with course title, progress summary, and user controls\n\n2. **Sidebar Navigation**:\n   - Display hierarchical course structure (modules, sections, lessons)\n   - Indicate completion status for each item using icons/colors\n   - Implement expand/collapse functionality for nested content\n   - Show estimated time and content type indicators for each item\n\n3. **Content Viewer**:\n   - Render rich lesson content from Lesson Studio (Task 10) including text, images, videos, code blocks, and interactive elements\n   - Support responsive content layout that adapts to different screen sizes\n   - Implement content navigation controls (previous/next, jump to section)\n   - Add bookmarking and note-taking capabilities\n\n4. **Assessment Integration**:\n   - Embed checkpoint quizzes from Assessment Builder (Task 11)\n   - Support multiple question types (multiple choice, fill-in-blank, matching, etc.)\n   - Implement quiz submission and immediate feedback display\n   - Show assessment history and performance metrics\n\n5. **Progress Tracking**:\n   - Create visual progress bar showing completion percentage\n   - Implement milestone markers for key achievements\n   - Connect to Mastery Tracking system (Task 14) to display competency levels\n   - Add visual indicators for recommended next steps\n\n6. **Adaptive Features**:\n   - Implement dynamic content presentation based on student performance\n   - Support conditional content display based on mastery level\n   - Add personalized recommendations for additional resources\n   - Integrate with adaptive journey system (Task 16)\n\n7. **Accessibility**:\n   - Ensure WCAG 2.1 AA compliance throughout the interface\n   - Implement proper heading structure and ARIA attributes\n   - Support keyboard navigation and screen readers\n   - Maintain sufficient color contrast and text sizing\n   - Add alt text for all images and media\n\n8. **PRD Context**:\n   - **Sidebar Navigation**: Implement a collapsible sidebar that displays the complete course structure with clear visual indicators for completion status, current position, and content types. Navigation should allow students to quickly jump between different sections of the course.\n   - **Rich Content Viewer**: Create a robust content display area that renders various content types (text, images, videos, code samples, interactive elements) with consistent styling and responsive layout. Support for bookmarking and note-taking should be integrated directly into the content view.\n   - **Checkpoint Quiz Integration**: Seamlessly embed assessment components that maintain the course's visual language while providing clear feedback on correct/incorrect answers. Support for reviewing past quiz attempts should be available.\n   - **Visual Progress Tracking**: Implement an intuitive progress visualization system showing overall course completion, module completion, and mastery levels for key concepts. Progress indicators should be consistently visible to motivate continued engagement.\n   - **Adaptive Journey Features**: Support dynamic difficulty adjustments based on student performance, allowing content to adapt in complexity or provide additional practice opportunities. Enable variant lesson formats that can be conditionally displayed based on learning style preferences or performance patterns.\n   - **Accessibility Requirements**: Ensure full WCAG 2.1 AA compliance, including proper semantic structure, keyboard navigation, screen reader support, and sufficient color contrast. All interactive elements must be fully accessible with appropriate ARIA attributes.\n\nUse the AppShell (Task 4) as the foundation for the Course Player, ensuring consistent styling and navigation patterns. Implement state management to track user progress within sessions and persist across page refreshes.",
      "testStrategy": "Testing should verify functionality, usability, and accessibility of the Course Player UI:\n\n1. **Functional Testing**:\n   - Verify sidebar navigation correctly displays course structure and updates active state\n   - Test content viewer renders all supported content types from Lesson Studio\n   - Confirm assessment integration displays quizzes correctly and processes submissions\n   - Validate progress tracking accurately reflects completion status\n   - Test adaptive features show appropriate content based on user progress\n\n2. **Integration Testing**:\n   - Verify integration with Lesson Studio content (Task 10)\n   - Test Assessment Builder quiz embedding and submission (Task 11)\n   - Validate Mastery Tracking data display (Task 14)\n   - Confirm adaptive journey features function correctly (Task 16)\n\n3. **Responsive Testing**:\n   - Test UI on multiple devices (desktop, tablet, mobile)\n   - Verify sidebar collapses/expands appropriately on smaller screens\n   - Confirm content reflows correctly at different viewport sizes\n\n4. **Accessibility Testing**:\n   - Run automated WCAG 2.1 AA compliance checks using axe or similar tools\n   - Perform keyboard navigation testing (tab order, focus indicators)\n   - Test with screen readers (NVDA, JAWS, VoiceOver)\n   - Verify color contrast meets minimum ratios\n   - Test with browser zoom up to 200%\n\n5. **User Testing**:\n   - Conduct usability testing with representative users\n   - Gather feedback on navigation intuitiveness and content readability\n   - Test with users who have accessibility needs\n\n6. **Performance Testing**:\n   - Measure and optimize load times for content rendering\n   - Test performance with large course structures\n   - Verify smooth transitions between content sections\n\nCreate automated tests using Jest and React Testing Library to verify component rendering and interactions. Document test cases in the test suite with clear descriptions of expected behavior.",
      "status": "pending",
      "dependencies": [
        4,
        10,
        11,
        14,
        16
      ],
      "priority": "high",
      "subtasks": [
        {
          "id": 1,
          "title": "Implement Course Player Layout and Sidebar Navigation",
          "description": "Create the foundational two-panel layout with a collapsible sidebar navigation and main content area, including the header with course information and the hierarchical course structure navigation.",
          "dependencies": [],
          "details": "Implementation details:\n\n1. Set up the basic Course Player component structure using the AppShell (Task 4) as foundation\n   - Create CoursePlayer container component with responsive layout\n   - Implement header with course title, progress summary, and user controls\n   - Add breadcrumb navigation component showing current position\n\n2. Develop the collapsible sidebar navigation\n   - Create hierarchical navigation structure for modules, sections, and lessons\n   - Implement expand/collapse functionality for nested content\n   - Add visual indicators for completion status (using icons/colors)\n   - Include estimated time and content type indicators for each item\n   - Ensure sidebar is responsive and can be toggled on smaller screens\n\n3. Implement state management for course structure and navigation\n   - Set up Redux/Context store for course structure data\n   - Create actions and reducers for navigation state\n   - Implement persistence of navigation state across page refreshes\n   - Add event handlers for navigation item selection\n\n4. Ensure accessibility for navigation components\n   - Implement proper heading structure and ARIA attributes\n   - Add keyboard navigation support\n   - Ensure sufficient color contrast for status indicators\n   - Test with screen readers\n\nTesting approach:\n- Unit tests for navigation components and state management\n- Integration tests for sidebar interaction with main content area\n- Responsive design testing across different screen sizes\n- Accessibility testing with automated tools and keyboard navigation",
          "status": "pending",
          "parentTaskId": 21
        },
        {
          "id": 2,
          "title": "Develop Content Viewer with Rich Media Support",
          "description": "Create a robust content viewer component that can render various content types (text, images, videos, code blocks, interactive elements) with responsive layout, navigation controls, and bookmarking functionality.",
          "dependencies": [
            1
          ],
          "details": "Implementation details:\n\n1. Create the main content viewer component\n   - Implement responsive container for lesson content\n   - Add content navigation controls (previous/next, jump to section)\n   - Create loading states and error handling for content fetching\n   - Ensure proper content scrolling behavior and viewport management\n\n2. Develop renderers for different content types\n   - Text renderer with support for headings, paragraphs, lists, etc.\n   - Image renderer with lazy loading and responsive sizing\n   - Video player integration with playback controls\n   - Code block renderer with syntax highlighting\n   - Interactive element container for embedded activities\n\n3. Implement bookmarking and note-taking features\n   - Add bookmark toggle UI and state management\n   - Create note-taking interface with text editor\n   - Implement save/load functionality for user-generated content\n   - Add bookmark/notes listing and navigation\n\n4. Connect content viewer to navigation system\n   - Handle navigation events from sidebar to load appropriate content\n   - Update breadcrumb and current position indicators\n   - Implement content transition animations\n   - Save viewing progress to state management\n\n5. Ensure accessibility for all content types\n   - Add proper alt text for images\n   - Ensure video players have captions and transcripts\n   - Maintain proper heading structure in rendered content\n   - Test all interactive elements with keyboard and screen readers\n\nTesting approach:\n- Unit tests for individual content type renderers\n- Integration tests for content navigation and state updates\n- Visual regression tests for content rendering\n- Performance testing for media loading and rendering\n- Accessibility testing for all content types",
          "status": "pending",
          "parentTaskId": 21
        },
        {
          "id": 3,
          "title": "Implement Assessment Integration and Progress Tracking",
          "description": "Integrate assessment components, progress tracking visualizations, and adaptive learning features to create a complete interactive learning experience.",
          "dependencies": [
            1,
            2
          ],
          "details": "Implementation details:\n\n1. Integrate assessment components\n   - Create container for embedding checkpoint quizzes\n   - Implement renderers for multiple question types (multiple choice, fill-in-blank, matching, etc.)\n   - Add quiz submission handling and immediate feedback display\n   - Develop assessment history and performance metrics views\n\n2. Implement progress tracking visualizations\n   - Create visual progress bar showing completion percentage\n   - Add milestone markers for key achievements\n   - Implement mastery level indicators connected to Mastery Tracking system\n   - Develop visual indicators for recommended next steps\n\n3. Develop adaptive learning features\n   - Implement conditional content display based on student performance\n   - Create system for dynamic content presentation based on mastery level\n   - Add personalized recommendations component\n   - Connect to adaptive journey system for personalized learning paths\n\n4. Integrate all components into cohesive experience\n   - Ensure consistent styling across all components\n   - Implement smooth transitions between content and assessments\n   - Create unified state management for tracking progress across components\n   - Add persistence layer for saving progress to backend\n\n5. Final accessibility and performance optimizations\n   - Conduct comprehensive accessibility audit\n   - Optimize component rendering and state updates\n   - Implement lazy loading for performance\n   - Add final polish for animations and transitions\n\nTesting approach:\n- Unit tests for assessment components and progress tracking\n- Integration tests for adaptive features and content conditionals\n- End-to-end tests for complete user journeys\n- Performance testing under various network conditions\n- User acceptance testing with sample course content",
          "status": "pending",
          "parentTaskId": 21
        }
      ]
    },
    {
      "id": 22,
      "title": "Implement Document Upload and Listing for Base Classes",
      "description": "Develop functionality to upload and list documents associated with base classes, including database schema changes, backend API endpoints, and frontend UI components.",
      "details": "This task requires implementing a complete document management system for base classes across multiple layers of the application:\n\n1. Database Schema Changes:\n   - Add a `base_class_id` foreign key column to the documents table in Supabase\n   - Ensure proper constraints and indexes for performance\n   - Update any existing migrations or schema definitions\n\n2. Backend API Development:\n   - Create an endpoint for document upload that accepts files, validates them, and associates them with the specified base class\n   - Implement a listing endpoint that retrieves all documents for a given base class ID\n   - Add proper authentication and authorization checks to ensure only authorized users can upload/view documents\n   - Implement appropriate error handling and validation\n   - Consider file size limits, allowed file types, and storage considerations\n\n3. Frontend Implementation:\n   - Add a document upload component to the base class details page\n   - Implement a file browser/selector that works across different browsers\n   - Create a document listing component that displays existing documents with relevant metadata\n   - Add download/preview functionality for listed documents\n   - Implement loading states and error handling for API interactions\n   - Ensure the UI is responsive and accessible\n\n4. Integration with Knowledgebase:\n   - Ensure uploaded documents are properly indexed for the knowledgebase\n   - Implement any necessary processing to extract content for lesson generation\n   - Add UI elements that explain how documents will be used in lesson creation\n\nThe implementation should follow existing application patterns and coding standards. Consider implementing pagination for the document listing if many documents are expected per base class.",
      "testStrategy": "Testing for this feature should be comprehensive across all layers:\n\n1. Database Testing:\n   - Verify the schema changes are correctly applied\n   - Test foreign key constraints to ensure data integrity\n   - Check that indexes are properly created for query performance\n\n2. Backend API Testing:\n   - Unit test the upload and listing endpoints with various input scenarios\n   - Test authentication and authorization rules\n   - Verify proper handling of edge cases (large files, invalid file types, etc.)\n   - Test error responses and status codes\n   - Implement integration tests that verify the entire flow from upload to storage\n\n3. Frontend Testing:\n   - Write unit tests for React components using Jest and React Testing Library\n   - Test the upload component with various file types and sizes\n   - Verify the document listing correctly displays data from the API\n   - Test loading states, error handling, and empty states\n   - Conduct cross-browser testing to ensure compatibility\n\n4. Manual Testing:\n   - Perform end-to-end testing of the complete document upload and listing flow\n   - Verify that uploaded documents appear correctly in the listing\n   - Test the feature with actual base classes in the development environment\n   - Verify that documents are correctly associated with the knowledgebase\n   - Test the user experience for clarity and ease of use\n\n5. Performance Testing:\n   - Test with large documents and high document counts\n   - Verify loading times for the document listing remain acceptable\n   - Check that the UI remains responsive during uploads\n\nDocument all test cases and results for future reference and regression testing.",
      "status": "done",
      "dependencies": [],
      "priority": "high",
      "subtasks": [
        {
          "id": 1,
          "title": "Design Database Schema for Document Storage",
          "description": "Create database schema to store uploaded documents with metadata including file name, size, format, upload date, and user information",
          "dependencies": [],
          "details": "Define tables for documents, document versions, permissions, and relationships to users. Include fields for document status tracking, indexing status, and content extraction flags.",
          "status": "done"
        },
        {
          "id": 2,
          "title": "Develop Backend API for Document Management",
          "description": "Create RESTful API endpoints for document upload, retrieval, listing, and deletion with proper authentication and validation",
          "dependencies": [
            1
          ],
          "details": "Implement file validation, chunked uploads for large files, progress tracking, error handling, and security measures. Include endpoints for document status updates and metadata management.",
          "status": "done"
        },
        {
          "id": 3,
          "title": "Build Frontend Upload and Listing UI Components",
          "description": "Develop drag-and-drop file uploader and document listing interface with filtering and sorting capabilities",
          "dependencies": [
            2
          ],
          "details": "Create components for upload field with progress indicators, file token display, error states, and responsive design for mobile and desktop. Implement document listing with search, filter, and preview functionality.",
          "status": "done"
        },
        {
          "id": 4,
          "title": "Implement Knowledgebase Integration and Indexing",
          "description": "Develop system to extract content from uploaded documents, index for search, and integrate with existing knowledgebase",
          "dependencies": [
            2,
            3
          ],
          "details": "Create content extraction pipeline for different file formats, implement indexing service, and develop integration with search functionality. Include status tracking for indexing process and error handling.\n<info added on 2025-05-13T03:21:53.521Z>\nCreate content extraction pipeline for different file formats, implement indexing service, and develop integration with search functionality. Include status tracking for indexing process and error handling.\n\nDatabase schema has been updated with a migration to add base_class_id to the document_chunks table, enabling proper association between chunks and their respective base classes. Next steps include verifying the summarize-chunks function to ensure it correctly processes document content with the updated schema. Once verified, we need to test the complete end-to-end flow from document upload through chunking, indexing, and retrieval to confirm proper integration with the knowledgebase system.\n</info added on 2025-05-13T03:21:53.521Z>",
          "status": "done"
        }
      ]
    },
    {
      "id": 23,
      "title": "Lesson Structure Generation from BaseClass",
      "description": "Implement functionality to generate lesson paths and lessons from a BaseClass definition, including optional AI-powered content auto-generation for these lessons.",
      "details": "",
      "testStrategy": "",
      "status": "done",
      "dependencies": [],
      "priority": "high",
      "subtasks": [
        {
          "id": 1,
          "title": "Define BaseClass.settings.curriculum_outline JSON structure and update BaseClass type",
          "description": "Determine and document the JSON structure for curriculum_outline within BaseClass.settings (or a dedicated field). This structure will define paths and their lessons. Update the BaseClass interface in src/types/teach.ts to reflect this new settings field.",
          "details": "Example curriculum_outline structure:\n```json\n{\n  \"paths\": [\n    {\n      \"id_ref\": \"path_1\", // Optional reference ID for internal use during generation\n      \"title\": \"Module 1: Introduction\",\n      \"description\": \"Fundamental concepts.\",\n      \"order\": 1,\n      \"lessons\": [\n        {\n          \"id_ref\": \"lesson_1_1\",\n          \"title\": \"First Lesson Topic\",\n          \"description\": \"Details about the first lesson.\",\n          \"order\": 1\n        }\n      ]\n    }\n  ]\n}\n```\nUpdate BaseClass in `src/types/teach.ts` to include `settings?: { curriculum_outline?: CurriculumOutline; [key: string]: any; };` where CurriculumOutline is a new interface matching this structure.\n<info added on 2025-05-13T13:51:14.780Z>\nThe structure to type is now based on `base_classes.settings.generatedOutline`, which contains an array of `modules` (acting as Paths). Each module has a `title` (string), `topics` (string[]), and an array of `suggestedLessons` (acting as Lessons). Each `suggestedLesson` has a `title` (string) and an `objective` (string). The `suggestedAssessments` array can be ignored for this typing task.\n\nDefine the following TypeScript interfaces in `src/types/teach.ts`:\n\n```typescript\ninterface GeneratedLesson {\n  title: string;\n  objective: string;\n}\n\ninterface GeneratedModule {\n  title: string;\n  topics: string[];\n  suggestedLessons: GeneratedLesson[];\n  suggestedAssessments?: any[]; // optional, not typed for this task\n}\n\ninterface GeneratedOutline {\n  modules: GeneratedModule[];\n}\n\ninterface BaseClass {\n  // ...other fields\n  settings?: {\n    generatedOutline?: GeneratedOutline;\n    [key: string]: any;\n  };\n}\n```\n\nUpdate the `BaseClass` type to include `settings?: { generatedOutline?: GeneratedOutline; [key: string]: any; };`. Remove or replace any previous `curriculum_outline` types if they were added based on earlier assumptions.\n</info added on 2025-05-13T13:51:14.780Z>",
          "status": "done",
          "dependencies": [],
          "parentTaskId": 23
        },
        {
          "id": 2,
          "title": "Create Supabase migration for paths and lessons tables",
          "description": "Create a new Supabase migration file. This migration will: 1. Alter the `paths` table: add `creator_user_id UUID REFERENCES auth.users(id)`, add `base_class_id UUID REFERENCES public.base_classes(id) ON DELETE CASCADE`, add `order_index INTEGER`. Remove/alter old `created_by` if it refers to `members`. Ensure `title` column exists. 2. Alter the `lessons` table: add `creator_user_id UUID REFERENCES auth.users(id)`, (optional) add `base_class_id UUID REFERENCES public.base_classes(id) ON DELETE SET NULL`. Remove/alter old `created_by`. Ensure `order_index INTEGER NOT NULL`.",
          "details": "",
          "status": "done",
          "dependencies": [],
          "parentTaskId": 23
        },
        {
          "id": 3,
          "title": "Implement API for BaseClass-to-Lesson Generation",
          "description": "Create the Next.js API route handler. It will read the `BaseClass.settings.curriculum_outline`, then iterate through the defined paths and lessons to create corresponding records in the `paths` and `lessons` database tables, linking them to the `baseClassId` and to each other (`lessons` to `paths`).",
          "details": "",
          "status": "done",
          "dependencies": [],
          "parentTaskId": 23
        },
        {
          "id": 4,
          "title": "Integrate Lesson Generation Trigger",
          "description": "Determine the trigger point for lesson generation. Choice 1: Automatically call the `generate-lessons` API after a `BaseClass` is successfully created or its `curriculum_outline` is updated. Choice 2: Add a button on the `BaseClass` management/editing page to let the user manually trigger this generation. Implement the chosen method.",
          "details": "",
          "status": "done",
          "dependencies": [],
          "parentTaskId": 23
        },
        {
          "id": 5,
          "title": "Implement API for AI Content Auto-Generation for a Lesson",
          "description": "Create an API route that takes a `lessonId`. This endpoint will use an AI model (e.g., GPT-4) to generate a set of initial `lesson_sections` (e.g., introduction, key topics, summary, simple quiz) for that lesson. The content should be based on the lesson's title, description, and its parent path/base class context. Save these sections to the `lesson_sections` table.",
          "details": "",
          "status": "done",
          "dependencies": [],
          "parentTaskId": 23
        },
        {
          "id": 6,
          "title": "UI for 'Auto-Generate All Lessons' Content Button",
          "description": "On the individual `BaseClass` management page, add a button labeled 'Auto-Generate Content for All Lessons'. When clicked, this should: 1. Fetch all lessons associated with the current `BaseClass`. 2. For each lesson, call the API endpoint from subtask 11.5 (`/api/teach/lessons/[lessonId]/auto-generate-content`). 3. Provide visual feedback for the (potentially long-running) process and report success/failure.",
          "details": "",
          "status": "done",
          "dependencies": [],
          "parentTaskId": 23
        }
      ]
    },
    {
      "id": 24,
      "title": "Task #24: Implement Editor Components for BaseClass Studio Right Panel",
      "description": "Create specialized editor components for BaseClass, Path, Lesson, and Lesson Section entities to be displayed in the right panel of the BaseClass Studio Page, enabling content creators to efficiently edit these educational elements.",
      "details": "This task involves designing and implementing four distinct editor components that will appear in the right panel of the BaseClass Studio interface:\n\n1. BaseClass Editor Component:\n   - Create form fields for editing BaseClass metadata (title, description, objectives, etc.)\n   - Implement save/cancel functionality with proper validation\n   - Add ability to manage BaseClass settings and configurations\n   - Include options to publish/unpublish the BaseClass\n\n2. Path Editor Component:\n   - Develop interface for editing Path properties (name, description, learning outcomes)\n   - Create functionality to reorder lessons within a path\n   - Implement path-specific settings (prerequisites, completion criteria)\n   - Add visual indicators for path status and progress tracking options\n\n3. Lesson Editor Component:\n   - Build rich text editing capabilities for lesson content\n   - Implement media embedding options (images, videos, code snippets)\n   - Create fields for lesson metadata (title, objectives, estimated duration)\n   - Add functionality to manage lesson resources and attachments\n\n4. Lesson Section Editor Component:\n   - Develop interface for editing section titles and content\n   - Implement drag-and-drop reordering of sections within a lesson\n   - Create controls for section-specific settings (visibility, interactive elements)\n   - Add ability to create different section types (text, quiz, exercise)\n\nAll components should:\n- Follow the application's design system for consistency\n- Implement real-time validation and error handling\n- Save changes automatically or provide explicit save controls\n- Include loading states and error recovery mechanisms\n- Be responsive and accessible\n- Integrate with the existing AI-powered lesson creation system from Task #10\n\nThe implementation should use React components with TypeScript, following the project's component architecture patterns. State management should align with the application's existing approach (Redux, Context API, etc.).",
      "testStrategy": "Testing for these editor components should be comprehensive and include:\n\n1. Unit Tests:\n   - Test each editor component in isolation using Jest and React Testing Library\n   - Verify that form validation works correctly for all input fields\n   - Ensure that state updates properly when user inputs change\n   - Test that save/cancel functionality works as expected\n   - Verify that error states are handled appropriately\n\n2. Integration Tests:\n   - Test the interaction between the editor components and the rest of the BaseClass Studio\n   - Verify that data flows correctly between the components and the backend\n   - Test that changes in one component reflect properly in related components\n   - Ensure that the AI-powered features from Task #10 integrate correctly with these editors\n\n3. End-to-End Tests:\n   - Create Cypress tests that simulate user workflows for creating and editing content\n   - Test complete scenarios like creating a BaseClass, adding a Path, creating Lessons, and organizing Lesson Sections\n   - Verify that all changes persist correctly after page refreshes\n\n4. Accessibility Testing:\n   - Verify that all editor components are keyboard navigable\n   - Test with screen readers to ensure proper ARIA attributes\n   - Check color contrast and focus states\n\n5. Performance Testing:\n   - Measure and optimize render times for each component\n   - Test with large datasets to ensure the editors remain responsive\n   - Verify that real-time saving doesn't impact user experience\n\n6. User Acceptance Testing:\n   - Create a test plan for content creators to validate the usability of the editors\n   - Collect feedback on the intuitiveness and efficiency of the editing experience\n   - Verify that all required editing capabilities are present and functioning\n\nDocument all test cases and results in the project's test documentation system, and ensure that automated tests are integrated into the CI/CD pipeline.",
      "status": "done",
      "dependencies": [
        10
      ],
      "priority": "high",
      "subtasks": [
        {
          "id": 1,
          "title": "Implement BaseClass Editor Component",
          "description": "Create a component to edit BaseClass details such as name, description, subject, grade levels, and other metadata. This will be displayed in the right panel of the BaseClass Studio when a BaseClass is selected in the navigation tree.",
          "details": "<info added on 2025-05-19T01:35:11.883Z>\nThe BaseClass Editor Component will be implemented with the following features:\n\n1. Main Editor Tab:\n   - Form fields for editing BaseClass metadata:\n     - Name (text input)\n     - Description (text area)\n     - Subject (dropdown/select)\n     - Grade levels (multi-select)\n     - Other relevant metadata fields\n   - Save button that persists changes to the backend\n   - Form validation to ensure required fields are completed\n\n2. Knowledge Base Tab:\n   - Document management interface for the BaseClass\n   - List view of all associated documents with metadata\n   - Upload functionality for adding new documents\n   - Delete functionality for removing documents\n   - Basic document preview capability\n\n3. Implementation Approach:\n   - Use React hooks for state management\n   - Implement form validation\n   - Create reusable form components\n   - Add loading states during save operations\n   - Implement error handling for API calls\n\n4. Future Enhancements (not in current scope):\n   - Toast notifications for user feedback\n   - UI/UX refinements\n   - Additional BaseClass fields as needed\n   - Improved document preview capabilities\n\nThe component will be designed to fit within the right panel of the BaseClass Studio and will be shown when a BaseClass is selected in the navigation tree.\n</info added on 2025-05-19T01:35:11.883Z>",
          "status": "done",
          "dependencies": [],
          "parentTaskId": 24
        },
        {
          "id": 2,
          "title": "Implement Path Editor Component",
          "description": "Create a component to edit Path details (e.g., title, description) and manage its associated Lessons (reorder, add, remove). This will be displayed in the right panel of the BaseClass Studio when a Path is selected.",
          "details": "<info added on 2025-05-19T01:35:22.311Z>\nThe Path Editor Component will be implemented as part of the BaseClass Studio right panel. The implementation will focus on three main areas:\n\n1. Path Details Form:\n   - Create form fields for all Path properties including title, description, and order_index\n   - Implement validation for required fields\n   - Add save functionality that updates the Path in the database\n   - Include a cancel button to discard changes\n   - Show loading/success/error states during save operations\n\n2. Lessons Viewer:\n   - Display a list of all Lessons currently associated with the Path\n   - Show key information for each Lesson (title, order within path)\n   - Implement a collapsible/expandable UI to save space\n   - Add visual indicators to show lesson status (draft, published, etc.)\n\n3. Future Lesson Management Features (to be implemented in a follow-up task):\n   - UI for reordering lessons via drag-and-drop\n   - Functionality to add existing lessons to the Path\n   - Button to create new lessons directly within the Path\n   - Option to remove lessons from the Path\n\nThe component will follow the same design patterns established in the BaseClass Editor Component for consistency across the Studio interface.\n</info added on 2025-05-19T01:35:22.311Z>",
          "status": "done",
          "dependencies": [],
          "parentTaskId": 24
        },
        {
          "id": 3,
          "title": "Implement Lesson Editor Component",
          "description": "Create a component to edit Lesson details (e.g., title, description, learning objectives) and manage its LessonSections (reorder, add, remove). This will be displayed in the right panel of the BaseClass Studio when a Lesson is selected.",
          "details": "<info added on 2025-05-19T01:35:34.482Z>\nThe Lesson Editor Component will be implemented with the following features:\n\n1. Lesson Details Form:\n   - Input fields for all Lesson properties:\n     - Title (text input)\n     - Description (text area)\n     - Learning Objectives (multi-line text area or list editor)\n     - Order Index (number input)\n     - Any additional metadata fields required\n   - Form validation to ensure required fields are completed\n   - Save button that persists changes to the backend\n   - Cancel button to discard changes\n   - Real-time validation feedback\n\n2. LessonSections Management:\n   - List view of all LessonSections belonging to the current Lesson\n   - Each LessonSection displayed with title and preview\n   - Drag-and-drop functionality for reordering sections\n   - \"Add Section\" button to create new LessonSections\n   - Delete/remove buttons for each LessonSection with confirmation dialog\n   - Click-to-edit functionality to navigate to the LessonSection editor\n\n3. UI/UX Considerations:\n   - Consistent styling with the rest of BaseClass Studio\n   - Responsive design for different screen sizes\n   - Loading states during save operations\n   - Error handling with user-friendly messages\n   - Unsaved changes detection and warnings\n\n4. Integration Points:\n   - Connect to the Lesson data model\n   - Integrate with the right panel display system\n   - Coordinate with the LessonSection editor component\n   - Update the parent component when changes are made\n\nThe component will be built using React with TypeScript, following the project's component architecture patterns.\n</info added on 2025-05-19T01:35:34.482Z>",
          "status": "done",
          "dependencies": [],
          "parentTaskId": 24
        },
        {
          "id": 4,
          "title": "Implement LessonSection Editor Component",
          "description": "Create a component to edit LessonSection content using a rich-text editor (e.g., Tiptap) with block-based capabilities. This will be displayed in the right panel of the BaseClass Studio when a LessonSection is selected. This component should handle content creation, updates, and versioning.",
          "details": "<info added on 2025-05-19T01:35:45.043Z>\nThe LessonSection Editor Component will implement specialized content editing interfaces based on the section_type:\n\n1. Text Sections:\n   - Implement Tiptap rich-text editor with full formatting capabilities\n   - Support for headings, lists, code blocks, and other text formatting options\n   - Enable embedding of images and other media within text content\n   - Implement autosave functionality for content changes\n\n2. Video URL Sections:\n   - Create a specialized editor for video content\n   - Input field for video URL (YouTube, Vimeo, etc.)\n   - Preview capability to validate video URLs\n   - Optional fields for video start/end timestamps\n\n3. Quiz Sections:\n   - Develop a structured editor for quiz content\n   - Support for multiple question types (multiple choice, true/false, short answer)\n   - Interface for adding, editing, and removing questions\n   - JSON schema validation for quiz structure\n   - Preview mode to test quiz functionality\n\n4. Document Embed Sections:\n   - Create interface for embedding external documents\n   - Support for PDF, Google Docs, and other document types\n   - Preview capability for embedded documents\n   - Options for display settings (height, width, scrollable)\n\nThe component will handle content type switching and maintain appropriate state based on the section_type. Section metadata (title, section_type, order_index) will be managed separately in Subtask 24.3.2.\n</info added on 2025-05-19T01:35:45.043Z>",
          "status": "done",
          "dependencies": [],
          "parentTaskId": 24
        }
      ]
    },
    {
      "id": 25,
      "title": "Knowledge Base Source Management",
      "description": "Implement comprehensive knowledge base source management functionality, allowing users to add content to their knowledge base through multiple methods: file uploads, URL submissions, text pasting, and audio recordings. This includes client-side handling of various input types, backend processing with the 'process-document' Edge Function, and real-time status updates in the UI.",
      "status": "done",
      "dependencies": [],
      "priority": "high",
      "details": "This task encompasses the full lifecycle of knowledge base content: from initial user input through various channels, to storage in Supabase, processing via Edge Functions (including specialized handling for different content types like audio transcription), and finally displaying the content with real-time status updates in the UI.",
      "testStrategy": "Test each input method (files, URLs, text, audio) individually to ensure proper handling. Verify correct storage paths and document record creation. Test the processing pipeline end-to-end, including specialized handlers like audio transcription. Ensure the UI correctly displays processing status and updates in real-time. Test error handling for various failure scenarios.",
      "subtasks": [
        {
          "id": 1,
          "title": "KB: Client-Side File Upload & Document Record Creation",
          "description": "In KnowledgeBaseEditor.tsx, implement logic for the 'Upload Files' tab to upload files to Supabase Storage, create a corresponding record in the 'documents' table, and then trigger the 'process-document' Edge Function.",
          "details": "Ensure correct bucket naming (org-${orgId}-uploads), file path conventions (e.g., base_class_documents/${baseClassId}/${fileName}), and invocation of process-document with the new documentId. Update UI with pending status.",
          "status": "done",
          "dependencies": [],
          "parentTaskId": 25
        },
        {
          "id": 2,
          "title": "KB: Client-Side URL (Web & YouTube) Submission",
          "description": "In KnowledgeBaseEditor.tsx, for the 'Paste Link/Text' tab, implement logic to handle URL submissions (both general web and YouTube). Create a 'documents' record (file_type: 'application/json', metadata: {originalUrl: ...}) and trigger 'process-document'.",
          "details": "Determine appropriate storage_path convention for URL types. Update UI with pending status.",
          "status": "done",
          "dependencies": [],
          "parentTaskId": 25
        },
        {
          "id": 3,
          "title": "KB: Client-Side Pasted Text Submission (as File)",
          "description": "In KnowledgeBaseEditor.tsx, for the 'Paste Link/Text' tab, implement logic to handle direct text paste. Convert pasted text into a File object (e.g., pasted_text.txt) and use the file upload mechanism (Subtask 25.1 logic).",
          "details": "This approach reuses existing file processing pipeline, avoiding immediate changes to the 'process-document' function for raw text input. Update UI.",
          "status": "done",
          "dependencies": [],
          "parentTaskId": 25
        },
        {
          "id": 4,
          "title": "KB: Client-Side Audio Recording Upload",
          "description": "In KnowledgeBaseEditor.tsx, for the 'Record Audio' tab, after recording, upload the audio blob to Supabase Storage. Create a 'documents' record and trigger 'process-document'.",
          "details": "Define file naming and storage path for recorded audio. Update UI.",
          "status": "done",
          "dependencies": [],
          "parentTaskId": 25
        },
        {
          "id": 5,
          "title": "KB: Backend Audio Transcription in Edge Function",
          "description": "Modify the 'process-document' Edge Function to add support for audio file types. Integrate an audio transcription service (e.g., OpenAI Whisper).",
          "details": "The transcribed text should then be passed to the existing chunking and embedding pipeline. Manage API keys for the transcription service via environment variables. Handle errors gracefully.",
          "status": "done",
          "dependencies": [],
          "parentTaskId": 25
        },
        {
          "id": 6,
          "title": "KB: Fetch & Display Existing KB Items in UI",
          "description": "In KnowledgeBaseEditor.tsx, fetch documents from the 'documents' table associated with the current baseClass.id.",
          "details": "Populate the 'knowledgeBaseItems' state with the fetched data, mapping fields correctly and displaying their current processing status. Implement loading states.",
          "status": "done",
          "dependencies": [],
          "parentTaskId": 25
        },
        {
          "id": 7,
          "title": "KB: Real-time/Polling for KB Item Status Updates",
          "description": "In KnowledgeBaseEditor.tsx, implement a mechanism (Supabase Realtime or polling) to update the status of knowledge base items in the UI as they change in the database.",
          "details": "This will provide users with live feedback on the processing of their uploaded content.",
          "status": "done",
          "dependencies": [],
          "parentTaskId": 25
        },
        {
          "id": 8,
          "title": "KB: End-to-End Testing & Refinement",
          "description": "Conduct end-to-end testing for all knowledge base source types (files, URLs, text, audio). Verify data flow, processing, status updates, and UI feedback.",
          "details": "Identify and fix any bugs. Refine UI/UX based on testing. Ensure error handling is robust.",
          "status": "done",
          "dependencies": [],
          "parentTaskId": 25
        }
      ]
    },
    {
      "id": 26,
      "title": "Advanced Learning Analytics and Adaptive Content Engine",
      "description": "Develop a comprehensive system for advanced learning analytics and adaptive content delivery that personalizes the educational experience in real-time. This includes creating database schemas for tracking student interactions, building analytics processing services, implementing real-time adaptive content generation, and developing an intelligent personalization engine that modifies learning paths based on student performance.",
      "status": "pending",
      "dependencies": [
        16
      ],
      "priority": "high",
      "details": "This task encompasses the development of a sophisticated learning analytics and adaptive content system with four main components:\n\n1. Enhanced database schema for tracking detailed student interactions and learning profiles\n2. Core analytics processing services to extract meaningful patterns and insights\n3. Real-time adaptive content engine that dynamically modifies content based on student performance\n4. Intelligent personalization engine that adjusts learning paths according to individual needs\n\nThe system will leverage AI for content generation and adaptation, implement real-time decision algorithms, and integrate with existing Luna platform components.",
      "testStrategy": "Testing will include:\n\n1. Unit tests for each component and service\n2. Integration tests between analytics engine and adaptive content systems\n3. Performance testing for real-time analytics processing\n4. A/B testing framework for evaluating adaptation effectiveness\n5. User acceptance testing with sample student profiles\n6. Load testing to ensure system can handle concurrent users\n7. Security testing for student data protection\n8. Regression testing after integration with existing systems",
      "subtasks": [
        {
          "id": 1,
          "title": "Enhanced Learning Analytics Engine Database Schema",
          "description": "Implement database schema extensions for advanced learning analytics including learning_interactions table for tracking detailed student interactions, student_learning_profiles table for personalization data, and performance_analytics table for real-time metrics computation",
          "details": "Create comprehensive database schema to support advanced adaptive learning:\n\n1. learning_interactions table:\n   - Track detailed interaction data (view, pause, replay, skip, bookmark, note)\n   - Store interaction timestamps, duration, device type\n   - Include performance context and session tracking\n   \n2. student_learning_profiles table:\n   - Store learning style weights and preferences\n   - Track optimal session duration and difficulty progression\n   - Store content format preferences and performance patterns\n   \n3. performance_analytics table:\n   - Real-time engagement and comprehension scores\n   - Optimal difficulty level predictions\n   - Attention span metrics and struggle/strength indicators\n\n4. Create appropriate indexes and RLS policies\n5. Implement migration scripts for production deployment",
          "status": "pending",
          "dependencies": [],
          "parentTaskId": 26
        },
        {
          "id": 2,
          "title": "Learning Analytics Processing Services",
          "description": "Build core analytics processing services including LearningAnalyticsEngine for extracting learning patterns, engagement score calculation, learning style identification, and attention pattern recognition",
          "details": "Implement comprehensive analytics processing system:\n\n1. LearningAnalyticsEngine service:\n   - Process raw interaction data into meaningful patterns\n   - Calculate engagement scores based on interaction frequency and completion\n   - Identify learning styles from content format preferences\n   - Track optimal challenge levels for individual students\n   \n2. Real-time analytics API endpoints:\n   - POST /api/learning-analytics/track - Real-time interaction tracking\n   - GET /api/learning-analytics/profile/:studentId - Retrieve profiles\n   - POST /api/learning-analytics/update-profile - Update preferences\n   - GET /api/learning-analytics/performance/:studentId - Current metrics\n   \n3. Performance optimization:\n   - Implement efficient data processing algorithms\n   - Add caching for frequently accessed analytics\n   - Optimize database queries for real-time performance\n   \n4. Integration with existing systems:\n   - Connect with Luna context engine\n   - Integrate with lesson player for data collection",
          "status": "pending",
          "dependencies": [
            "26.1"
          ],
          "parentTaskId": 26
        },
        {
          "id": 3,
          "title": "Real-time Adaptive Content Engine",
          "description": "Implement the AdaptiveContentEngine that dynamically selects and modifies content in real-time based on student performance, including content variant generation, adaptation triggers, and personalized content delivery",
          "details": "Build sophisticated content adaptation system:\n\n1. AdaptiveContentEngine core functionality:\n   - Generate multiple difficulty levels for each lesson section\n   - Create different content formats (visual, auditory, interactive, text)\n   - Provide scaffolding and enrichment versions\n   - Generate personalized examples and explanations\n   \n2. Real-time adaptation triggers:\n   - Performance below threshold → Additional scaffolding\n   - Rapid mastery → Enrichment content\n   - Attention drop → Content format switch\n   - Error patterns → Targeted remediation\n   \n3. API endpoints for content adaptation:\n   - POST /api/adaptive-content/evaluate - Assess and recommend adaptations\n   - GET /api/adaptive-content/variants/:lessonId - Retrieve content variants\n   - POST /api/adaptive-content/generate-variant - AI-generate new variants\n   - PUT /api/adaptive-content/apply-adaptation - Apply adaptations\n   \n4. AI integration for content generation:\n   - Use OpenAI for generating content variants\n   - Implement content quality validation\n   - Add support for multiple learning modalities",
          "status": "pending",
          "dependencies": [
            "26.2"
          ],
          "parentTaskId": 26
        },
        {
          "id": 4,
          "title": "Intelligent Personalization Engine",
          "description": "Build the PersonalizationEngine that modifies learning paths in real-time based on performance data, implementing adaptive strategies for remediation, enrichment, alternative paths, and accelerated learning",
          "details": "Implement advanced personalization capabilities:\n\n1. PersonalizationEngine core features:\n   - Real-time learning path adjustment algorithms\n   - Struggle and mastery detection systems\n   - Engagement monitoring and intervention triggers\n   - Path modification decision framework\n   \n2. Adaptation strategies implementation:\n   - Remediation Path: Additional support for struggling concepts\n   - Enrichment Path: Advanced challenges for high performers\n   - Alternative Path: Different approaches to same objectives\n   - Accelerated Path: Skip redundant content for demonstrated mastery\n   \n3. Detection algorithms:\n   - Struggle Detection: Failed attempts, extended time, help-seeking\n   - Mastery Detection: Quick completion, high accuracy, consistency\n   - Engagement Monitoring: Interaction frequency, session duration\n   \n4. Integration and testing:\n   - Connect with adaptive content engine\n   - Integrate with student progress tracking\n   - Implement A/B testing framework for path effectiveness\n   - Add comprehensive logging for decision analysis",
          "status": "pending",
          "dependencies": [
            "26.3"
          ],
          "parentTaskId": 26
        }
      ]
    },
    {
      "id": 27,
      "title": "Machine Learning Models for Personalized Learning",
      "description": "Develop and implement a comprehensive machine learning system for personalized learning that includes feature engineering, model implementation, and real-time deployment. This system will analyze user behavior patterns, predict optimal learning approaches, and dynamically adapt content delivery based on individual learning styles, attention spans, and difficulty preferences.",
      "status": "pending",
      "dependencies": [
        26
      ],
      "priority": "high",
      "details": "This task encompasses the full machine learning pipeline for our personalized learning platform, from data processing to production deployment. The system will leverage user interaction data to build predictive models that optimize the learning experience through real-time adaptations and recommendations.",
      "testStrategy": "Testing will include: 1) Unit tests for feature engineering components, 2) Validation of model accuracy against benchmark datasets, 3) Performance testing for real-time inference latency, 4) A/B testing framework to validate improvements in learning outcomes, 5) Integration testing with the broader learning platform, and 6) Monitoring systems to detect model drift and performance degradation in production.",
      "subtasks": [
        {
          "id": 1,
          "title": "Feature Engineering Pipeline for ML Models",
          "description": "Build comprehensive feature engineering pipeline that processes raw learning data into ML-ready features, including temporal patterns, interaction patterns, performance indicators, and cognitive load indicators",
          "details": "Implement sophisticated feature extraction system:\n\n1. Enhanced Feature Extraction components:\n   - Temporal Pattern Analysis: Session duration, frequency, peak learning times\n   - Interaction Pattern Analysis: Video engagement, reading speeds, navigation behavior\n   - Performance Indicator Analysis: Accuracy trends, improvement rates, transfer learning\n   - Cognitive Load Analysis: Pause patterns, help-seeking, time-on-task distribution\n   \n2. Feature engineering capabilities:\n   - Normalize features for ML model consumption\n   - Handle missing data and outliers\n   - Create composite features from raw interactions\n   - Implement feature versioning for model updates\n   \n3. Data processing infrastructure:\n   - Real-time feature computation for immediate predictions\n   - Batch processing for model training data preparation\n   - Feature store implementation for consistent feature access\n   - Data quality monitoring and validation\n   \n4. ML training dataset preparation:\n   - Create labeled datasets for supervised learning\n   - Implement data sampling strategies for balanced training\n   - Generate training/validation/test splits\n   - Support for continuous learning and model updates",
          "status": "pending",
          "dependencies": [],
          "parentTaskId": 27
        },
        {
          "id": 2,
          "title": "ML Model Implementation for Learning Pattern Recognition",
          "description": "Implement three core ML models: LearningStyleClassifier for learning style prediction, AttentionSpanPredictor for optimal session length, and DifficultyPreferenceModel for challenge level optimization",
          "details": "Build sophisticated ML models for adaptive learning:\n\n1. LearningStyleClassifier (Neural Network):\n   - Multi-class classification for visual, auditory, kinesthetic, reading/writing\n   - Input: 120+ behavioral interaction features\n   - Architecture: Deep neural network with dropout regularization\n   - Training: Supervised learning on labeled interaction data\n   \n2. AttentionSpanPredictor (LSTM Time-series):\n   - Predict optimal session length and break recommendations\n   - Input: Sequential interaction data over time windows\n   - Architecture: Multi-layer LSTM with attention mechanism\n   - Training: Time-series prediction on historical session data\n   \n3. DifficultyPreferenceModel (Preference Learning):\n   - Optimal difficulty level (1-10 scale) and progression rate\n   - Input: Performance history and engagement metrics\n   - Architecture: Collaborative filtering + neural collaborative filtering\n   - Training: Preference learning on performance-engagement pairs\n   \n4. Model training infrastructure:\n   - Hyperparameter optimization and model selection\n   - Cross-validation and performance evaluation\n   - Model versioning and experiment tracking\n   - Distributed training capabilities for large datasets",
          "status": "pending",
          "dependencies": [
            "27.1"
          ],
          "parentTaskId": 27
        },
        {
          "id": 3,
          "title": "Real-time Model Deployment and Orchestration",
          "description": "Build MLModelOrchestrator system for managing model deployment, real-time inference, performance monitoring, and automated model updates with A/B testing capabilities",
          "details": "Implement production-ready ML model infrastructure:\n\n1. MLModelOrchestrator core features:\n   - Model versioning and deployment management\n   - Real-time prediction serving with <200ms latency requirement\n   - Model performance monitoring and drift detection\n   - Automated model updates based on new data\n   \n2. Real-time inference system:\n   - API endpoints for model predictions\n   - Load balancing and scaling for high throughput\n   - Caching strategies for frequently requested predictions\n   - Fallback mechanisms for model failures\n   \n3. Model performance tracking:\n   - Prediction accuracy metrics by model and time period\n   - Model confidence score distributions and analysis\n   - Feature importance analysis and drift detection\n   - User outcome correlation with prediction quality\n   \n4. A/B testing and continuous improvement:\n   - Framework for testing model improvements\n   - Champion-challenger model deployment\n   - Statistical significance testing for model updates\n   - Performance comparison dashboards and alerts\n   \n5. Infrastructure and monitoring:\n   - Model serving infrastructure setup\n   - Logging and monitoring for production models\n   - Error handling and recovery mechanisms\n   - Security and access control for model endpoints",
          "status": "pending",
          "dependencies": [
            "27.2"
          ],
          "parentTaskId": 27
        }
      ]
    },
    {
      "id": 28,
      "title": "Enhanced Mastery Assessment and Learning Path Optimization",
      "description": "Develop a comprehensive system for advanced mastery assessment and learning path optimization that includes multi-dimensional competency tracking, predictive analytics, and dynamic path adaptation to create personalized, effective learning experiences.",
      "status": "pending",
      "dependencies": [
        27
      ],
      "priority": "high",
      "details": "This task encompasses the development of three interconnected systems:\n\n1. Multi-Dimensional Mastery Assessment Framework for granular competency tracking and holistic assessment\n2. Predictive Analytics for Learning Path Optimization to identify optimal learning sequences\n3. Dynamic Path Adaptation and Integration Systems for real-time personalization\n\nThese components will work together to create a sophisticated educational intelligence system that accurately measures student mastery across multiple dimensions while continuously optimizing their learning paths based on performance data and predictive models.",
      "testStrategy": "Testing will include:\n\n1. Unit tests for each component of the mastery assessment and learning path optimization systems\n2. Integration tests to verify proper communication between components\n3. Performance testing to ensure the system can handle expected user loads\n4. A/B testing framework to validate the effectiveness of learning path recommendations\n5. User acceptance testing with educators and students to verify usability and value\n6. Validation of AI-generated insights against expert educator assessments\n7. Privacy and security audits to ensure compliance with educational data standards",
      "subtasks": [
        {
          "id": 1,
          "title": "Multi-Dimensional Mastery Assessment Framework",
          "description": "Implement enhanced mastery framework with granular competency tracking, multi-dimensional mastery evidence collection, and AI-powered mastery synthesis using GPT-4 for holistic assessment",
          "details": "Build comprehensive mastery assessment system:\n\n1. Enhanced database schema implementation:\n   - competency_framework table with prerequisite relationships\n   - mastery_evidence table for multi-source evidence collection\n   - mastery_snapshots table for holistic mastery calculations\n   - Proper indexing and RLS policies for performance and security\n   \n2. MasteryCalculationEngine core features:\n   - Multi-dimensional analysis across knowledge, application, transfer, consistency, depth\n   - Evidence weighting and confidence calculation algorithms\n   - Temporal mastery progression tracking\n   - Adaptive mastery threshold calculations\n   \n3. AI-Powered Mastery Synthesis:\n   - GPT-4 integration for evidence pattern analysis\n   - Nuanced mastery insights combining quantitative and qualitative data\n   - Natural language mastery explanations and recommendations\n   - Bias detection and mitigation in AI assessments\n   \n4. Competency framework management:\n   - Subject area competency mapping and hierarchies\n   - Bloom's taxonomy integration for cognitive levels\n   - Prerequisite dependency tracking and validation\n   - Custom competency definition tools for educators",
          "status": "pending",
          "dependencies": [],
          "parentTaskId": 28
        },
        {
          "id": 2,
          "title": "Predictive Analytics for Learning Path Optimization",
          "description": "Build LearningPathOptimizer with learning path effectiveness tracking, path sequence analysis, and predictive path recommendations with confidence intervals and alternative path generation",
          "details": "Implement advanced learning path optimization system:\n\n1. Learning path analytics infrastructure:\n   - learning_path_analytics table for tracking path effectiveness\n   - learning_path_predictions table for predictive model outputs\n   - Path sequence analysis and success pattern identification\n   - Demographic clustering for personalized path recommendations\n   \n2. LearningPathOptimizer core features:\n   - Historical path effectiveness analysis and pattern recognition\n   - Optimal learning sequence prediction for individual students\n   - Alternative path generation for A/B testing and fallback options\n   - Confidence intervals and expected outcome predictions\n   \n3. Predictive intervention system (InterventionPredictor):\n   - Early warning system for disengagement risk\n   - Mastery stagnation detection and intervention triggers\n   - Conceptual difficulty anticipation and preemptive support\n   - Motivation decline detection and engagement strategies\n   \n4. Intervention recommendation engine:\n   - Immediate action recommendations (24-48 hours)\n   - Short-term strategy suggestions (1 week)\n   - Long-term adjustment planning (1 month)\n   - Success metrics and escalation trigger definitions\n   \n5. Performance validation and feedback loops:\n   - Prediction accuracy tracking and model improvement\n   - Intervention effectiveness measurement\n   - A/B testing framework for path optimization strategies",
          "status": "pending",
          "dependencies": [
            "28.1"
          ],
          "parentTaskId": 28
        },
        {
          "id": 3,
          "title": "Dynamic Path Adaptation and Integration Systems",
          "description": "Implement DynamicPathAdapter for continuous learning path optimization with real-time adaptation triggers, comprehensive integration with existing systems, and enhanced UI components for adaptive learning visualization",
          "details": "Build comprehensive dynamic adaptation and integration system:\n\n1. DynamicPathAdapter implementation:\n   - Real-time path modification based on performance ranges\n   - Engagement level change detection and response\n   - Mastery velocity shift adaptation\n   - External context change handling (time constraints, goals)\n   \n2. Adaptation strategy execution:\n   - Difficulty Adjustment: Dynamic content complexity modification\n   - Content Format Change: Visual/auditory/interactive switching\n   - Sequence Modification: Learning activity reordering\n   - Remediation Insertion: Targeted support content addition\n   - Enrichment Addition: Advanced challenge integration\n   \n3. Integration with existing systems:\n   - Luna Context Engine enhancement for educational context awareness\n   - Course Player adaptive features with real-time content adaptation display\n   - Teacher Dashboard analytics with real-time learning analytics and intervention alerts\n   - Enhanced student progress tracking and visualization\n   \n4. UI/UX enhancements for adaptive learning:\n   - Real-time adaptation indicators and explanations\n   - Personalized navigation recommendations\n   - Dynamic progress tracking visualizations\n   - Adaptive assessment integration in course player\n   - Teacher insights panel with individual student tracking\n   \n5. Quality assurance and monitoring:\n   - Continuous model validation and A/B testing framework\n   - Educational outcome validation and effectiveness monitoring\n   - Privacy and ethical AI implementation with bias monitoring\n   - Performance metric tracking and success measurement",
          "status": "pending",
          "dependencies": [
            "28.2"
          ],
          "parentTaskId": 28
        }
      ]
    },
    {
      "id": 29,
      "title": "Fix Luna Lesson Creation API Error - Remove Objectives Field References",
      "description": "Remove references to the objectives field from Luna lesson creation API endpoints since the lessons table doesn't have an objectives column, ensuring the API correctly handles combining objectives into the description field.",
      "details": "This task involves identifying and removing all references to the 'objectives' field in the Luna lesson creation API endpoints, as the lessons database table does not contain an objectives column. The current implementation is causing errors when creating or updating lessons.\n\nImplementation steps:\n1. Review all API endpoint handlers related to lesson creation and updates in the backend codebase, particularly focusing on:\n   - POST /api/lessons\n   - PUT /api/lessons/:id\n   - Any other endpoints that manipulate lesson data\n\n2. For each identified endpoint:\n   - Remove any direct references to the 'objectives' field in request validation\n   - Update the data transformation logic to ensure objectives data is properly merged into the description field\n   - Ensure any TypeScript interfaces or database models are updated to reflect this change\n\n3. Examine the database schema to confirm the structure of the lessons table and verify it indeed lacks an objectives column\n\n4. Update API documentation to reflect that objectives should be included in the description field rather than as a separate field\n\n5. Implement or modify the logic that combines objectives into the description field:\n   - If objectives are still being sent by clients, extract them from the request\n   - Format them appropriately (e.g., as bullet points or a section at the beginning of the description)\n   - Combine them with the existing description content\n   - Store the combined content in the description column\n\n6. Ensure backward compatibility by handling cases where clients might still send objectives as a separate field during a transition period\n\n7. Update any client-side code that might be explicitly sending objectives as a separate field to instead include them in the description field",
      "testStrategy": "1. Unit Testing:\n   - Write unit tests for the modified API endpoints to verify they correctly handle requests with and without objectives\n   - Test that objectives data is properly merged into the description field\n   - Verify error handling for malformed requests\n\n2. Integration Testing:\n   - Test the full flow of lesson creation and updating through the API\n   - Verify that lessons are correctly stored in the database with objectives incorporated into the description\n   - Test with various combinations of description and objectives data\n\n3. Client Compatibility Testing:\n   - Test with existing client applications to ensure they can still create and update lessons\n   - Verify that the UI correctly displays the combined description (with objectives)\n\n4. Regression Testing:\n   - Ensure that existing lessons can still be retrieved and displayed correctly\n   - Verify that other lesson-related functionality (searching, filtering, etc.) still works as expected\n\n5. Error Handling Testing:\n   - Test error scenarios to ensure appropriate error messages are returned\n   - Verify that invalid requests are properly rejected\n\n6. Performance Testing:\n   - Verify that the changes do not negatively impact API response times\n   - Test with large description/objectives content to ensure proper handling\n\n7. Manual Testing:\n   - Create a new lesson through the UI and verify it saves correctly\n   - Edit an existing lesson, modifying both description and what would have been objectives\n   - Verify the changes are correctly saved and displayed",
      "status": "done",
      "dependencies": [
        10,
        23
      ],
      "priority": "high",
      "subtasks": []
    },
    {
      "id": 30,
      "title": "Test Luna Lesson Creation After Database Trigger Fix",
      "description": "Verify that Luna lesson creation functionality works correctly after fixing the database trigger stack depth issue, ensuring the system can properly create and store lessons without errors.",
      "details": "This task involves comprehensive testing of the Luna lesson creation functionality after resolving the database trigger stack depth issue that was previously causing errors. The testing should cover all aspects of lesson creation to ensure the fix has resolved the underlying problem without introducing new issues.\n\nImplementation steps:\n\n1. Set up a testing environment that mirrors the production environment, including the database with the fixed triggers.\n\n2. Create a test plan covering the following scenarios:\n   - Creating a basic lesson with minimal required fields\n   - Creating a complex lesson with all available fields populated\n   - Creating lessons through the UI interface\n   - Creating lessons through direct API calls\n   - Creating lessons as part of a BaseClass generation\n   - Updating existing lessons with new content\n   - Deleting lessons and verifying database integrity\n\n3. For each test scenario, document:\n   - Test inputs (lesson data)\n   - Expected outcomes\n   - Actual results\n   - Any errors or warnings encountered\n\n4. Pay special attention to:\n   - Database trigger execution (monitor logs to ensure triggers fire correctly)\n   - Performance metrics (response times, server load during lesson creation)\n   - Edge cases (extremely large content, special characters, etc.)\n   - Integration with related systems (BaseClass, Paths, etc.)\n\n5. Create automated tests where possible to ensure regression testing can be performed in the future.\n\n6. Document any remaining issues or potential improvements identified during testing.\n\n7. Verify that the objectives field is correctly being combined into the description field as implemented in Task #29.\n\n8. Test the system under load to ensure the trigger stack depth issue doesn't resurface with concurrent operations.",
      "testStrategy": "1. **Unit Testing**:\n   - Create unit tests for the lesson creation API endpoints\n   - Verify correct handling of the objectives field (should be combined with description)\n   - Test error handling for invalid inputs\n   - Ensure database triggers execute without exceeding stack depth limits\n\n2. **Integration Testing**:\n   - Test the full lesson creation flow from UI to database\n   - Verify that lessons created through BaseClass generation work correctly\n   - Test integration with the RichTextEditor component\n   - Ensure media assets are properly linked to lessons\n\n3. **Performance Testing**:\n   - Measure response times for lesson creation operations\n   - Test concurrent lesson creation to ensure no trigger stack issues occur\n   - Monitor database performance during high-volume operations\n\n4. **Regression Testing**:\n   - Verify that all previously working functionality still operates correctly\n   - Ensure no new bugs were introduced by the trigger fix\n\n5. **User Acceptance Testing**:\n   - Have content creators test the lesson creation process end-to-end\n   - Gather feedback on any issues or unexpected behavior\n\n6. **Documentation**:\n   - Create a detailed test report documenting all test cases, results, and any issues found\n   - Update system documentation if any behavior changes were made during the fix\n\n7. **Verification Checklist**:\n   - Lesson creation succeeds without errors\n   - Lesson content is stored correctly in the database\n   - Triggers execute properly without stack depth errors\n   - Performance meets acceptable thresholds\n   - UI displays created lessons correctly\n   - Lesson updates and deletions work as expected",
      "status": "done",
      "dependencies": [
        29,
        10,
        23
      ],
      "priority": "high",
      "subtasks": []
    },
    {
      "id": 31,
      "title": "Comprehensive Testing of Luna's Multi-Step Content Creation Workflows",
      "description": "Test Luna's comprehensive multi-step content creation workflows to ensure all scenarios (path with lessons, lessons with sections, complete hierarchical structures) work correctly without ID confusion issues.",
      "details": "This task involves creating a comprehensive testing suite for Luna's content creation workflows, focusing on verifying the correct handling of hierarchical content structures and ID management across the system.\n\nImplementation steps:\n\n1. Create test cases for all content creation scenarios:\n   - Creating a learning path with multiple lessons\n   - Creating lessons with multiple sections\n   - Creating complete hierarchical structures (paths → lessons → sections)\n   - Testing content creation with and without AI-assisted generation\n   - Testing manual content creation workflows\n   - Testing batch operations (creating multiple items at once)\n\n2. Implement specific tests for ID management:\n   - Verify that IDs are correctly assigned and maintained throughout the content hierarchy\n   - Test for potential ID collisions or confusion when creating related content\n   - Ensure parent-child relationships are properly maintained in the database\n   - Verify that references between content items remain intact after updates\n\n3. Test edge cases:\n   - Creating content with maximum allowed children\n   - Deleting and recreating content in the same session\n   - Moving content between different parent containers\n   - Duplicating content and verifying unique IDs\n   - Testing with very long content that might trigger edge cases\n\n4. Implement integration tests that verify the entire workflow:\n   - From BaseClass definition to complete learning path generation\n   - From lesson creation to section population\n   - From content creation to content delivery/viewing\n\n5. Create automated test scripts that can be run as part of CI/CD:\n   - Use Playwright or similar tools for end-to-end testing\n   - Create API-level tests for backend functionality\n   - Implement database integrity checks after operations\n\n6. Document all test cases and expected outcomes in a test plan:\n   - Define success criteria for each test case\n   - Create a matrix of test scenarios and their coverage\n   - Document any known limitations or edge cases",
      "testStrategy": "1. Manual Testing:\n   - Create a test matrix covering all content creation scenarios\n   - Perform step-by-step testing of each workflow, documenting results\n   - Verify database state after each operation using SQL queries\n   - Test with different user roles to ensure permissions work correctly\n\n2. Automated Testing:\n   - Implement end-to-end tests using Playwright that simulate user interactions:\n     - Create a learning path with multiple lessons\n     - Add sections to lessons\n     - Verify correct rendering and relationships\n   - Create API tests that verify correct backend behavior:\n     - Test all API endpoints involved in content creation\n     - Verify correct response codes and data structures\n     - Test error handling and edge cases\n\n3. Database Verification:\n   - Create SQL queries to verify database integrity after operations\n   - Check for orphaned records or incorrect relationships\n   - Verify that IDs are unique and correctly referenced\n\n4. Performance Testing:\n   - Test with large datasets to ensure performance remains acceptable\n   - Measure response times for complex operations\n   - Identify any bottlenecks in the content creation process\n\n5. Regression Testing:\n   - Create a suite of tests that can be run after any changes to verify functionality\n   - Automate critical path tests to run in CI/CD pipeline\n   - Document baseline performance metrics for comparison\n\n6. Acceptance Criteria:\n   - All content creation workflows complete successfully without errors\n   - Database integrity is maintained throughout all operations\n   - No ID confusion issues occur in any test scenario\n   - UI correctly displays all created content with proper relationships\n   - Performance remains within acceptable parameters",
      "status": "done",
      "dependencies": [
        6,
        23,
        29,
        30
      ],
      "priority": "high",
      "subtasks": []
    },
    {
      "id": 32,
      "title": "Implement Luna's Dynamic Action Button Components",
      "description": "Develop reusable UI components for Luna's dynamic action buttons that handle confirmations, choices, and workflow navigation to create friction-free user interactions throughout the application.",
      "details": "This task involves creating a comprehensive set of reusable button components that Luna can dynamically generate to guide users through various workflows:\n\n1. **Button Component Library**:\n   - Create a base ActionButton component with consistent styling and behavior\n   - Implement ButtonVariants: primary, secondary, tertiary, danger, success\n   - Add support for different sizes: small, medium, large\n   - Ensure all buttons are fully accessible with proper ARIA attributes\n   - Implement loading states with appropriate spinners/indicators\n\n2. **Confirmation Button Components**:\n   - Create a ConfirmationButton that shows a confirmation dialog before action execution\n   - Implement a TwoStepButton that changes state/text after first click (e.g., \"Delete\" → \"Confirm Delete\")\n   - Add support for custom confirmation messages and action callbacks\n\n3. **Choice Button Components**:\n   - Develop a ButtonGroup component for presenting multiple options\n   - Create a ChoiceButtonSet for mutually exclusive options (radio button equivalent)\n   - Implement MultiSelectButtonSet for multiple selections (checkbox equivalent)\n   - Add support for dynamic option generation based on Luna's context\n\n4. **Workflow Navigation Components**:\n   - Create NextStepButton and PreviousStepButton components for multi-step workflows\n   - Implement a StepProgressIndicator to show position in workflow\n   - Develop a WorkflowButtonBar component to contain navigation buttons with consistent positioning\n   - Add support for conditional button enabling/disabling based on form validation state\n\n5. **Integration with Luna's AI Context**:\n   - Create a LunaActionProvider context to manage button state and callbacks\n   - Implement hooks for button components to access Luna's context\n   - Add support for dynamic button generation based on Luna's suggested actions\n   - Ensure buttons can report usage analytics back to Luna for learning\n\n6. **Animation and Feedback**:\n   - Add subtle animations for button state changes\n   - Implement haptic feedback for mobile devices\n   - Create toast notifications for action confirmations\n   - Add visual cues for recommended actions\n\n7. **Documentation and Examples**:\n   - Create a storybook page documenting all button variants\n   - Add usage examples for common scenarios\n   - Document the API for each button component\n   - Create integration examples with Luna's AI system",
      "testStrategy": "1. **Unit Testing**:\n   - Write Jest tests for each button component to verify rendering and basic functionality\n   - Test all button variants, sizes, and states\n   - Verify accessibility attributes are correctly applied\n   - Test that callbacks are properly triggered\n\n2. **Integration Testing**:\n   - Create tests that verify buttons work correctly within forms and workflows\n   - Test integration with Luna's context provider\n   - Verify that buttons correctly enable/disable based on validation state\n   - Test that confirmation dialogs appear and function as expected\n\n3. **User Flow Testing**:\n   - Create test scenarios for common user workflows (e.g., creating a lesson, uploading documents)\n   - Verify that workflow navigation buttons correctly guide users through multi-step processes\n   - Test that choice buttons correctly capture and store user selections\n   - Verify that confirmation buttons prevent accidental actions\n\n4. **Accessibility Testing**:\n   - Run automated accessibility tests using tools like Axe or Lighthouse\n   - Perform keyboard navigation testing to ensure all buttons are accessible without a mouse\n   - Test with screen readers to verify proper ARIA attributes and announcements\n   - Verify color contrast meets WCAG 2.1 AA standards\n\n5. **Visual Regression Testing**:\n   - Create snapshots of all button states and variants\n   - Verify consistent styling across the application\n   - Test responsive behavior on different screen sizes\n   - Verify animations and transitions work as expected\n\n6. **Performance Testing**:\n   - Measure render time for pages with many dynamic buttons\n   - Verify that button animations don't cause layout shifts\n   - Test performance on lower-end devices\n\n7. **User Acceptance Testing**:\n   - Create a test plan for stakeholders to verify button functionality meets requirements\n   - Collect feedback on button placement, sizing, and labeling\n   - Verify that the buttons enhance rather than complicate user workflows",
      "status": "done",
      "dependencies": [
        1,
        4,
        21
      ],
      "priority": "high",
      "subtasks": []
    },
    {
      "id": 33,
      "title": "Test Luna's Dynamic Action Button Functionality",
      "description": "Create comprehensive test cases for Luna's dynamic action buttons, focusing on confirmation dialogs, yes/no choices, and workflow navigation to ensure proper user interaction throughout the application.",
      "details": "This task involves creating and executing test cases to verify that Luna's dynamic action buttons function correctly across various scenarios:\n\n1. **Confirmation Dialog Testing**:\n   - Test Luna's ability to generate confirmation dialogs when users request actions that require verification\n   - Verify that \"Yes/No\" buttons appear correctly when Luna asks for confirmation\n   - Test edge cases where confirmation might be ambiguous or complex\n\n2. **Lesson Creation Confirmation Flow**:\n   - Ask Luna to create a new lesson and verify that appropriate confirmation buttons appear\n   - Test the complete flow from request to confirmation to execution\n   - Verify proper handling of both affirmative and negative responses\n\n3. **Content Modification Confirmation**:\n   - Request Luna to make changes to existing content that should trigger confirmation\n   - Test modification scenarios with varying levels of impact (minor edits vs. major changes)\n   - Verify that confirmation buttons appear with appropriate context and warning messages\n\n4. **Multi-step Workflow Navigation**:\n   - Test Luna's ability to guide users through multi-step processes using dynamic buttons\n   - Verify that button state changes appropriately as users progress through workflows\n   - Test navigation between steps, including going back or canceling mid-workflow\n\n5. **Button Styling and Accessibility**:\n   - Verify that buttons follow the design system guidelines for different variants\n   - Test keyboard navigation and screen reader compatibility\n   - Ensure buttons have appropriate hover/focus states and visual feedback\n\n6. **Error Handling**:\n   - Test scenarios where button actions might fail\n   - Verify appropriate error messages and recovery options\n   - Test timeout scenarios and connection issues\n\n7. **Cross-browser and Responsive Testing**:\n   - Verify button functionality across different browsers and devices\n   - Test responsive behavior on mobile, tablet, and desktop viewports\n\n8. **Performance Testing**:\n   - Measure response time between request and button appearance\n   - Test button rendering performance with multiple simultaneous actions",
      "testStrategy": "1. **Create Test Matrix**:\n   - Document all test scenarios in a spreadsheet with expected outcomes\n   - Include positive paths, negative paths, and edge cases\n   - Prioritize tests based on frequency and criticality\n\n2. **Manual Testing Procedure**:\n   - For each test case, document the exact prompt to give Luna\n   - Record expected button appearance, text, and behavior\n   - Execute tests and document actual results with screenshots\n   - Note any discrepancies between expected and actual behavior\n\n3. **Confirmation Dialog Testing**:\n   - Ask Luna: \"Can you create a new lesson about photosynthesis?\"\n   - Verify \"Yes\" and \"No\" buttons appear with appropriate styling\n   - Test both responses and verify correct system behavior\n   - Repeat with: \"Would you like to delete this section?\" and verify warning styling\n\n4. **Cross-functional Testing**:\n   - Test button functionality across different application areas:\n     - Lesson Studio\n     - Course Designer\n     - Assessment Builder\n     - Student Study Space\n\n5. **Regression Testing**:\n   - Create a set of standard prompts that should trigger action buttons\n   - Run these tests after any changes to the button component library\n   - Automate basic tests using Playwright or Cypress if possible\n\n6. **User Acceptance Testing**:\n   - Create guided test scenarios for non-technical users\n   - Observe and document their interactions with Luna's buttons\n   - Collect feedback on clarity, usability, and intuitiveness\n\n7. **Documentation**:\n   - Create a comprehensive report of all test results\n   - Document any bugs or issues found with severity ratings\n   - Provide recommendations for improvements\n   - Update test cases for future regression testing",
      "status": "done",
      "dependencies": [
        32
      ],
      "priority": "high",
      "subtasks": []
    },
    {
      "id": 34,
      "title": "Debug and Fix Luna Chat Action Buttons Display Issue",
      "description": "Identify and resolve the display issues with action buttons in Luna chat by implementing comprehensive debugging to trace the entire flow from API response to UI rendering.",
      "details": "This task involves implementing a systematic debugging approach to identify and fix the action buttons display issue in Luna chat:\n\n1. **Add Comprehensive Logging**:\n   - Implement detailed logging at key points in the action button rendering pipeline\n   - Add console logging for API responses containing action button data\n   - Track state changes in React components that render action buttons\n   - Log DOM manipulation and rendering events related to action buttons\n\n2. **Trace Data Flow**:\n   - Map the complete data flow from API response to UI rendering\n   - Verify that action button data is correctly structured in API responses\n   - Confirm proper data transformation in middleware/service layers\n   - Check state management for action button visibility and properties\n\n3. **Identify Rendering Issues**:\n   - Debug CSS styling conflicts that might affect button visibility\n   - Check for conditional rendering logic errors\n   - Verify z-index and positioning of action button containers\n   - Test button rendering across different viewport sizes\n\n4. **Fix Implementation**:\n   - Correct any identified data structure issues in API responses\n   - Fix state management bugs related to action button visibility\n   - Resolve CSS conflicts or styling issues\n   - Ensure proper event handling for action button interactions\n   - Implement proper cleanup of action buttons when conversations change\n\n5. **Refactor for Robustness**:\n   - Implement error boundaries around action button components\n   - Add fallback rendering for when action button data is malformed\n   - Create more explicit type checking for action button props\n   - Improve component isolation to prevent side effects\n\n6. **Documentation**:\n   - Document the identified issues and their solutions\n   - Update component documentation with any new props or behavior changes\n   - Add comments to critical sections of the action button rendering code",
      "testStrategy": "1. **Systematic Testing Approach**:\n   - Create a test matrix covering all action button types and states\n   - Test each action button type (confirmation, choice, navigation) individually\n   - Verify buttons render correctly in all chat contexts\n\n2. **Visual Regression Testing**:\n   - Take screenshots before and after fixes to confirm visual improvements\n   - Compare button rendering across different browsers and devices\n   - Verify proper alignment, spacing, and visual appearance\n\n3. **Functional Testing**:\n   - Verify that clicking action buttons triggers the correct actions\n   - Test edge cases like rapid clicking, multiple buttons, and button state changes\n   - Confirm that action buttons disappear appropriately after being clicked\n\n4. **Cross-browser Testing**:\n   - Test action button rendering in Chrome, Firefox, Safari, and Edge\n   - Verify mobile browser compatibility on iOS and Android devices\n   - Check for any browser-specific rendering issues\n\n5. **Performance Testing**:\n   - Measure render time for chat messages with action buttons\n   - Verify that adding debug logging doesn't impact performance\n   - Test with a large number of action buttons to ensure scalability\n\n6. **Regression Testing**:\n   - Verify that fixing action buttons doesn't break other chat functionality\n   - Test integration with other Luna features that might use action buttons\n   - Confirm that all previously working action button scenarios still function\n\n7. **User Acceptance Testing**:\n   - Have team members verify the fix resolves the reported issues\n   - Collect feedback on action button usability after the fix\n   - Confirm the fix meets design and UX requirements",
      "status": "done",
      "dependencies": [
        32,
        33,
        4,
        6,
        7
      ],
      "priority": "high",
      "subtasks": []
    }
  ],
  "metadata": {
    "projectName": "Learnology AI Implementation",
    "totalTasks": 20,
    "sourceFile": "scripts/prd.txt",
    "generatedAt": "2023-06-14"
  }
}